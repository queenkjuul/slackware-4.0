  Database-SQL-RDBMS HOW-TO document for Linux (PostgreSQL Object Rela­
  tional Database System)
  Al Dev (Alavoor Vasudevan)        aldev@hotmail.com
  v4.0, 21 December 1997

  This document is a "practical guide" to very quickly setup a SQL
  Database engine and front end tools on a Unix system. It also dis­
  cusses the International standard language ANSI/ISO SQL and reviews
  about the merits/advantages of the SQL database engine developed by
  the world-wide internet in an "open development" environment.  It is
  about HOW-TO setup a next generation Object Relational SQL Database
  "PostgreSQL" on Unix system which can be used as Application Database
  Server or as Web Database Server. PostgreSQL implements subset of
  International standard ISO and ANSI SQL 1998,92,89. This document also
  gives information on the interface programs for the database like
  Front End GUIs, RAD tools (Rapid Application Development), programming
  languages interfaces ("C", "C++", Java, Perl), ODBC, JDBC drivers and
  Web Database Tools and Interface programs. Information given here
  applies to all Unix platforms and other databases and will be very
  useful for people who are new to Databases, SQL language and Post­
  greSQL.  This document also has SQL tutorial, SQL syntax which would
  be very helpful for beginners. Experienced people will find this docu­
  ment useful as a handy reference guide. For students, the information
  given here will enable them to get the source code for PostgreSQL
  relational database system, from which they can learn how a RDBMS SQL
  database engine is written.

  1.  Introduction

  Each and every computer system in the world needs a database to
  store/retrieve the information.  Without a database, a computer can
  become useless. The primary reason you use the computer is to store,
  retrieve and process information and do all these very quickly,
  thereby saving you time.  At the same time the system must be simple,
  robust, fast, reliable, economical and very easy to use.  The most
  popular database systems are based on the International Standard
  Organisation (ISO) SQL specifications which are also based on ANSI SQL
  (American) standards.  Current specifications generally used are ANSI
  SQL 92 and ANSI SQL 89.  Upcoming standard is the SQL 1998/99 which is
  also called SQL-3. Popular database like Oracle, Sybase and Informix
  systems are based on these standards or are trying to implement these
  standards.

  As given in this document, there are more than 20 varieties of
  commercial/internet database systems which are being used in the world
  and many more will be coming in the near future. Without a standard
  like ANSI/ISO SQL, it would be very difficult for the customer to
  develop a application once and run on all the database systems.
  Today's customer wants to develop an application once using ISO SQL,
  ODBC, JDBC and sell it to be used on all varieties of database systems
  in the world.

  The world's most popular FREE Database which implements some of the
  ISO SQL, ANSI SQL/98, SQL/92 and ANSI SQL/89 RDBMS is PostgreSQL.
  PostgreSQL is next generation Object relational database and the
  future ANSI SQL standards like SQL 1998 (SQL-3) and beyond will
  increasingly deal with Object databases and Object data types.
  PostgreSQL is the only free RDBMS in the world which supports Object
  databases and SQL. This document will tell you how-to install the
  database and also all the packages related to databases, how to set up
  the Web database, application database, front end GUIs and interface
  programs.  It is strongly advised that you MUST write your database
  applications 100 % compliant to standards of ISO/ANSI SQL, ODBC, JDBC
  so that your application is portable across multiple databases like
  PostgreSQL, Oracle, Sybase, Informix etc.

  You get the highest quality, and lot many features with PostgreSQL as
  it follows 'Open Systems development model'. Open systems is the one
  where the complete source code is given to you and the development
  takes place on the internet by a extremely large network of human
  brains.  Future trend foresees that most of the software development
  will take place on the so called "Information Super-Highway" which
  spans the whole globe.  In the coming years, internet growth will be
  explosive which will further fuel rapid adoption of PostgreSQL by
  customers.

  Applying the principles of physics (quantum, classical,
  thermodynamics), mathematics and statistics to software quality, you
  get the highest quality of software only in a 'Open Systems' like
  PostgreSQL by opening the source code to a very vast number of human
  brains interconnected by the information super-highway.  Greater the
  number of human brains working, the better will be the quality of
  software.  Open Systems model will also prevent re-invention of
  wheels, eliminates duplication of work and will be very economical,
  saves time in distribution and follows the modern economic laws of
  optimizing the national and global resources.  As we will be entering
  the 21st century, there will be a change in the way that you get
  software for your use.  Customers will give first preference for the
  open systems software like PostgreSQL.

  Buying software MAY become a thing of the past. You only need to buy
  good hardware, it is worth spending money on the hardware and get the
  software from internet. Important point is that it is the computer
  hardware which is doing bulk of the work(99 %). Hardware is the real
  work horse and software is just a minor contributor.  That is, work
  done by the software is insignificant as compared to that  of the
  computer hardware.  Computer hardware is so much more complex that
  only 6 out of 180 countries in the world so far have demonstrated the
  capability of designing and manufacturing computer chips/hardware.
  Manufacturing computer chips is a super-high technology and is a very
  complex process, capital intensive requiring large investments in
  plant and production machines which deal with 0.25 micron technology,
  billions of transistors/circuits which are densely packed on a small
  silicon chip, which to date even many of the developed countries
  cannot afford to manufacture!  Companies like AMD, Intel, Cyrix,
  Hitachi, IBM and others spent billions of man-years to master the
  high-technology like Micro-electronics and Nano-electronics.  Micro
  means (one-millionth of centimeter), Nano  means (one-billionth of
  centimeter). Current technology uses micro-electronics of about 0.35
  micron using aluminum as conductors, 0.25 micron sizes using copper as
  conductors of electrons.  In near future the technology of 0.10 micron
  with copper and even nano-electronics will be used to make computer
  chips.

  As you can see, it is hardware that is high technology and important
  and software is a low technology and is NOT as important.  Hence,
  manufacturing hardware/hard-goods is vital for national economy!
  Companies like Compaq, Dell, Sun Microsystems, HP, IBM who manufacture
  computers are major contributors to U.S economy today and in the
  future!!

  On other hand, each and every country in the world develops/makes
  software.  In fact, any person in this world with a small low-cost PC
  can create a Oracle database server system!! But it would take him
  about 20 years (Oracle database server is over some 20 man-years). One
  man-year is one person working full-time for one full year. If 20
  people work for a year than it is 20 man-years spent.

  Databases like Oracle, Informix, Sybase, IBM DB2 are written in
  nothing but 100% "C" language and binaries are created by compiling
  the source and than shipped to customers.

  Since a lot of work had been done on PostgreSQL for the past 12 years,
  it does not make sense to re-create from scratch another database
  which satisfies ANSI/ISO SQL.  It will be a great advantage to take
  the existing code and add missing features or enhancements to
  PostgreSQL and start using it immediately.

  PostgreSQL is not just a free database but it is a 'Internet Product'
  and demands due respect and appreciation from one and all. Prediction
  is that demand for "Made By Internet" products will grow exponentially
  as it is capable of maintaining a high quality, low cost, extremely
  large user-base and developer-base. Those nations who do not use the
  'Made By Internet' products will be seriously missing "World-wide
  Internet Revolution" and will be left far behind other countries.

  2.  Other Formats of this Document

  This document is published in 10 different formats namely - DVI,
  Postscript, Latex, LyX, GNU-info, HTML, RTF(Rich Text Format), Plain-
  text, Unix man pages and SGML.

  ·  You can get this HOWTO document as a single file tar ball in HTML,
     DVI, Postscript or SGML formats from -
     <ftp://sunsite.unc.edu/pub/Linux/docs/HOWTO/other-formats/>

  ·  Plain text format is in:
     <ftp://sunsite.unc.edu/pub/Linux/docs/HOWTO>

  ·  Translations to other languages like French, German, Spanish,
     Chinese, Japanese are in
     <ftp://sunsite.unc.edu/pub/Linux/docs/HOWTO> Any help from you to
     translate to other languages is welcome.

  The document is written using a tool called "SGML tool" which can be
  got from - <http://www.xs4all.nl/~cg/sgmltools/> Compiling the source
  you will get the following commands like

  ·  sgml2html databasehowto.sgml     (to generate html file)

  ·  sgml2rtf  databasehowto.sgml     (to generate RTF file)

  ·  sgml2latex databasehowto.sgml    (to generate latex file)

  This document is located at -

  ·  <http://sunsite.unc.edu/LDP/HOWTO/Database-HOWTO.html>

  Also you can find this document at the following mirrors sites -

  ·  <http://www.caldera.com/LDP/HOWTO/Database-HOWTO.html>

  ·  <http://www.WGS.com/LDP/HOWTO/Database-HOWTO.html>

  ·  <http://www.cc.gatech.edu/linux/LDP/HOWTO/Database-HOWTO.html>

  ·  <http://www.redhat.com/linux-info/ldp/HOWTO/Database-HOWTO.html>

  ·  Other mirror sites near you (network-address-wise) can be found at
     <http://sunsite.unc.edu/LDP/hmirrors.html> select a site and go to
     directory /LDP/HOWTO/Database-HOWTO.html

  In order to view the document in dvi format, use the xdvi program. The
  xdvi program is located in tetex-xdvi*.rpm package in Redhat Linux
  which can be located through ControlPanel | Applications | Publishing
  | TeX menu buttons.

               To read dvi document give the command -
                       xdvi -geometry 80x90 howto.dvi
               And resize the window with mouse. See man page on xdvi.
               To navigate use Arrow keys, Page Up, Page Down keys, also
               you can use 'f', 'd', 'u', 'c', 'l', 'r', 'p', 'n' letter
               keys to move up, down, center, next page, previous page etc.
               To turn off expert menu press 'x'.

  You can read postscript file using the program 'gv' (ghostview) or The
  ghostscript program is in ghostscript*.rpm package and gv program is
  in gv*.rpm package in Redhat Linux which can be located through
  ControlPanel | Applications | Graphics menu buttons. The gv program is
  much more user friendly than ghostscript.

               To read postscript document give the command -
                       gv howto.ps

               To use ghostscript give -
                       ghostscript howto.ps

  You can read HTML format document using Netscape Navigator, Microsoft
  Internet explorer, Redhat Baron Web browser or any of the 10 other web
  browsers.

  3.  Laws of Physics applies to Software!

  Laws of science (Physics) applies everywhere, all the time, to
  anything that you do and even to software projects like database
  systems. Physics is in action even while you are talking (sound
  waves), walking (friction between ground and your feet), sleeping or
  writing software. Every software developer/user must have a very basic
  and minimum understanding of the science - namely Physics, Quantum
  Mechanics, Thermodynamics, Statistics and Mathematics. It is suggested
  you give atleast one reading to a "Introductory/Basic" textbook on the
  above subjects.  As per science, it is impossible to build a database
  software system which will be 100 % perfect and bug free. But by
  combining the energies of millions of people around the world via
  internet it is possible to achieve a near perfect database software
  system. Individually, the energy of each person will be minute, but by
  networking a large number of people, the total energy will be huge
  which can be focused on a project to generate a perfect system.  It is
  very clear that internet can network a vast number of people, which
  implies internet can produce high quality software products.

  Science would like every software developer and end-user not to be
  narrow-single-track minded but to be open and give a chance to "The
  Internet Products" like PostgreSQL, Linux, etc..

  4.  What is PostgreSQL ?

  PostgreSQL Version 6.2.1 patch level 3 is a free database, complete
  source code is given to you and is a Object-Relational Database System
  near compliant (getting closer) with ANSI SQL1998,92,89 and runs on
  diverse hardware platforms and Operating systems.

               Sometimes emergency bug fix patches are released after the
               GA release of PostgreSQL. You can apply these optional patches
               depending upon the needs of your application. Follow these
               steps to apply the patches -
                       cd "To postgresql source directory"
                       patch < "Specify a patch file here"
                       make clean
                       make

  The ultimate objective and the final goal of PostgreSQL is to become
  100 % compliant to ANSI/ISO SQL and also to become the number ONE open
  generic Database in the world. PostgreSQL will also guide, steer,
  control, monitor and dictate the future of ANSI/ISO SQL.  That is, the
  implementation and ideas first take place in PostgreSQL and than
  latter be incorporated into the ANSI/ISO SQL. PostgreSQL is the "state
  of the art" technology database.

  Informix Universal server (released 1997) is based on earlier version
  of PostgreSQL because Informix bought Illustra Inc. and integrated
  with Informix. Illustra database was completely based on Postgres
  (earlier version of PostgreSQL).

  PostgreSQL is an enhancement of the POSTGRES database management
  system, a next-generation DBMS research prototype.  While PostgreSQL
  retains the powerful data model and rich data types of POSTGRES, it
  replaces the PostQuel query language with an extended subset of SQL.

  PostgreSQL development is being performed by a team of Internet
  developers who all subscribe to the PostgreSQL development mailing
  list. The current coordinator is Marc G. Fournier
  scrappy@postgreSQL.org . This team is now responsible for all current
  and future development of PostgreSQL.

  The authors of PostgreSQL 1.01 were Andrew Yu and Jolly Chen.  Many
  others have contributed to the porting, testing, debugging and
  enhancement of the code. The original Postgres code, from which
  PostgreSQL is derived, was the effort of many graduate students,
  undergraduate students, and staff programmers working under the
  direction of Professor Michael Stonebraker at the University of
  California, Berkeley.

  The original name of the software at Berkeley was Postgres. When SQL
  functionality was added in 1995, its name was changed to Postgres95.
  The name was changed at the end of 1996 to PostgreSQL.

  Millions of PostgreSQL is installed as Database servers, Web database
  servers and Application data servers. It is much more advanced and is
  a object oriented relational database (ORDBMS).

  PostgreSQL can store more data types than traditional datatypes like
  integer, characters, etc. - you get to create user-defined types,
  functions, inheritance etc. (Version 7.0 will make these capabilities
  even more advanced).  PostgreSQL runs on Solaris, SunOS, HPUX, AIX,
  Linux, Irix, Digital Unix, BSDi,NetBSD, FreeBSD, SCO unix, NEXTSTEP,
  Unixware and all and every flavor of Unix. Port to Windows 95/NT is
  underway.

  ·  Title:             PostgreSQL SQL RDBMS Database (Object Relational
     Database Management System)

  ·  Current Version:   6.2.1 patch level 3

  ·  Age:               PostgreSQL is 12 years old. Developed since 1985

  ·  Authors:           Developed by millions/universities/companies on
     internet for the past 12 YEARS

  5.  Where to get it ?

  You can buy Redhat 4.2 Linux CDROM, Debian Linux CDROM or Slackware
  Linux CDROM which already contains the postgresql in rpm package (both
  source code and binaries) from :

  ·  Linux System Labs Web site:   <http://www.lsl.com/>  7 (U.S.
     dollars)

  ·  Cheap Bytes Inc Web site:   <http://www.cheapbytes.com/> 7 (U.S.
     dollars)

  ·  Debian Main Web site contact: Oliver.Elphick@lfix.co.uk

  In near future PostgreSQL organisation will be selling 'PostgreSQL
  CDROM' which will contain the complete source code and binaries for
  all the Unix operating systems.

  Binaries only distribution of PostgreSQL:

  ·  You can run PostgreSQL without compiling the source. Get binaries
     for Intel-Linux from  <http://www.redhat.com/pub/contrib/i386/>
     file is postgresql-6.2-3.i386.rpm. This is in the redhat package
     'rpm' format and it contains both source and binaries for
     PostgreSQL.

  ·  Binaries site for Solaris, HPUX, AIX, IRIX, Linux :
     <ftp://ftp.postgresql.org/pub/bindist> If you compile on any
     platform please upload to site, so that it will be useful for
     others.

  ·  ftp site : Get binaries for Intel-Linux from
     <ftp://ftp.redhat.com/pub/contrib/i386/> file is
     postgresql-6.2-3.i386.rpm. This is in the redhat package 'rpm'
     format and it contains both source and binaries for PostgreSQL.

  WWW Web sites:

  ·  Primary Web site:   <http://www.postgresql.org/>

  ·  Secondary Web site:      <http://logical.thought.net/postgres95/>

  ·  <http://www.itm.tu-clausthal.de/mirrors/postgres95/>

  ·  <http://s2k-ftp.cs.berkeley.edu:8000/postgres95/>

  ·  <http://xenium.pdi.net/PostgreSQL/>

  ·  <http://s2k-ftp.cs.berkeley.edu:8000/postgres95/>

  The ftp sites are listed below :-

  ·  Primary FTP:        <ftp://ftp.postgresql.org/pub>

  ·  Secondary FTP:      <ftp://ftp.chicks.net/pub/postgresql>

  ·  <ftp://ftp.emsi.priv.at/pub/postgres/>

  ·  <ftp://ftp.itm.tu-clausthal.de/pub/mirrors/postgres95>

  ·  <ftp://rocker.sch.bme.hu/pub/mirrors/postgreSQL>

  ·  <ftp://ftp.jaist.ac.jp/pub/dbms/postgres95>

  ·  <ftp://ftp.luga.or.at/pub/postgres95>

  ·  <ftp://postgres95.vnet.net:/pub/postgres95>

  ·  <ftp://ftpza.co.za/mirrors/postgres>

  ·  <ftp://sunsite.auc.dk/pub/databases/postgresql>

  ·  <ftp://ftp.task.gda.pl/pub/software/postgresql>

  ·  <ftp://xenium.pdi.net/pub/PostgreSQL>

  PostgreSQL source code is also available at all the mirror sites of
  sunsite unc (total of about 1000 sites around the globe). It is inside
  the Red Hat Linux distribution in /pub/contrib/i386/postgresql.rpm
  file.

  ·  For list of mirror sites go to  <ftp://sunsite.unc.edu>

  6.  PostgreSQL Supports Extremely Large Databases greater than 200 Gig

  Performance of 32-bit cpu machines will rapidly decline when the
  database size exceed 5 gig. You can run 30 gig database on 32-bit cpu
  but it will not be very effective. There is limitation imposed on the
  amount of RAM (maximum of 2 gig only), limitation on the file system
  sizes and also on the operating system.  The operating system on
  32-bit cpu will be "bumping it's head" too many times on the "32-bit
  ceiling".

  If you need to use extremely large databases (greater than 5
  gigabytes), it is strongly advised that you use 64-bit machines like
  Digital Alpha cpu, Sun Ultra-sparc 64-bit cpu, Silicon graphics 64-bit
  cpu, upcoming Intel Merced IA-64 cpu, HPUX 64bit machines, IBM 64-bit
  machines. Compile PostgreSQL under 64-bit cpu and it can support huge
  databases and large queries. Performance of PostgreSQL for queries on
  large tables and databases will be several times faster than
  PostgreSQL on 32-bit cpu machines. Advantage of 64-bit machines are
  that you get very large memory addressing space and the operating
  system can support very large file-systems, provide better performance
  with large databases, support much larger memory(RAM), have more
  capabilities etc..

  7.  How can I trust PostgreSQL ? Regression Test Package builds cus­
  tomer confidence

  Regression test package (src/test/regress) is included in the
  distribution and let your computer do the verification for standard
  SQL operations as well as the extensibility capabilities of
  PostgreSQL.  Advantage is that computer can rapidly run millions of
  SQL tests in a very short time. The speed of computer is about one
  billion times faster than human brain! In near future the speed of
  computer will be several zillion times faster than human brain! Hence,
  it makes sense to use the power of computer to validate the software
  instead of using the human brain power.

  The test package already contains hundreds of SQL test programs.  You
  can start the regression test (relax and have a cooldrink!) and come
  back take a glance at the output results and you are done! It is that
  simple and easy.

  You can add more tests just in case you need to, and can upload to the
  primary PostgreSQL web site if you feel that it will be useful to
  others on internet.  Regression test package helps build customer
  confidence and trust in PostgreSQL and facilitates rapid deployment of
  PostgreSQL on production systems without any major worries.

  Regression test package can be taken as a "very solid" technical
  specification mutually agreed upon document between the developers and
  end-users. PostgreSQL developers extensively use the regression test
  package during development period and also before releasing the
  software to public to ensure good quality.

  8.  GUI FrontEnd Tool for PostgreSQL (Graphical User Interface)

  PostgreSQL has TCL/TK interface library in the distribution called
  'pgtcl'. TCL/TK is a Rapid Application Development tool and is a very
  powerful scripting language.  Develop once and run it everywhere on
  NT, Win 95, Linux, OS/2 and all unixes! TCL/TK is also widely used as
  a Internet script language. So you will have only one language for all
  your needs - applications and internet. TCL stands for 'Tool Command
  Language' and TK is 'Tool Kit'. There is a IDE (integrated development
  environment) for TCL/TK called SpecTCL. Check for this rpm package
  under Redhat linux distribution or at the sunscript site given below.
  TCL/TK is usually shipped with every linux cdrom. Also you can get it
  from these sites -

  ·  <http://sunscript.sun.com/>

  ·  <http://sunscript.sun.com/TclTkCore/>

  ·  <ftp://ftp.sunlabs.com/pub/tcl/tcl8.0a2.tar.Z>

  ·  Reference text book: Many textbooks on TCL/TK are available in the
     market.

  ·  Visual TCL  <ftp://ftp.redhat.com/pub/contrib/i386/visualtcl*.rpm>

  9.  Integrated Development Environment Tools for PostgreSQL (GUI IDE)

  Check out the following development tools which you can use in
  conjunction with ODBC/JDBC drivers. These are similar to Borland C++
  Builder, Borland JBuilder.
  Vibe is a Java and C++ IDE (Integrated Development Environment) that
  won Unix Review's IDE of the year. This 800 US dollars product is
  available for Linux at a very special low price 79 US dollars for a
  limited time.  Check it out! This is a developer's dream.

  ·  More information on Vibe at
     <http://www.LinuxMall.com/products/00487.html>

     You can also use Borland C++ Builder, Delphi, Borland JBuilder,
     PowerBuilder on Windows95 connecting to PostgreSQL on unix box
     through ODBC/JDBC drivers.

  Free of cost IDE Tools -

  Check the CDROM of redhat linux distribution.

  ·  FreeBuilder  <ftp://ftp.redhat.com/pub/contrib/i386/free*.rpm>

  ·  SpecTCL  <ftp://ftp.redhat.com/pub/contrib/i386/spec*.rpm>

  ·  JccWarrior  <ftp://ftp.redhat.com/pub/contrib/i386/jcc*.rpm>

  ·  Applixware Tool  <http://www.redhat.com>

  ·  XWPE X Windows Programming Environment
     <http://www.rpi.edu/~payned/xwpe/>
     <ftp://ftp.redhat.com/pub/contrib/i386/xwpe*.rpm>

  ·  XWB X Windows Work Bench
     <ftp://ftp.redhat.com/pub/contrib/i386/xwb*.rpm>

  ·  NEdit  <ftp://ftp.redhat.com/pub/contrib/i386/nedit*.rpm>

  10.  Kanchenjunga - Java RAD Tool for PostgreSQL

  Kanchenjunga is a Java Rapid Application Tool for PostgreSQL. You can
  use this tool to develop rapidly the java application interfacing
  PostgreSQL.

  ·  <http://www.man.ac.uk/~whaley/kj/kanch.html>

  11.  Interface Drivers for PostgreSQL

  11.1.  ODBC Drivers for PostgreSQL

  ODBC stands for 'Open DataBase Connectivity' is a popular standard for
  accessing information from various databases from different vendors.
  Applications written using the ODBC drivers are guaranteed to work
  with various databases like PostgreSQL, Oracle, Sybase, Informix etc..

  ·  <http://www.openlinksw.com> Open Link Software Corporation is
     selling ODBC for PostgreSQL and other databases.  Open Link also is
     giving away free ODBC (limited seats) check them out.

  ·  <http://stud1.tuwien.ac.at/~e9025461/> This is the primary PostODBC
     (PostgreSQL ODBC) site. Unfortunately it has proved to be rather
     slow for sites that are not located in Austria.

  ·  <http://www.MageNet.com/postodbc/DOC> This mirror is maintained by
     Julia Anne Case who is also a major PostODBC developer.
  There is an interesting project called the FreeODBC Pack Package .
  There's no PostgreSQL Version there, maybe you can help.

  ·  <http://www.ids.net/~bjepson/freeODBC/> This is a cost free version
     of ODBC.

  11.2.  UDBC Drivers for PostgreSQL

  UDBC is a static version of ODBC independent of driver managers and
  DLL support, used to embed database connectivity support directly into
  applications.

  ·  <http://www.openlinksw.com> Open Link Software Corporation is
     selling UDBC for PostgreSQL and other databases.  Open Link also is
     giving away free UDBC (limited seats) check them out.

  11.3.  JDBC Drivers for PostgreSQL

  JDBC stands for 'Java DataBase Connectivity'. Java is a platform
  independent programming language developed by Sun Microsystems. Java
  programmers are encouraged to write database applications using the
  JDBC to facilitate portability across databases like PostgreSQL,
  Oracle, informix, etc. If you write Java applications you can get JDBC
  drivers for PostgreSQL from the following sites:

  JDBC driver is already included in the PostgreSQL distribution.

  ·  <http://www.demon.co.uk/finder/postgres/index.html> Sun's Java
     connectivity to PostgreSQL

  ·  <ftp://ftp.ai.mit.edu/people/rst/rst-jdbc.tar.gz>

  ·  <http://www.openlinksw.com> Open Link Software Corporation is
     selling JDBC for PostgreSQL and other databases.  Open Link also is
     giving away free JDBC (limited seats) check them out.

  11.4.  Java Classes for PostgreSQL

  Java programmers can find these classes for PostgreSQL very useful.

  ·  <ftp://www.blackdown.org/pub/Java/Java-Postgres95>

  ·  <http://www.blackdown.org>

  12.  Perl Database Interface (DBI) Driver for PostgreSQL

  12.1.  Perl 5 interface for PostgreSQL

  It is included in the distribution of PostgreSQL. Check in
  src/pgsql_perl5 directory.

  ·  Email: E.Mergl@bawue.de

  ·  Another source from -

  ·  Perl Home page :

  12.2.  WHAT IS DBI ?

  The Perl Database Interface (DBI) is a database access Application
  Programming Interface (API) for the Perl Language. The Perl DBI API
  specification defines a set of functions, variables and conventions
  that provide a consistent database interface independent of the actual
  database being used.

  12.3.  Announcement DBD-Pg-0.63 DBI driver for PostgreSQL

  On its way to CPAN is DBD-Pg-0.63.tar.gz.  Since the last public
  release the following changes have been made:

  - - adapted to PostgreSQL-6.2: o $ sth->rows as well as $ sth->execute
  and $ sth->do return the number of affected rows even for non-Select
  statements.  o support for password authorization added, please check
  the man-page for pg_passwd.

  - - the data_source parameter of the connect method accepts two
  additional parameters which are  treated as host and port:
  DBI->connect("dbi:Pg:dbname:host:port", "uid", "pwd")

  - - support for AutoCommit, please read the module documentation for
  impacts on your scripts !

  - - more perl-ish handling of data type bool, please read the module
  documentation for impacts on your scripts !

  for further information see:

  12.4.  Release Notes and ReadMe file

       #---------------------------------------------------------
       #
       # $Id: README,v 1.10 1997/10/05 18:25:55 mergl Exp $
       #
       # Portions Copyright (c) 1994,1995,1996,1997 Tim Bunce
       # Portions Copyright (c) 1997                Edmund Mergl
       #
       #---------------------------------------------------------

       **********************************************************
       *                                                        *
       *            This release makes changes which are        *
       *                      INCOMPATIBLE                      *
       *                      ------------                      *
       *                  to previous releases.                 *
       *                                                        *
       *        Please check the module documentation           *
       *             for the attribute AutoCommit               *
       *               and for the data type bool.              *
       *                                                        *
       **********************************************************

  DESCRIPTION:

  ------------

  This is version 0.63 of DBD-Pg.  DBD-Pg is a PostgreSQL interface for
  Perl 5 using DBI.

  For further information about DBI look at:

  COPYRIGHT:

  ----------

  You may distribute under the terms of either the GNU General Public
  License or the Artistic License, as specified in the Perl README file.

  IF YOU HAVE PROBLEMS:

  ---------------------

  Please send comments and bug-reports to E.Mergl@bawue.de

  Please include the output of perl -v, and perl -V, the version of
  PostgreSQL, the version of DBD-Pg, and the version of DBI in your bug-
  report.

  REQUIREMENTS:

  -------------

  - build, test and install Perl 5         (at least 5.002) - build,
  test and install the DBI module (at least 0.89) - build, test and
  install PostgreSQL     (at least 6.2)

  PLATFORMS:

  ----------

  This release of DBD-Pg has been developed using Linux 2.0 with dynamic
  loading for the perl extensions. Let me know, if there are any
  problems with other platforms.

  INSTALLATION:

  -------------

  The Makefile checks the environment variable POSTGRES_HOME as well
  some standard locations, to find the root directory of your Postgres
  installation.

  1.   perl Makefile.PL 2.   make 3.   make test 4.   make install

  ( 1. to 3. as normal user, not as root ! )

  TESTING:

  --------

  Run 'make test'.  Note, that the user running this script must have
  been created with the access rights to create databases *AND* users !
  Do not run this script as root !

  If testing fails with the message 'login failed', please check if
  access to the database template1 as well as pgperltest is not
  protected in pg_hba.conf.

  If you are using the shared library libpq.so check if your dynamic
  loader finds libpq.so. With Linux the command /sbin/ldconfig -v should
  tell you, where it finds libpq.so. If ldconfig does not find libpq.so,
  either add an appropriate entry to /etc/ld.so.conf and re-run ldconfig
  or add the path to the environment variable LD_LIBRARY_PATH.  A
  typical error message resulting from not finding libpq.so is:
  install_driver(Pg) failed: Can't load './blib/arch/auto/DBD/Pg/Pg.so'
  for module DBD::Pg: File not found at

  Some linux distributions have an incomplete perl installation.  If you
  have compile errors like "XS_VERSION_BOOTCHECK undeclared", make a If
  this file is not present, you need to recompile and reinstall perl.

  SGI users: if you get segmentation faults make sure, you use the
  malloc which comes with perl when compiling perl (the default is not
  to).  "David R. Noble" drnoble@engsci.sandia.gov
  drnoble@engsci.sandia.gov

  ---------------------------------------------------------------------------

  E.Mergl@bawue.de                     October 05, 1997

  ---------------------------------------------------------------------------

  12.5.  FAQ for DBI

  Below is the Frequently Asked question FAQ for DBI. The main web page
  is at

  <http://www.hermetica.com/technologia/perl/DBI>

                     DBI Frequently Asked Questions v.0.35
                         Last updated: June 20th, 1997

  * NAME
  * SYNOPSIS
  * VERSION
  * DESCRIPTION
  * Basic Information & Information Sources

     * 1.1 What is DBI, DBperl, Oraperl and *perl?
     * 1.2. Where can I get it from?
     * 1.3. Where can I get more information?

  * Compilation Problems

     * 2.1. Compilation problems or "It fails the test!"

  * Platform and Driver Issues

     * 3.1 What's the difference between ODBC and DBI?
     * 3.2 Is DBI supported under Windows 95 / NT platforms?
     * 3.3 Can I access Microsoft Access or SQL-Server databases with DBI?
     * 3.4 Is the a DBD for >?
     * 3.5 What's DBM? And why should I use DBI instead?
     * 3.6 When will mSQL-2 be supported?
     * 3.7 What database do you recommend me using?
     * 3.8 Is > supported in DBI?

  * Programming Questions

     * 4.1 Is DBI any use for CGI programming?
     * 4.2 How do I get faster connection times with DBD::Oracle and CGI?
     * 4.3 How do I get persistent connections with DBI and CGI?
     * 4.4 ``When I run a perl script from the command line, it works, but,
       when I run it under the C, it fails!'' Why?
     * 5.1 Can I do multi-threading with DBI?
     * 5.2 How do I handle BLOB data with DBI?
     * 5.3 How can I invoke stored procedures with DBI?
     * 5.4 How can I get return values from stored procedures with DBI?
     * 5.5 How can I create or drop a database with DBI?
     * 5.6 How can I C or C a statement with DBI?
     * 5.7 How are C values handled by DBI?
     * 5.8 What are these C methods all about?

  * Support and Training

     * Commercial Support
     * Training

  * Other References
  * AUTHOR

  ----------------------------------------------------------------------------

  NAME

  DBI::FAQ -- The Frequently Asked Questions for the Perl5 Database Interface

  ----------------------------------------------------------------------------

  SYNOPSIS

      perldoc DBI::FAQ

  ----------------------------------------------------------------------------

  VERSION

  This document is currently at version 0.35, as of June 20th, 1997.

  ----------------------------------------------------------------------------

  DESCRIPTION

  This document serves to answer the most frequently asked questions on both
  the DBI Mailing Lists and personally to members of the DBI development team.

  ----------------------------------------------------------------------------

  Basic Information & Information Sources

  ----------------------------------------------------------------------------

  1.1 What is DBI, DBperl, Oraperl and *perl?

  To quote Tim Bunce, the architect and author of DBI:

      ``DBI is a database access Application Programming Interface (API)
        for the Perl Language. The DBI API Specification defines a set
        of functions, variables and conventions that provide a consistent
        database interface independent of the actual database being used.''

  In simple language, the DBI interface allows users to access multiple
  database types transparently. So, if you connecting to an Oracle, Informix,
  mSQL, Sybase or whatever database, you don't need to know the underlying
  mechanics of the 3GL layer. The API defined by DBI will work on all these
  database types.

  A similar benefit is gained by the ability to connect to two different
  databases of different vendor within the one perl script, ie, I want to read
  data from an Oracle database and insert it back into an Informix database
  all within one program. The DBI layer allows you to do this simply and
  powerfully.

  Here's a diagram that demonstrates the principle:

                              [ DBI Architecture ]

  DBperl is the old name for the interface specification. It's usually now
  used to denote perl4 modules on database interfacing, such as, oraperl,
  isqlperl, ingperl and so on. These interfaces didn't have a standard API and
  are generally not supported.

  Here's a list of DBperl modules, their corresponding DBI counterparts and
  support information. Please note, the author's listed here generally do not
  maintain the DBI module for the same database. These email addresses are
  unverified and should only be used for queries concerning the perl4 modules
  listed below. DBI driver queries should be directed to the dbi-users mailing
  list.

      Module Name Database Required   Author          DBI
      ----------- -----------------   ------          ---
      Sybperl     Sybase              Michael Peppler DBD::Sybase
                                      <mpeppler@itf.ch>
      Oraperl     Oracle 6 & 7        Kevin Stock     DBD::Oracle
                                      <dbi-users@fugue.com>
      Ingperl     Ingres              Tim Bunce &     DBD::Ingres
                                      Ted Lemon
                                      <dbi-users@fugue.com>
      Interperl   Interbase           Buzz Moschetti  DBD::Interbase
                                      <buzz@bear.com>
      Uniperl     Unify 5.0           Rick Wargo      None
                                      <rickers@coe.drexel.edu>
      Pgperl      Postgres            Igor Metz       DBD::Pg
                                      <metz@iam.unibe.ch>
      Btreeperl   NDBM                John Conover    SDBM?
                                      <john@johncon.com>
      Ctreeperl   C-Tree              John Conover    None
                                      <john@johncon.com>
      Cisamperl   Informix C-ISAM     Mathias Koerber None
                                      <mathias@unicorn.swi.com.sg>
      Duaperl     X.500 Directory     Eric Douglas    None
                  User Agent

  However, some DBI modules have DBperl emulation layers, so, DBD::Oracle
  comes with an Oraperl emulation layer, which allows you to run legacy
  oraperl scripts without modification. The emulation layer translates the
  oraperl API calls into DBI calls and executes them through the DBI switch.

  Here's a table of emulation layer information:

      Module                  Emulation Layer     Status
      ------          ---------------     ------
      DBD::Oracle     Oraperl             Complete
      DBD::Informix   Isqlperl            Under development
      DBD::Sybase     Sybperl             Working? ( Needs verification )
      DBD::mSQL       Msqlperl            Experimentally released with
                                          DBD::mSQL-0.61

  The Msqlperl emulation is a special case. Msqlperl is a perl5 driver for
  mSQL databases, but does not conform to the DBI Specification. It's use is
  being deprecated in favour of DBD::mSQL. Msqlperl may be downloaded from
  CPAN via:

      http://www.perl.com/cgi-bin/cpan_mod?module=Msqlperl

  ----------------------------------------------------------------------------

  1.2. Where can I get it from?

  DBI is primarily distributed from:

      ftp://ftp.demon.co.uk/pub/perl/db

  The Comprehensive Perl Archive Network resources should be used for
  retrieving up-to-date versions of the drivers, since local mirror sites
  usually lag. CPAN may be accessed via Tom Christiansen's splendid CPAN
  multiplexer program located at:

      http://www.perl.com/CPAN/

  For more specific version information and exact URLs of drivers, please see
  the DBI drivers list and the DBI module pages which can be found on:

      http://www.hermetica.com/technologia/perl/DBI

  ----------------------------------------------------------------------------

  1.3. Where can I get more information?

  There are a few information sources on DBI.

  DBI Specification

           http://www.hermetica.com/technologia/perl/DBI/doc/dbispec

       There are two specifications available at this link, the new DBI Draft
       Specification which is a rapidly changing document as the development
       team drive towards a stable interface, and the old historical DBperl
       Specification out of which the current DBI interface evolved.

       The latter document should be regarded as being of historical interest
       only and should not serve as a programming manual, or authoratative in
       any sense. However, it is still a very useful reference source.

  POD documentation
       PODs are chunks of documentation usually embedded within perl programs
       that document the code ``in place'', providing a useful resource for
       programmers and users of modules. POD for DBI and drivers is beginning
       to become more commonplace, and documentation for these modules can be
       read with the following commands.

       The DBI Specification
            The POD for the DBI Specification can be read with the:

                perldoc DBI

            command.

       Oraperl
            Users of the Oraperl emulation layer bundled with DBD::Oracle, may
            read up on how to program with the Oraperl interface by typing:

                perldoc Oraperl

            This will produce an updated copy of the original oraperl man page
            written by Kevin Stock for perl4. The oraperl API is fully listed
            and described there.

       DBD::mSQL
            Users of the DBD::mSQL module may read about some of the private
            functions and quirks of that driver by typing:

                perldoc DBD::mSQL

       Frequently Asked Questions
            This document, the Frequently Asked Questions is also available as
            POD documentation! You can read this on your own system by typing:

                perldoc DBI::FAQ

            This may be more convenient to people not permanently, or
            conveniently, connected to the Internet.

       POD in general
            Information on writing POD, and on the philosophy of POD in
            general, can be read by typing:

                perldoc perlpod

            Users with the Tk module installed may be interested to learn
            there is a Tk-based POD reader available called tkpod, which
            formats POD in a convenient and readable way.

  Rambles, Tidbits and Observations

           http://www.hermetica.com/technologia/perl/DBI/tidbits

       There are a series of occasional rambles from various people on the DBI
       mailing lists who, in an attempt to clear up a simple point, end up
       drafting fairly comprehensive documents. These are quite often varying
       in quality, but do provide some insights into the workings of the
       interfaces.

  ``DBI -- The perl5 Database Interface''
       This is an article written by Alligator Descartes and Tim Bunce on the
       structure of DBI. It was published in issue 5 of ``The Perl Journal''.
       It's extremely good. Go buy the magazine. In fact, buy all of them!
       ``The Perl Journal''s WWW site is:

           http://www.tpj.com

  ``DBperl''
       This article, published in the November 1996 edition of ``Dr. Dobbs
       Journal'' concerned DBperl. The author of this edition apparently did
       not bother to contact any of the DBI development team members for
       verification of the information contained within his article. Several
       reviews of the article on the dbi-users mailing list were disparaging,
       to say the least. The fact the article was written about DBperl instead
       of DBI hints at the staleness of the information.

       However, we include the reference for completeness' sake.

  ``The Perl5 Database Interface''
       This item is a book to be written by Alligator Descartes ( for it is me
       ) and published by O'Reilly and Associates this coming Winter.

       Here is the putative table of contents for the book.

            * Introduction
                 + Databases
                 + CGI / WWW
                 + perl
            * Basic Database Concepts
                 + Types of Database
                      o Flat File
                      o AnyDBM
                      o RDBMS
                 + Using Which Database For What...
            * SQL
                 + Why SQL?
                 + Structuring Information In Databases
                 + Retrieving Data From Databases
                 + Manipulating Data and Data Structures
            * DBI Architecture
            * Programming with DBI
                 + DBI Initialization
                 + Handles
                      o Driver Handles
                      o Database Handles
                      o Statement Handles
                 + Connection and Disconnection
                 + Handling Errors
                 + Issuing Simple Queries
                 + Executing Atomic Statements
                 + Statement MetaData
                 + More perl-ish Statements
                 + Binding
                 + Transaction Handling
                 + Utility Methods
                 + Handle Attributes and Dynamic Variables
            * DBI and ODBC
            * The Database Drivers
                 + DBD::Oracle and oraperl
                 + DBD::Informix and isqlperl
                 + DBD::mSQL and Msqlperl
            * Case Studies
                 + DBI and the WWW
                 + Data Migration and Warehousing
                 + Administration Software
            * Appendix: API Reference / Specification
            * Appendix: Resources

  README files
       The README files included with each driver occasionally contains some
       useful information ( no, really! ) that may be pertinent to the user.
       Please read them. It makes our worthless existences more bearable.
       These can all be read from the main DBI WWW page at:

           http://www.hermetica.com/technologia/perl/DBI

  Mailing Lists
       There are three mailing lists for DBI run by Ted Lemon. These can all
       be subscribed to and unsubscribed from via the World Wide Web at the
       URL of:

           http://www.fugue.com/dbi

       The lists that users may participate in are:

       dbi-announce
            This mailing list is for announcements only. Very low traffic. The
            announcements are usually posted on the main DBI WWW page.

            If you cannot successfully use the form on the above WWW page,
            please subscribe to the list in the following manner:

                Email: 'dbi-announce-request@fugue.com' with a message body of
                'subscribe'

       dbi-dev
            This mailing list is intended for the use of developers discussing
            ideas and concepts for the DBI interface, API and driver
            mechanics. Only any use for developers, or interested parties. Low
            traffic.

            If you cannot successfully use the form on the above WWW page,
            please subscribe to the list in the following manner:

                Email: 'dbi-dev-request@fugue.com' with a message body of
                'subscribe'

       dbi-users
            This mailing list is a general discussion list used for bug
            reporting, problem discussion and general enquiries. Medium
            traffic.

            If you cannot successfully use the form on the above WWW page,
            please subscribe to the list in the following manner:

                Email: 'dbi-users-request@fugue.com' with a message body of
                'subscribe'

  Mailing List Archives
       US Mailing List Archives

                http://outside.organic.com/mail-archives/dbi-users/

            Searchable hypermail archives of the three mailing lists, and some
            of the much older traffic have been set up for users to browse.

       European Mailing List Archives

                http://www.rosat.mpe-garching.mpg.de/mailing-lists/PerlDB-Interest

            As per the US archive above.
  ----------------------------------------------------------------------------

  Compilation Problems

  ----------------------------------------------------------------------------

  2.1. Compilation problems or "It fails the test!"

  First off, consult the online information about the module, beit DBI itself,
  or a DBD, and see if it's a known compilation problem on your architecture.
  These documents can be found at:

      http://www.hermetica.com/technologia/perl/DBI

  If it's a known problem, you'll probably have to wait till it gets fixed. If
  you're really needing it fixed, try the following:

  Attempt to fix it yourself
       This technique is generally not recommended to the faint-hearted. If
       you do think you have managed to fix it, then, send a patch file (
       context diff ) to the author with an explanation of:

          o What the problem was, and test cases, if possible.

          o What you needed to do to fix it. Please make sure you mention
            everything.

          o Platform information, database version, perl version, module
            version and DBI version.

  Email the author Do NOT whinge!
       Please email the address listed in the WWW pages for whichever driver
       you are having problems with. Do not directly email the author at a
       known address unless it corresponds with the one listed.

       We tend to have real jobs to do, and we do read the mailing lists for
       problems. Besides, we may not have access to <insert your favourite
       brain-damaged platform here> and couldn't be of any assistance anyway!
       Apologies for sounding harsh, but that's the way of it!

       However, you might catch one of these creative genii at 3am when we're
       doing this sort of stuff anyway, and get a patch within 5 minutes. The
       atmosphere in the DBI circle is that we do appreciate the users'
       problems, since we work in similar environments.

       If you are planning to email the author, please furnish as much
       information as possible, ie:

          o ALL the information off the README file in the problematic module.
            And we mean ALL of it. We don't put lines like that in
            documentation for the good of our health, or to meet obscure
            README file standards of length.

          o If you have a core dump, try the Devel::CoreStack module for
            generating a stack trace from the core dump. Send us that too.
            Devel::CoreStack can be found on CPAN at:

                http://www.perl.com/cgi-bin/cpan_mod?module=Devel::CoreStack

          o Module versions, perl version, test cases, operating system
            versions and any other pertinent information.

       Remember, the more information you send us, the quicker we can track
       problems down. If you send us nothing, expect nothing back.

  Email the dbi-users Mailing List
       It's usually a fairly intelligent idea to cc the mailing list anyway
       with problems. The authors all read the lists, so you lose nothing by
       mailing there.

  ----------------------------------------------------------------------------

  Platform and Driver Issues

  ----------------------------------------------------------------------------

  3.1 What's the difference between ODBC and DBI?

  Good question! To be filled in more detail!

  ----------------------------------------------------------------------------

  3.2 Is DBI supported under Windows 95 / NT platforms?

  Finally, yes! Jeff Urlwin has been working diligently on building DBI and
  DBD::Oracle under these platforms, and, with the advent of a stabler perl
  and a port of MakeMaker, the project has come on by great leaps and bounds.

  The DBI and DBD::Oracle Win32 ports are now a standard part of DBI, so,
  downloading DBI of version higher than 0.81 should work fine. For the
  DBD::Oracle patches required, please read the Win32 porting page at:

      http://www.hermetica.com/technologia/perl/DBI/win32

  ----------------------------------------------------------------------------

  3.3 Can I access Microsoft Access or SQL-Server databases with DBI?

      Contributed by Tim Bunce and Jeff Urlwin

  Supplied with DBI-0.79 ( and later ) is an experimental DBI 'emulation
  layer' for the Win32::ODBC module. It's called DBI::W32ODBC and is, at the
  moment, very minimal. You will need the Win32::ODBC module available from:

      http://www.roth.net

  Given its status, problem reports without fixes are likely to be ignored.
  You will also need the Win32 DBI patch kit as supplied by Jeff Urlwin, which
  you can locate by reading the previous question's answer.

  Jeff Urlwin is currently working hard on the ODBC layer.

  To get back to the question, theoretically, yes, you can access Microsoft
  Access and SQL-Server databases from DBI via ODBC!

  ----------------------------------------------------------------------------

  3.4 Is the a DBD for <insert favourite database here>?

  Is is listed on the DBI drivers page?

      http://www.hermetica.com/technologia/perl/DBI/DBD

  If not, no. A complete absence of a given database driver from that page
  means that no-one has announced any intention to work on it.

  A corollary of the above statement implies that if you see an announcement
  for a driver not on the above page, there's a good chance it's not actually
  a DBI driver, and may not conform to the specifications. Therefore,
  questions concerning problems with that code should not really be addressed
  to the DBI Mailing Lists.

  ----------------------------------------------------------------------------

  3.5 What's DBM? And why should I use DBI instead?

  Extracted from ``DBI - The Database Interface for Perl 5'':

      ``UNIX was originally blessed with simple file-based ``databases'', namely
      the dbm system. dbm lets you store data in files, and retrieve
      that data quickly. However, it also has serious drawbacks.

          File Locking

          The dbm systems did not allow particularly robust file locking
          capabilities, nor any capability for correcting problems arising through
          simultaneous writes [ to the database ].

          Arbitrary Data Structures

          The dbm systems only allows a single fixed data structure:
          key-value pairs. That value could be a complex object, such as a
          [ C ] struct, but the key had to be unique. This was a large
          limitation on the usefulness of dbm systems.

      However, dbm systems still provide a useful function for users with
      simple datasets and limited resources, since they are fast, robust and
      extremely well-tested. Perl modules to access dbm systems have now
      been integrated into the core Perl distribution via the
      AnyDBM_File module.''

  To sum up, DBM is a perfectly satisfactory solution for essentially
  read-only databases, or small and simple datasets. However, for more
  powerful and scaleable datasets, not to mention robust transactional
  locking, users are recommended to use DBI.

  ----------------------------------------------------------------------------

  3.6 When will mSQL-2 be supported?

  As of DBD::mSQL-0.61, there has been support for mSQL-2. However, there is
  no real support for any of the new methods added to the core mSQL library
  regarding index support yet. These are forthcoming and will be accessible
  via func methods private to DBD::mSQL. You can read more about these private
  methods in the DBD::mSQL POD that can be found by typing:

      perldoc DBD::mSQL

  provided you have DBD::mSQL correctly installed.

  ----------------------------------------------------------------------------

  3.7 What database do you recommend me using?

  This is a particularly thorny area in which an objective answer is difficult
  to come by, since each dataset, proposed usage and system configuration
  differs from person to person.

  From the current author's point of view, if the dataset is relatively small,
  being tables of less than 1 million rows, and less than 1000 tables in a
  given database, then mSQL is a perfectly acceptable solution to your
  problem. This database is extremely cheap, is wonderfully robust and has
  excellent support. More information is available on the Hughes Technology
  WWW site at:

      http://www.hughes.com.au

  If the dataset is larger than 1 million row tables or 1000 tables, or if you
  have either more money, or larger machines, I would recommend Oracle7 RDBMS.
  Oracle's WWW site is an excellent source of more information.

      http://www.oracle.com

  Informix is another high-end RDBMS that is worth considering. There are
  several differences between Oracle and Informix which are too complex for
  this document to detail. Information on Informix can be found on their WWW
  site at:

      http://www.informix.com

  In the case of WWW fronted applications, mSQL may be a better option due to
  slow connection times between a CGI script and the Oracle RDBMS and also the
  amount of resource each Oracle connection will consume. mSQL is lighter
  resource-wise and faster.

  These views are not necessarily representative of anyone else's opinions,
  and do not reflect any corporate sponsorship or views. They are provided
  as-is.

  ----------------------------------------------------------------------------

  3.8 Is <insert feature here> supported in DBI?

  Given that we're making the assumption that the feature you have requested
  is a non-standard database-specific feature, then the answer will be no.

  DBI reflects a generic API that will work for most databases, and has no
  database-specific functionality.

  However, driver authors may, if they so desire, include hooks to
  database-specific functionality through the func method defined in the DBI
  API. Script developers should note that use of functionality provided via
  the func methods is unlikely to be portable across databases.

  ----------------------------------------------------------------------------

  Programming Questions

  ----------------------------------------------------------------------------

  4.1 Is DBI any use for CGI programming?

  In a word, yes! DBI is hugely useful for CGI programming! In fact, I would
  tentatively say that CGI programming is one of two top uses for DBI.

  DBI confers the ability to CGI programmers to power WWW-fronted databases to
  their users, which provides users with vast quantities of ordered data to
  play with. DBI also provides the possibility that, if a site is receiving
  far too much traffic than their database server can cope with, they can
  upgrade the database server behind the scenes with no alterations to the CGI
  scripts.

  ----------------------------------------------------------------------------

  4.2 How do I get faster connection times with DBD::Oracle and CGI?

      Contributed by John D. Groenveld

  The Apache httpd maintains a pool of httpd children to service client
  requests.

  Using the Apache mod_perl module by Doug MacEachern, the perl interpreter is
  embedded with the httpd children. The CGI, DBI, and your other favorite
  modules can be loaded at the startup of each child. These modules will not
  be reloaded unless changed on disk.

  For more information on Apache, see the Apache Project's WWW site:

      http://www.apache.org

  The mod_perl module can be downloaded from CPAN via:

      http://www.perl.com/cgi-bin/cpan_mod?module=mod_perl

  ----------------------------------------------------------------------------

  4.3 How do I get persistent connections with DBI and CGI?

      Contributed by John D. Groenveld

  Using Edmund Mergl's Apache::DBI module, database logins are stored in a
  hash with each of these httpd child. If your application is based on a
  single database user, this connection can be started with each child.
  Currently, database connections cannot be shared between httpd children.

  Apache::DBI can be downloaded from CPAN via:

      http://www.perl.com/cgi-bin/cpan_mod?module=Apache::DBI

  ----------------------------------------------------------------------------

  4.4 ``When I run a perl script from the command line, it works, but, when I
  run it under the httpd, it fails!'' Why?

  Basically, a good chance this is occurring is due to the fact that the user
  that you ran it from the command line as has a correctly configured set of
  environment variables, in the case of DBD::Oracle, variables like
  $ORACLE_HOME, $ORACLE_SID or TWO_TASK.

  The httpd process usually runs under the user id of nobody, which implies
  there is no configured environment. Any scripts attempting to execute in
  this situation will correctly fail.

  To solve this problem, set the environment for your database in a BEGIN ( )
  block at the top of your script. This will solve the problem.

  Similarly, you should check your httpd error logfile for any clues, as well
  as the ``Idiot's Guide To Solving Perl / CGI Problems'' and ``Perl CGI
  Programming FAQ'' for further information. It is unlikely the problem is
  DBI-related.

  The ``Idiot's Guide To Solving Perl / CGI Problems'' can be located at:

      http://www.perl.com/perl/faq/index.html

  as can the ``Perl CGI Programming FAQ''. Read BOTH these documents
  carefully!

  ----------------------------------------------------------------------------

  5.1 Can I do multi-threading with DBI?

  As of the current date of this FAQ ( see top of page ), no. perl does not
  support multi-threading. However, multi-threading is expected to become part
  of the perl core distribution as of version 5.005, which implies that DBI
  may support multi-threading fairly soon afterwards.

  For some OCI example code for Oracle that has multi-threaded SELECT
  statements, see:

      http://www.hermetica.com/technologia/oracle/oci/orathreads.tar.gz

  ----------------------------------------------------------------------------

  5.2 How do I handle BLOB data with DBI?

  To be written.

  ----------------------------------------------------------------------------

  5.3 How can I invoke stored procedures with DBI?

  Assuming that you have created a stored procedure within the target
  database, eg, an Oracle database, you can use $dbh->do to immediately
  execute the procedure. For example,

      $dbh->do( "BEGIN someProcedure END" );

  ----------------------------------------------------------------------------

  5.4 How can I get return values from stored procedures with DBI?

      Contributed by Jeff Urlwin

      $sth = $dbh->prepare( "BEGIN foo(:1, :2, :3); END;" );
      $sth->bind_param(1, $a);
      $sth->bind_param_inout(2, \$path, 2000);
      $sth->bind_param_inout(3, \$success, 2000);
      $sth->execute;

  Remember to perform error checking, though!

  ----------------------------------------------------------------------------

  5.5 How can I create or drop a database with DBI?

  Database creation and deletion are concepts that are entirely too abstract
  to be adequately supported by DBI. For example, Oracle does not support the
  concept of dropping a database at all! Also, in Oracle, the database server
  essentially is the database, whereas in mSQL, the server process runs
  happily without any databases created in it. The problem is too disparate to
  attack.

  Some drivers, therefore, support database creation and deletion through the
  private func methods. You should check the documentation for the drivers you
  are using to see if they support this mechanism.

  ----------------------------------------------------------------------------

  5.6 How can I commit or rollback a statement with DBI?

  To be written.

  ----------------------------------------------------------------------------

  5.7 How are NULL values handled by DBI?

  NULL values in DBI are specified to be treated as the value undef. NULLs can
  be inserted into databases as NULL, for example:

      $rv =
          $dbh->do( "INSERT INTO table VALUES( NULL )" );

  but when queried back, the NULLs should be tested against undef. This is
  standard across all drivers.

  ----------------------------------------------------------------------------

  5.8 What are these func methods all about?

  The func method is defined within DBI as being an entry point for
  database-specific functionality, eg, the ability to create or drop
  databases. Invoking these driver-specific methods is simple, for example, to
  invoke a createDatabase method that has one argument, we would write:

      $rv =
          $dbh->func( 'argument', 'createDatabase' );

  Software developers should note that the func methods are non-portable
  between databases.

  ----------------------------------------------------------------------------

  Support and Training

  The Perl5 Database Interface is FREE software. IT COMES WITHOUT WARRANTY OF
  ANY KIND.

  However, some organizations are providing either technical support or
  training programs on DBI. The present author has no knowledge as to the
  quality of these services. The links are included for reference purposes
  only.

  ----------------------------------------------------------------------------

  Commercial Support

  The Perl Clinic
       The Perl Clinic can arrange commercial support contracts for Perl, DBI,
       DBD::Oracle and Oraperl. Support is provided by the company with whom
       Tim Bunce, author of DBI, works. For more information on their
       services, please see:

           http://www.perl.co.uk/tpc

       for more details.

  ----------------------------------------------------------------------------

  Training

  No training programs are known at this time.

  ----------------------------------------------------------------------------

  Other References

  In this section, we present some miscellaneous WWW links that may be of some
  interest to DBI users. These are not verified and may result in unknown
  sites or missing documents.

      http://www-ccs.cs.umass.edu/db.html
      http://www.odmg.org/odmg93/updates_dbarry.html
      http://www.jcc.com/sql_stnd.html

  ----------------------------------------------------------------------------

  AUTHOR

  Alligator Descartes <descarte@hermetica.com>

  ----------------------------------------------------------------------------
  Reproduced here by permission from Alligator Descartes Hermetica
  ----------------------------------------------------------------------------

  13.  PostgreSQL Management Tools

  13.1.  PGACCESS - A GUI Tool for PostgreSQL Management

  It is already included in the distribution of PostgreSQL.  You may
  want to check out this web site for a newer copy

  ·  <http://www.flex.ro/pgaccess>

  ·  If you have any comment, suggestion for improvements, please feel
     free to e-mail to : teo@flex.ro

  This is what the home page of pgaccess says:

  PgAccess - a Tcl/Tk interface to PostgreSQL

  ---------------------------------------------------------------------------
  Latest version of PgAccess is 0.63 , 4 December 1997

  I think that there were some problems loading libpgtcl library.
  I invite you to read a special section concerning libpgtcl

  What does PgAccess now!

  Here are some images from PgAccess windows : Main window , table builder ,
  table(query) view , visual query builder .

  Tables
  - opening tables for viewing, max 200 records (changed by preferences menu)

  - column resizing, dragging the vertical grid line (better in table space
  rather than in the table header)
  - text wrap in cells - layout saved for every table
  - import/export to external files (SDF,CSV)
  - filter capabilities (enter filter like (price>3.14)
  - sort order capabilities (enter manually the sort field(s))
  - editing in place
  - improved table generator assistant
  - improved field editing
  Queries
  - define , edit and stores "user defined queries"
  - store queries as views
  - execution of queries
  - viewing of select type queries result
  - query deleting and renaming
  - NEW !!! Visual query builder with drag & drop capabilities. For any of
  you who had installed the Tcl/Tk plugin for Netscape Navigator, you can see
  it at work clicking here
  Sequences
  - defines sequences, delete them and inspect them
  Functions
  - define, inspect and delete functions in SQL language

  On the TODO list!
  - table design (add new fields, renaming, etc.)
  - function definition
  - report generator
  - basic scripting

  If you have any comment, suggestion for improvements, please feel free to
  e-mail to : teo@flex.ro
  ---------------------------------------------------------------------------

  More information about libgtcl

  Also, you will need the PostgreSQL to Tcl interface library, lined as a
  Tcl/Tk 'load'-able module. It is called libpgtcl and the source is located
  in the PostgreSQL directory /src/interfaces/libpgtcl. Specifically, you
  will need a libpgtcl library that is 'load'-able from Tcl/Tk. This is
  technically different from an ordinary PostgreSQL loadable object file,
  because libpgtcl is a collection of object files. Under Linux, this is
  called libpgtcl.so.
  You can download from here a version already compiled for Linux i386
  systems. Just copy libpgtcl.so into your system library director (/usr/lib)
  and go for it. One of the solutions is to remove from the source the line
  containing load libpgtcl.so and to load pgaccess.tcl not with wish, but
  with pgwish (or wishpg) that wish that was linked with libpgtcl library.

  However, the application should work without problems.
  13.2.  Windows Interactive Query Tool for PostgreSQL (WISQL or MPSQL)

  MPSQL provides users with a graphical SQL interface to PostgresSQL.
  MPSQL is similar to Oracle's SQL Worksheet and Microsoft SQL Server's
  query tool WISQL.  It has nice GUI and has history of commands. Also
  you can cut and paste and it has other nice features to improve your
  productivity.

  ·  <http://www.troubador.com/~keidav/index.html>

  ·  Email: keidav@whidbey.com

  ·  <http://www.ucolick.org/~de/> in file tcl_syb/wisql.html

  ·  <http://www.troubador.com/~keidav/index.html>

  ·  Email: de@ucolick.org

  13.3.  Interactive Query Tool (ISQL) for PostgreSQL called PSQL

  ISQL is For Character command line terminals.  This is included in the
  distribution, and is called PSQL. Very similar to Sybase ISQL, Oracle
  SQLplus. At unix prompt give command 'psql' which will put you in
  psql> prompt.

       Type \h to see help of commands.

  Very user friendly and easy to use. Also very useful for shell script­
  ing in Bourne, Korn and C-shells.

  13.4.  MPMGR - A Database Management Tool for PostgresSQL

  MPMGR will provide a graphical management interface for PostgresSQL.
  You can find it at

  ·  <http://www.troubador.com/~keidav/index.html>

  ·  Email: keidav@whidbey.com

  ·  <http://www.ucolick.org/~de/> in file tcl_syb/wisql.html

  ·  <http://www.troubador.com/~keidav/index.html>

  ·  Email: de@ucolick.org

  14.  Setting up multi-boxes PostgreSQL with just one monitor

  You can stack up the cpu-boxes and connect to just one monitor and use
  the switch box to select the host. This saves space and you eliminate
  monitor(200 US dollars), keyboard(60 dollars) and the mouse(50
  dollars) and also avoid lot of clutter.

  Please check out these sites:

  ·  Network Technologies Inc
     <http://www.networktechinc.com/servswt.html> (120 dollars/PC 8
     ports) which lists

  ·  Scene Double Inc, England
     <http://www.scene.demon.co.uk/qswitch.htm>

  ·  Cybex corporation  <http://www.cybex.com>

  ·  Raritan Inc  <http://www.raritan.com>

  ·  RealStar Solutions Inc  <http://www.real-star.com/kvm.htm>

  ·  Belkin Inc  <http://www.belkin.com>

  ·  DataComm Warehouse Inc Call 24 hours a day, 7 days a week at
     1-800-328-2261They supply all varieties of computer hardware
     <http://www.warehouse.com>

  ·  Better Box Communications Ltd.
     <http://www.betterbox.com/info.html>

  ·  Go to nearest hardware store and ask for "Server Switch" also known
     as "KVM Auto Switches".

  Search engine yahoo to find more companies with "Server Switches" or
  "KVM Switches".

  It is strongly recommended to have a dedicated unix box for each
  PostgreSQL server process for better performance. No other application
  program/processes should run on this box. See the Business section of
  your local newspapers for local vendors selling only intel box, 13"
  monochrome monitor (very low cost monitor). Local vendors sell just
  the hardware WITHOUT any Microsoft Windows/DOS (saves you about $
  150).  You do not need a color monitor for the database server, as you
  can do remote administration from color PC workstation. Get Redhat
  Linux cdrom from below -

  ·  Linux System Labs Web site:   <http://www.lsl.com/>  7 (U.S.
     dollars)

  ·  Cheap Bytes Inc Web site:   <http://www.cheapbytes.com/> 7 (U.S.
     dollars)

     Make sure that the hardware you purchase is supported by Redhat
     Linux. Check the ftp site of Redhat for recommended hardware like
     SCSI adapters, video cards before buying.  For just $ 600 you will
     get a powerful intel box with Redhat Linux running PostgreSQL.  Use
     odbc/jdbc/perl/tcl to connect to PostgreSQL from Windows95, OS/2,
     Unix Motif or Netscape browser (Netscape is very fast becoming the
     standard client).

  To stack up cpu boxes, buy $ 15 floor-to-ceiling shelf and clamp it to
  the wall with several bracket clamps.  Also bolt it down to floor. The
  size of the shelf is such that it just fits the computer. Place Intel
  boxes such that the side is butting against the wall and the front and
  rear (serial ports, network port, power connections) are easily
  accessible. Follow rules of Ergonomics, the shelf should have enough
  gap on both sides and there should be enough gap between many tower
  shelves.  Bundle the wires neatly. Put vertical steel strips so that
  boxes do not fall off during earth-quakes. Floor to ceiling shelf will
  fit about 30 Intel-Linux boxes.  Thus a small room can fit about 10
  tower shelves with 300 cpu boxes controlled by just one monitor and
  one keyboard!!

  Below is the extract from networktechnic Inc for the "Server Switches"

  Order now call 800-742-8324 (toll free in USA)

  To receive our catalog please Email your address to: sales@networktechinc.com

  CONTROL MULTIPLE PC'S with one keyboard monitor & mouse
  These electronic switches will allow one
  keyboard, monitor & mouse to control up to 64
  PC's. Embedded microcomputers simulate the
  presence of keyboard, monitor & mouse to all
  attached PC's 100% of the time.

  Features and Applications

  * Keyboard, front panel or remote control
  * 9 pin D Serial or 6 pin miniDIN mouse support
  * 5 pin DIN or 6 pin miniDIN keyboard support
  * 1600x1200 video resolution with no degradation
  * Uses standard cables
  * Desktop or rackmount

  Specifications - Keyboard

  * All connectors are female
  * 5 pin DIN or 6 pin miniDIN
  * Will hard or soft boot all PC's 100% of the time

  Controls - Buttons on Front

  * Touch a button and be connected to that PC
  * Hold any button in for more than 0.5 second and go into SCAN, BROADCAST or COMMAND mode
  * LEDs on front indicate mode of operation Keyboard
  * Type CTRL+* and go into COMMAND mode
  * SCAN, BROADCAST or COMMAND are available

  Mouse

  * 9 pin D serial
          o NTI switch emulates Microsoft serial mouse to all PC's
          o 9 pin D male for mouse
          o 9 pin D female for PC's
  * 6 pin miniDIN
          o NTI switch emulates IBM PS/2 style mouse to all PC's
          o All connectors are female

  Wired remote

  * Optional--must be purchased
  * Operates same as "Buttons on Front"

  Tech Info

  * Request technical manual MAN025

  Monitor-VGA

  * Bandwidth is 150 MHz
  * 1600X1200 resolution with no degradation
  * All connectors are female

  Power

  * 110 or 220 VAC at 50 or 60 Hz

  15.  Problem/Project Tracking System Application Tool for PostgreSQL

  This is at

  ·  <http://www.homeport.org/~shevett/pts/>

  16.  Convert dbase dbf files to PostgreSQL

  The program dbf2msql works fine with mSQL and PostgreSQL. You can find
  it at

  ·  <ftp://ftp.nerosworld.com/pub/SQL/dbf2sql/>

  ·  <ftp://gopher.library.tudelft.nl/pub/misc/dbf2msql-0.4.tar.gz>

  ·  <ftp://ftp.postgresql.org/pub/incoming/dbf2pg-3.0.tar.gz>

  This program was written by Maarten Boekhold, Faculty of Electrical
  Engineering TU Delft, NL Computer Architecture and Digital Technique
  section M.Boekhold@et.tudelft.nl

  You can also use a python method to read dbf files and load into a
  postgres database.

  ·  See  <http://www.python.org>

  17.  PostgreSQL 4GL for web database applications - AppGEN Development
  System

  AppGEN can be downloaded from

  <http://www.man.ac.uk/~whaley/ag/appgen.html>

  <ftp://ftp.mcc.ac.uk/pub/linux/ALPHA/AppGEN>.

  Extract from the home page of AppGEN is given below:-

  AppGEN is a high level fourth generation language and application
  generator for producing World Wide Web (WWW) based applications. These
  applications are typically used over the internet or within a
  corporate intranet. AppGEN applications are implemented as C scripts
  conforming to the Common Gateway Interface (CGI) standard supported by
  most Web Servers.

  To use AppGEN you will need the following :-

  PostgresSQL, relational database management system

  A CGI compatible web server such as NCSA's HTTPD

  An ansi C compiler such as GCC

  AppGEN consists of the following Unix (Linux) executables :-

  ·  defgen, which produces a basic template application from a logical
     data structure. The applications are capable of adding, updating,
     deleting and searching for records within the database whilst
     automatically maintaining referential integrity.

  ·  appgen, the AppGEN compiler which compiles the appgen source code
     into CGI executable C source and HTML formatted documents ready for
     deployment on a web server.

  ·  dbf2sql, a utility fo converting dBase III compatible .dbf files
     into executable SQL scripts. This enables data stored in most
     DOS/Windows based database packages to be migrated to a SQL server
     such as PostgresSQL.

  ·  In addition, AppGEN comprises of a collection of HTML documents,
     GIF files and Java applets which are used at runtime by the system.
     And of course, like all good software, the full source code is
     included.

  The author, Andrew Whaley, can be contacted on
  andrew@arthur.smuht.nwest.nhs.uk and would appreciate any comments or
  suggestions about the software.

  18.  Web Database Design/Implementation tool for PostgreSQL - EARP

  <http://www.oswego.edu/Earp>

  <ftp://ftp.oswego.edu> in the directory 'pub/unix/earp'.

  The extract from the home page of EARP is given below:-

  The "Easily Adjustable Response Program" (EARP) created by David
  Dougherty

  18.1.  What is EARP ?

  EARP is a Web Database Design/Implementation tool, built on top of the
  PostgreSQL database system. Its functionality includes:

  ·  A Visual Design System.

  ·  A sendmail interface. (can handle incoming and outgoing mail)

  ·  An Enhanced Security Mechanism.

  ·  A cgi driver.

  18.2.  Implementation

  The main implementation of EARP is a CGI binary which runs under the
  http daemon to provide access to the database server. All of the
  design tools are built into the driver, no design takes place over
  anything but the web. The tools themselves require a graphical
  browser, the compatibility of objects designed with the tools is
  implementation independent, based on designing individuals
  preferences.

  18.3.  What you need to run EARP

  EARP will likely run on a variety of platforms with little or no
  porting. The known working platforms consist of the following:

  ·  Solaris 2.5

  ·  Linux 1.2.13+

  ·  GNU C++

  ·  PostgreSQL (Version 1.01 / 1.02 )

  ·  netsite server

  ·  NCSA httpd

  ·  GNU C++

  ·  PostgreSQL (Version 1.01 / 1.02 )

  ·  NCSA httpd

  ·  Apache httpd

  18.4.  News Flash

  The current (1.3) release of Earp was designed on top of the libpq
  release that came with PostgreSQL v1.01/1.02.  If you are using a more
  recent version of Postgres, expect that the program will require some
  porting to work correctly. In the development version (Earp 2.0),
  libpq support is being incorporated as a module, and thus will support
  as many versions of postgres as we have time to write the modules. The
  development release is expected to become public near mid-spring(97).

  18.5.  How does it work ?

  One of the main features of EARP is that it uses an Object Oriented
  approach to producing html pages which interface to the database. Most
  pages will consist of several objects. Each object is produced by some
  sort of tool and given a name, objects are then linked together in a
  callable sequence by the page tool. Objects are also reusable across
  multiple pages.  Basic tools exist for HTML, Querys, Grabbing input
  from forms, Extendable Formatting of Query and Input objects, and
  Linking together of objects into other objects. More advanced tools
  include the mail tool and the multithreaded query tool.

  Another feature of EARP is advanced security. Access to various areas
  of the EARP system can be limited in a variety of ways. To facilitate
  its advanced security, EARP performs checks for each connection to the
  system, determining what ids and groups the connecting agent belongs
  to. Access to areas is defined seperately, and the combination decides
  if access to a specific area of Earp is allowed. Moreover, all that is
  required to implement the security features is an http server that
  supports basic (or better) user authentication.

  18.6.  Some online examples

  As part of the ICC Help Database, the Catalog Search Page is an EARP
  document which runs several queries.  The selection boxes are
  generated by the EARP program from listings in the database.

  As another example of what can be done using EARP... now you can look
  at the List of Objects in the Help Database.

  Creating the three interfaces for the link took me less than 15
  minutes.

  18.7.  Where do I get it ?

  EARP is available via anonymous ftp from  <ftp://ftp.oswego.edu> in
  the directory 'pub/unix/earp'. The version as of this writing is 1.3.1

  Please, once you've retrieved EARP and gotten it to work, drop me a
  line and tell me your success or failure story.

  18.8.  Available Documentation

  All documentation has been moved to the User Docs and Tutorials index
  page.

  18.9.  A History of EARP

  Earp 0.1 began in Fall of 1995 as program I was working on to build a
  dynamically configurable web accessable guest book.  At that point it
  was a bunch of cgi programs that all did different but useful things
  and were held together with SSI glue, and a little sneaky c
  programming. What I soon realized though is that I was doing a lot of
  repetitive work, and that most of what I was doing had to be run in
  many windows at once (netscape, emacs, shell, mail) for it to make any
  sense, and that debugging was quickly becoming a nightmare. At that
  time I was also being approached by my friend and boss Don Michaels,
  who was interested in automating a large hunk of our user support, and
  keeping a historical database of requests and responses.

  Soon, I had worked out the initial scheme for what is now quickly
  becoming our help database, only I balked at the idea of building a
  help database with what was at that point a very primitive set of
  utilities. When spring classes were occurring(96) I started it anyway,
  mainly out of boredom, but also because I was in a database design
  class and a wanted to flex a few brain muscles. After a while I had a
  reasonable prototype up and running, which made Don very happy as he
  had basically given up on the idea of anyone every really creating a
  help database for him. (The prototype is still running on one of my
  servers...(june96)) The prototype did some very interesting things,
  but by april I was again getting discouraged... Everytime I wanted to
  change something, I had to go through a lengthy process of
  recompilation, or find an entry in a text file full of distractions.
  Also, there was no way for me to use the building block idea which is
  so useful in EARP... I did a lot of huge cutting and pasting. About
  the time that classes where ending I had again given up on the current
  scheme of things, and decided that what I needed was a better set of
  tools for what I was doing. Additionally, I also wanted to make my
  prototype work on top of a REAL relational database, and I wasn't
  cherishing the idea of reworking all those hard coded accesses, links,
  and output methods.

  I had a break for a short while, if you want to call it that. We
  sponsored the SUNY CIT Conference and I was so busy for about a week
  and a half that I got distanced from most of what I had written for
  the prototype help database, except the ideas I had had when I wrote
  the initial series of utilities, and what my biggest peeves were about
  the current state of things.

  Shortly after the conference, I began the prototype for the current
  version of EARP(may96), using the postgreSQL database as my relational
  backend. By the middle of June, the prototype had evolved into a
  fairly nice integrated suite of tool prototypes, with the primary
  advantage that they all ran over html, and stored their initialization
  information in the database. Most of the second half of june was spent
  debugging and working out the kinks in the code, and playing with the
  interface.( within those two weeks I accessed our web server over 5000
  times.) By the end of June I had most of the major bugs blasted out of
  EARP, and a large enough number of objects in the "new" help database
  to officially announce it to our help support staff.

  Incidentally, I also kept a journal during the development of EARP,
  and myself and Don Michaels are presenting a paper describing the Help
  Database at the Chicago ACM/SIGUCCS conference in September of this
  year.

  19.  WWW Web interface for PostgresSQL - DBENGINE

  <http://www.cis-computer.com/dbengine/ >

  dbengine a plug 'n play Web interface for PostgreSQL created by Ingo
  Ciechowski

  The extract from the home page of dbengine is given below:-

                                   dbengine

                              [CGI-Forum Webring]

                  a plug 'n play Web interface for Postgres95

  Version 0.82 alpha
  Documentation as of 08/11/97
  Written by Ingo Ciechowski
  ---------------------------------------------------------------------------

  About dbengine

  dbengine is an interface between the WWW and Postgres95 which provides
  simple access to any existing database within just a few minutes.

  This little Perl program was born after I've tried quite a lot of already
  available packages like AppGen, PHP-FI and more. So why did I kind of
  re-invent the wheel ?

  Well, PHP-FI gives you a Perl like language in your documents, but no real
  Perl while AppGen and wdb-p95 require that you create some configuration
  file for each of your databases -- sound's like you'll first of all have to
  learn some sort of new mata language before you can get started.

  That was the point when I started to feel more familiar with a small Perl
  applet of my own... and now my dbengine became a tool that I think at is
  ready to be shared with others.

  Unlike other tools you don't have to learn any special programming or
  scripting language to get started with dbengine. Also there's no
  configuration file for each database, so you don't have to get familiar
  with such a new structure.
  However - in case you want to gain access to the full features of dbengine
  it'd be a good idea to know the Perl language.

  The whole system can be configured by simple manipulations of an additional
  database that contains closer information about how to visualize your
  database access.
  You can even specify virtual Fields which are calculated on the fly right
  before they're displayed on the screen.

  Screenshots

     * Tablelist view with connected databases (104k)
     * Record view with related record list out of seperate table (100k)

  License

  dbengine is free software under the same terms as Perl. Read its licence if
  you aren't sure what you can or can't do. The bottom line is that this is a
  kinder and gentler version of the GNU licence -- one that doesn't infect
  your work if you care to borrow from dbengine or package up pieces of it as
  part of a commercial product!

  more information...

  If you're interested in closer information about dbengine, use these links:

     * how to install dbengine
     * how to configure the package
     * working with dbengine
     * description database
     * template files

  If you need any additional information, please feel free to send me an
  E-Mail .
  And of course there's still the well documented Perl source code that could
  help you to find your way ;-)

  ---------------------------------------------------------------------------
       last update of this page: 08/11/97
  ---------------------------------------------------------------------------

  20.  Apache Webserver Module for PostgreSQL - NeoSoft NeoWebScript

  Apache is a well-known Web Server. And a module to interface
  PostgreSQL to Apache Webserver is at -
  <http://www.neosoft.com/neowebscript/>

  The extract from the home page of NeoWebScript is given below:-

  NeoWebScript is a programming language that allows both simple and
  complex programs to be embedded into HTML files.

  When an HTML page containing embedded NeoWebScript is requested, the
  NeoWebScript-enabled webserver executes the embedded script(s),
  producing a webpage containing customized content created by the
  program.

  NeoWebScript is a fast, secure, easy to learn way to do powerful,
  server-based interactive programming directly in the HTML code in web
  pages. With NeoWebScript, counters, email forms, graffiti walls, guest
  books and visitor tracking are all easy, even for a beginning
  programmer. See how well NeoWebScript holds its' own vs. PERL and
  JavaScript.

  NeoWebScript 2.2 just released!  On June 24, 1997, NeoSoft released
  NeoWebScript 2.2, integrating it with the new Apache 1.2.0 server.

  If you're on a webserver that has NeoWebScript installed and you would
  like to started with it, we have a lot of User Info available.  Our
  New User FAQ has the basic answers to get you started. The Tutorials
  guide you through learning the language, while the Demos give you
  prebuilt applications you can download and modify.  Commands and
  Variables are the complete language references, and Troubleshooting
  contains hints and tips to help you get past any problems.

  If you'd like to install NeoWebScript on your webserver, your
  Webmaster needs to read our Sysop FAQ to get started. Theory of
  Operations will explain how NeoWebScript works, while installation
  will take them through the steps. Management deals with configuration
  issues and running the server, tests let you verify correct
  NeoWebScript operation, and troubleshooting deals with server
  problems.

  Hey, wait a minute you ask, how much do you want for all this great
  software, huh? There is no cost to you to use NeoWebScript-2.2 for
  your ISP, your intranet, or your extranet.  You'll see a full license
  when you register to download, but the gist is we'd like a whopping $
  99 if you want to embed it in your own product or use it in a commerce
  (eg. SSL) server.

  NeoWebScript is a module for the Apache webserver that allows you to
  embed the Tcl/Tk programming language in your webpages as a scripting
  tool. It was invented by Karl Lehenbauer, NeoSoft's Chief Technical
  Officer, and documented, enhanced and extended by NeoSoft's
  programmers and technical writers.

  The Apache webserver is the world's most popular webserver, accounting
  for 42 % of the 1,044,163 sites polled by the May 1997 Netcraft Web
  Server survey. The next largest entry were the various Microsoft
  servers, reporting in with slightly over 16 %, or a difference of over
  270,000 servers.

  Tcl/Tk is the powerful, free, cross-platform scripting language
  developed by Dr. John Ousterhout, now a Sun Distinguished Engineer. In
  his own words

  "Tcl/Tk lets software developers get the job done ten times faster
  than with toolkits based on C or C++. It's also a great glue language
  for making existing applications work together and making them more
  graphical and Internet-aware."

  With a developer community of over 500,000 worldwide, and thousands of
  commercial applications, Sun has just announced a new business group
  called SunScript, to support this community with an integrated
  development environment and to develop a suite of products to link Tcl
  to the Web and Java.

  Karl Lehenbauer, Founder and Chief Technical Officer of NeoSoft, has
  been part of Tcl/Tk development from the very beginning.  Together
  with Mark Diehkans, they authored Extended Tcl, also known as TclX or
  NeoSoft Tcl, a powerful set of extensions to the language. Many of the
  current core Tcl commands originated in Extended Tcl, and were then
  imported into the core language by Dr.  Ousterhout.

  NeoSoft Inc., 1770 St. James Place, Suite 500, Houston, TX 77056 USA

  21.  HEITML server side extension of HTML and a 4GL language for Post­
  greSQL

  Tool heitml is another way to interface postgres with the world wide
  web.  For more details contact

                 Helmut Emmelmann H.E.I. Informationssyteme GmbH
                 Wimpfenerstrasse 23 Tel. 49-621-795141
                 68259 Mannheim Germany Fax. 49-621-795161

  ·  E-mail Mr.Helmut Emmelmann at emmel@h-e-i.de

  ·  Heitml main web site  <http://www.heitml.com>

  ·  Heitml secondary web site  <http://www.h-e-i.deom>

  heitml is a server side extension of HTML and a 4GL language at the
  same time. People can write web applications in the HTML style by
  using new HTML-like tags.

  heitml (pronounced "Hi"-TML) is an extension of HTML and a full-
  featured 4th generation language that enables Web-based Applications
  to interact with data stored in SQL databases, without resorting to
  complex CGI scripts.

  heitml extends HTML on the sever side, dynamically converting ".hei"
  files to HTML format and so is compatible with any web browser.It
  embraces the familiar, easy-to-use HTML syntax and provides a large
  assortment of pre-developed Tags and Libraries to take care of tasks
  that formerly required CGI. As XML, heitml provides user defined tags.
  With heitml the user defined markup can be translated to HTML and send
  to a browser.

  heitml targets both HTML designers and professional programmers alike.
  HTML designers can use heitml Tags to build dynamic web pages, access
  SQL databases, or create complete web applications. Counters,
  registration databases, search forms, email forms, or hierarchical
  menues can all be created simply by using the pre-developed HTML-like
  Tags found in the many Component Libraries.

  For programmers heitml embeds a complete forth generation language in
  HTML

                 (e.g. <if>, <while>, and <let> Tags),

  plus powerful expression evaluation with integer, real, boolean,
  string, and tuple data types. Tuples have reference semantics as in
  modern object oriented languages and are stored on a heap. heitml
  variables including all complex data structures stored on the heap
  maintain their values between pages using the Session Mode. It is pos­
  sible to define your own tags or environment tags and even re-define
  HTML-tags.

  heitml makes it possible to

  - - - develop Web Sites in a structured and modular way, drastically
  reducing maintenance overhead.

  - - - develop intelligent and interactive Web Sites, with content that
  dynamically adapts itself to user needs.

  - - - show the content of SQL databases with no programming other than
  to use our library of prefined "dba" Tags.

  - - - develop complex database and Catalog Shopping applications using
  Session Variables

  heitml runs on Linux with any Web Server using the CGI interface, and
  is especially fast (avoiding the CGI overhead) within the APACHE
  (version 1.1.1, 1.1.3, or 1.2.4) Web Server using the apache API.
  Currently MSQL (Version 1 and 2), PostgreSQL (Version 6), mysql, and
  the yard databases are supported). heitml also works on Linux, BSDi,
  Solaris and SunOS, as well as Windows NT with CGI and ISAPI and ODBC
  and Windows 95.
  heitml (on linux) is free for research, non-commercial and private
  usage. Commercial Web Sites must pay a licensing fee. The fully
  operational version of heitml is available for a trial period
  downloaded freely. (Note, however, that each ".hei" Web Page you
  develop will display a message identifying it as the version for non-
  commercial use. After registration, you will receive a key to switch
  off the message without having to re-install the program.)

  New features in version 1.2 are

  - - - Component Libraries for Database Search Forms, opening and
  closing hierachical menus, and email forms

  - - - Session Mode has been re-designed and enhanced to keep all
  variables (including the entire heap) between pages. This means data
  of any size can be kept within a session. This opens up the
  opportunity for a wider range of new applications, e.g. storing
  complete query results in session memory.

  - - - Installation instructions, documentation and example libraries
  have been significantly improved, a Tutorial has been added

  - - - Tags to execute shell commands and send emails have been added

  - - - Pretty Printing and debugging support. heitml shows your source
  code in color in your browser and marks errors in an intuitive way. In
  the case of runtime errors, all internal data structures are displayed
  in the browser marking and preserving the original source code
  positions.

  - - - Various new server variables and built-in functions have been
  added

  - - - In production mode heitml now collects complete information on
  errors that occurred while people were accessing your site.

  This is what the home page of the heitml says -

  heitml (pronounced "Hi"-TML) significantly extends and enhances the
  functionality of HTML by definable tags and full programming features.
  This makes dynamic content and database applications possible simply
  within the HTML world, without CGI and without external scripting or
  programming languages.  This means you, as an HTML author, can embed
  applications in your web pages, simply by using some new tags without
  CGI and without programming. As an advanced user or programmer on the
  other hand you can create and program powerful tag libraries. This
  approach makes heitml suitable for HTML newcomers and professional
  programmers alike.  heitml runs on the web server and dynamically
  generates HTML, so heitml is compatible with the internet standards
  and with any web browser. It allows full access to databases while
  shielding the user from any unneccessary CGI complexity. heitml has
  been developed according to the newst research and in compiler
  construction and transaction systems.

  heitml pages are developed just the same way as HTML pages, with a
  text editor or HTML editor, and placed on the web server as usual.
  However now pages can contain dynamic heitml tags and access tag
  libraries.  You can use these tags to access the database, to create
  dynamic content, to send emails, and even to create powerful
  applications like registration databases and shopping systems.

  HTML newcomers and professional programmers alike will be amazed at
  how quickly and easily they can design exciting applications like our
  Interactive Guestbook without resorting to complex and difficult to
  learn CGI scripts, simply by using the tools provided in our dba
  Library.

  heitml is accompanied by a wide range of tag libraries, to create
  guestbooks, database maintenance applications, extensible query forms,
  powerful email forms or structure your web site using a hierarchic
  menu. These tools are ready to go, just add the corresponding tags to
  your web site.

  As an experienced programmer you can make fully use of the heitml
  persistent dynamic tuple architecture : heitml is not just a scripting
  language with dynamic typing, full power expression evaluation,
  recursive procedures and extensive parameter passing features, but it
  also features persistent dynamic tuples to automatically keep session
  data of any size.

  heitml has so many features and uses it is impossible to describe it
  in a single Web Page. For that reason we have set up this Web Site in
  a manner that allows you to obtain a simple product "overview", or to
  delve as deeply as you want into the "nuts and bolts" of the language.
  Whichever manner you choose, we think you'll find that heitml has a
  lot to offer, and we hope you'll agree that it truly "takes the World
  Wide Web to a Higher Level!"

  The menu on the left-hand side of the screen will help you navigate
  our Web Site in an organized and methodical manner, but you can also
  use our Quick Menu to instantly jump to any page with a single mouse-
  click.

  If you're a first-time visitor to this Site, we suggest that you check
  out the heitml Interactive Guestbook for a truly impressive
  demonstration of how heitml can make your Web Pages more Interactive.
  If you sign our Guestbook, you can leave comments or tell us about
  your favorite Web Site using HTML formatting commands. It's like
  creating your own private Web Page and seeing it published
  immediately!

  The heitml Features section provides a Quick Summary of Features and
  Benefits, as well as Pages that are tailored to address the specific
  needs and questions of Designers and Programmers Our Language Guide
  provides an on-line tutorial that demonstrates in a practical manner
  some of the ways you can use heitml to develop, enhance and simplify
  your Web Pages and Applications.

  The Language Reference is for those looking for specific information
  regarding the syntax, structure and use of the various language
  elements. However, it would be a good idea for everyone to read the
  General Design page, which provides an overview of the specific kinds
  of problems heitml is designed to solve.

  Naturally, you'll want to know whether heitml runs on the specifc
  Operating System, Web Server, or SQL database software you're
  currently using, and you'll find all that information in our Supported
  Platforms section.

  Finally, we invite you to Download a trial copy of the program for use
  on your own system. We know you'll appreciate this "try before you buy
  policy", and we look forward to any feedback you'd like to give us.

  22.  PHP/FI Server-side html-embedded scripting language for Post­
  greSQL

  WWW Interface Tool  <http://www.vex.net/php>

  Professional Home Pages (PHP)  <http://php.iquest.net/>

  Questions e-mail to : rasmus@lerdorf.on.ca

  The extract from the home page of PHP/FI is given below:-

  PHP/FI is a server-side html-embedded scripting language. It lets you
  write simple scripts right in your .HTML files much like JavaScript
  does, except, unlike JavaScript PHP/FI is not browser-dependant.
  JavaScript is a client-side html-embedded language while PHP/FI is a
  server-side language. PHP/FI is similar in concept to Netscape's
  LiveWire Pro product. If you have the money, you run Netscape's
  Commerce Server and you run one of the supported operating systems,
  you should probably have a look at LiveWire Pro. If you like free
  fast-moving software that comes with full source code you will
  probably like PHP/FI.

  22.1.  Major Features

  Standard CGI, FastCGI and Apache module Support As a standard CGI
  program, PHP/FI can be installed on any Unix machine running any Unix
  web server. With support for the new FastCGI standard, PHP/FI can take
  advantage of the speed improvements gained through this mechanism. As
  an Apache module, PHP/FI becomes an extremely powerful and lightning
  fast alternative to CGI programmimg.

  ·  Access Logging With the access logging capabilities of PHP/FI,
     users can maintain their own hit counting and logging. It does not
     use the system's central access log files in any way, and it
     provides real-time access monitoring. The Log Viewer Script
     provides a quick summary of the accesses to a set of pages owned by
     an individual user. In addition to that, the package can be
     configured to generate a footer on every page which shows access
     information. See the bottom of this page for an example of this.

  ·  Access Control A built-in web-based configuration screen handles
     access control configuration. It is possible to create rules for
     all or some web pages owned by a certain person which place various
     restrictions on who can view these pages and how they will be
     viewed. Pages can be password protected, completely restricted,
     logging disabled and more based on the client's domain, browser, e-
     mail address or even the referring document.

  ·  Postgres Support Postgres is an advanced free RDBMS. PHP/FI
     supports embedding Postgres95 and PostgreSQL SQL queries directly
     in .html files.

  ·  RFC-1867 File Upload Support File Upload is a new feature in
     Netscape 2.0. It lets users upload files to a web server. PHP/FI
     provides the actual Mime decoding to make this work and also
     provides the additional framework to do something useful with the
     uploaded file once it has been received.

  ·  HTTP-based authentication control PHP/FI can be used to create
     customized HTTP-based authentication mechanisms for the Apache web
     server.

  ·  Variables, Arrays, Associative Arrays PHP/FI supports typed
     variables, arrays and even Perl-like associative arrays. These can
     all be passed from one web page to another using either GET or POST
     method forms.

  ·  Conditionals, While Loops PHP/FI supports a full-featured C-like
     scripting language.  You can have if/then/elseif/else/endif
     conditions as well as while loops and switch/case statements to
     guide the logical flow of how the html page should be displayed.

  ·  Extended Regular Expressions Regular expressions are heavily used
     for pattern matching, pattern substitutions and general string
     manipulation. PHP/FI supports all common regular expression
     operations.

  ·  Raw HTTP Header Control The ability to have web pages send
     customized raw HTTP headers based on some condition is essential
     for high-level web site design. A frequent use is to send a
     Location: URL header to redirect the calling client to some other
     URL. It can also be used to turn off cacheing or manipulate the
     last update header of pages.

  ·  On-the-fly GIF image creation PHP/FI has support for Thomas
     Boutell's GD image library which makes it possible to generate GIF
     images on the fly.

  ·  ISP "Safe Mode" support PHP/FI supports a unique "Safe Mode" which
     makes it safe to have multiple users run PHP scripts on the same
     server.

  ·  It's Free!  One final essential feature. The package is completely
     free.  It is licensed under the GPL which allows you to use the
     software for any purpose, commercial or otherwise. See the GNU
     Public License document for complete details.

  22.2.  Credits

  * Large parts of this code were developed at and for the University of
  Toronto. Many thanks to Lee Oattes of the Network Development
  Department at the university for constant constructive criticism.

  * The PostgreSQL support code was written by Adam Sussman
  asussman@vidya.com

  * Countless others have helped test and debug the package.

  PHP/FI Version 2.0

  22.3.  Brief History

  PHP began life as a simple little cgi wrapper written in Perl. I wrote
  it in an afternoon during a period between contracts when I needed a
  quick tool to get an idea of who was reading my online resume. It was
  never intended to go beyond my own private use. The web server where I
  had my resume was extremely overloaded and had constant problems
  forking processes. I rewrote the Perl wrapper in C to get rid of the
  considerable overhead of having to fork Perl each time my resume was
  accessed.

  Eventually other people on the same web server came across my wrapper
  and asked if they could use it. Then, as inevitably happens, they
  started asking for more features. I added more features and finally
  put together a semi-complete distribution along with documentation, a
  mailing-list and a FAQ. The name of this first package was Personal
  Home Page Tools, which later became Personal Home Page Construction
  Kit.

  At the same time I started playing with databases and wrote a tool to
  easily embed SQL queries into web pages. It was basically another CGI
  wrapper that parsed SQL queries and made it easy to create forms and
  tables based on these queries. This tool was named FI (Form
  Interpreter).

  PHP/FI version 2.0 is a complete rewrite of these two packages
  combined into a single program. It has now evolved to the point where
  it is a simple programming language embedded inside HTML files. The
  original acronym, PHP, has stuck. It isn't really appropriate any
  longer. PHP/FI is used more for entire web sites today than for small
  Personal Home Page setups. By whatever name, it eliminates the need
  for numerous small Perl cgi programs by allowing you to place simple
  scripts directly in your HTML files. This speeds up the overall
  performance of your web pages since the overhead of forking Perl
  several times has been eliminated. It also makes it easier to manage
  large web sites by placing all components of a web page in a single
  html file. By including support for various databases, it also makes
  it trivial to develop database enabled web pages. Many people find the
  embedded nature much easier to deal with than trying to create
  separate HTML and CGI files.

  Throughout this documentation any references to PHP, FI or PHP/FI all
  refer to the same thing. The difference between PHP and FI is only a
  conceptual one. Both are built from the same source distribution. When
  I build the package without any access logging or access restriction
  support, I call my binary FI. When I build with these options, I call
  it PHP.

  22.4.  So, what can I do with PHP/FI ?

  The first thing you will notice if you run a page through PHP/FI is
  that it adds a footer with information about the number of times your
  page has been accessed (if you have compiled access logging into the
  binary). This is just a very small part of what PHP/FI can do for you.
  It serves another very important role as a form interpreter cgi, hence
  the FI part of the name. For example, if you create a form on one of
  your web pages, you need something to process the information on that
  form. Even if you just want to pass the information to another web
  page, you will have to have a cgi program do this for you. PHP/FI
  makes it extremely easy to take form data and do things with it.

  22.5.  A simple example

  Suppose you have a form:

       <FORM ACTION="/cgi-bin/php.cgi/~userid/display.html" METHOD=POST>
       <INPUT TYPE="text" name="name">
       <INPUT TYPE="text" name="age">
       <INPUT TYPE="submit">
       <FORM>

  Your display.html file could then contain something like:

  < ?echo "Hi $ name, you are $ age years old!

  " >

  It's that simple! PHP/FI automatically creates a variable for each
  form input field in your form. You can then use these variables in the
  ACTION URL file.

  The next step once you have figured out how to use variables is to
  start playing with some logical flow tags in your pages. For example,
  if you wanted to display different messages based on something the
  user inputs, you would use if/else logic. In our above example, we can
  display different things based on the age the user entered by changing
  our display.html to:

       <?
           if($age>50);
               echo "Hi $name, you are ancient!<p>";
           elseif($age>30);
               echo "Hi $name, you are very old!<p>";
           else;
               echo "Hi $name.";
           endif;
       >

  PHP/FI provides a very powerful scripting language which will do much
  more than what the above simple example demonstrates. See the section
  on the PHP/FI Script Language for more information.

  You can also use PHP/FI to configure who is allowed to access your
  pages.  This is done using a built-in configuration screen. With this
  you could for example specify that only people from certain domains
  would be allowed to see your pages, or you could create a rule which
  would password protect certain pages. See the Access Control section
  for more details.

  PHP/FI is also capable of receiving file uploads from any RFC-1867
  compliant web browser. This feature lets people upload both text and
  binary files. With PHP/FI's access control and logical functions, you
  have full control over who is allowed to upload and what is to be done
  with the file once it has been uploaded. See the File Upload section
  for more details.

  PHP/FI has support for the PostgreSQL database package. It supports
  embedded SQL queries in your .HTML files. See the section on
  PostgreSQL Support for more information.

  PHP/FI also has support for the mysql database package. It supports
  embedded SQL queries in your .HTML files. See the section on mysql
  Support for more information.

  22.6.  CGI Redirection

  Apache 1.0.x Notes

  A good way to run PHP/FI is by using a cgi redirection module with the
  Apache server. Please note that you do not need to worry about
  redirection modules if you are using the Apache module version of
  PHP/FI. There are two of these redirection modules available. One is
  developed by Dave Andersen angio@aros.net and it is available at
  ftp://ftp.aros.net/pub/util/apache/mod_cgi_redirect.c and the other
  comes bundled with Apache and is called mod_actions.c. The modules are
  extremely similar. They differ slightly in their usage. Both have been
  tested and both work with PHP/FI.

  One large caveat at the time of this writing (Apr.20/96) is that the
  current official Apache release (1.0.5) has a severe limitation which
  prevents cgi redirected requests from having any post-method data
  associated with them. I have tracked this down and fixed it in my
  version of Apache, and there is an official patch available in the
  File Archives on the PHP Home Page.

  A second rather large caveat with Apache 1.0.x is that it does not
  align double types correctly on most architectures. You find find
  yourself getting strange bus errors from your httpd when using
  mod_php, either upgrade to Apache 1.1 or edit the alloc.c Apache
  source file. In this file you will find the following piece of code:

  union align { /* Types which are likely to have the longest RELEVANT
  alignment * restrictions... we don't do much with doubles.  */

  char *cp; void (*f)(); long l; FILE *fp; };

  You will need to add a double to this line and recompile your Apache
  server. The correct block of code is:

  union align { /* Types which are likely to have the longest RELEVANT
  alignment * restrictions... we don't do much with doubles.  */

  char *cp; void (*f)(); long l; FILE *fp; double d; };

  Check the Apache documentation on how to add a module. Generally you
  add the module name to a file called Configuration. The line to be
  added if you want to use the mod_actions module is:

  Module action_module mod_actions.o

  If you are using the mod_cgi_redirect.c module add this line:

  Module cgi_redirect_module mod_cgi_redirect.o

  Then compile your httpd and install it. To configure the cgi
  redirection you need to either create a new mime type in your
  mime.types file or you can use the AddType command in your srm.conf
  file to add the mime type. The mime type to be added should be
  something like this:

  application/x-httpd-php phtml

  If you are using the mod_actions.c module you need to add the
  following line to your srm.conf file:

  Action application/x-httpd-php /cgi-bin/php.cgi

  If you are using mod_cgi_redirect.c you should add this line to
  srm.conf:

  CgiRedirect application/x-httpd-php /cgi-bin/php.cgi

  Don't try to use both mod_actions.c and mod_cgi_redirect.c at the same
  time.

  Once you have one of these cgi redirection modules installed and
  configured correctly, you will be able to specify that you want a file
  parsed by php/fi simply by making the file's extension .phtml.
  Furthermore, if you add index.phtml to your DirectoryIndex
  configuration line in your srm.conf file then the top-level page in a
  directory will be automatically parsed by php if your index file is
  called index.phtml.
  Netscape HTTPD

  You can automatically redirect requests for files with a given
  extension to be handled by PHP/FI by using the Netscape Server CGI
  Redirection module. This module is available in the File Archives on
  the PHP/FI Home Page. The README in the package explicitly explains
  how to configure it for use with PHP/FI.

  NCSA HTTPD

  NCSA does not currently support modules, so in order to do cgi
  redirection with this server you need to modify your server source
  code. A patch to do this with NCSA 1.5 is available in the PHP/FI file
  archives.

  22.7.  Running PHP/FI from the command line

  If you build the CGI version of PHP/FI, you can use it from the
  command line simply typing: php.cgi filename where filename is the
  file you want to parse. You can also create standalone PHP/FI scripts
  by making the first line of your script look something like:

           #!/usr/local/bin/php.cgi -q

  The "-q" suppresses the printing of the HTTP headers. You can leave
  off this option if you like.

  23.  Python Interface for PostgreSQL

  PyGres95 is a python interface for the PostgreSQL. See the readme file
  at <ftp://ftp.via.ecp.fr/pub/python/contrib/Database/PyGres95.README >

  Package is available from
  <ftp://ftp.via.ecp.fr/pub/python/contrib/Database/PyGres95-1.0b.tar.gz
  >

  The extract from the home page of PyGres95 is given below:-

  PyGres - v1.0b : PostgreSQL module for Python

  PyGres95, version 1.0b A Python interface for PostgreSQL database.
  Written by Pascal Andre, andre@chimay.via.ecp.fr

  PostgreSQL is a database system derived from Postgres4.2. It conforms
  to (most of) ANSI SQL and offer many interesting possibilities (C
  dynamic linking for functions or type definition, time travel, ...).
  This package is copyrighted by the Regents of the University of
  California, and is freely distributable.

  Python is a interpretated programming langage. It is object oriented,
  simple to use (light syntax, simple and straighforward statements),
  and has many extensions for building GUIs, interfacing with WWW, ...
  An "intelligent" web browser (HotJava like) is currently under
  development (november 1995), and this should open programmers many
  doors. Python is copyrighted by Stichting Mathematisch Centrum,
  Amsterdam, The Netherlands, and is freely distributable.

  PyGres95 is a python module that interfaces PostgreSQL database. It
  embeds PostgreSQL query library to allow an easy use of powerful
  PostgreSQL features cooperatively with all the other python modules.
  It has been developed on a Linux 1.3/ELF system, but have been tested
  on a Solaris 2.4 platform. Anyway, it should work on any platform
  where python and postgreSQL are available.

  23.1.  Where to get PyGres ?

  The home sites of the differents packages are:

  ·  Python :      <ftp.python.org:/pub/python>

  ·  PostgreSQL :  <ftp.s2k-ftp.cs.berkeley.edu:/pub/postgres95>

  ·  PyGres95 :    <ftp.via.ecp.fr:/pub/python/contrib>

  You should anyway try to find some mirror site closer of your site.
  Refer to the information sources to find these sites. PyGres95 should
  reside in the contrib directories of Python and PostgreSQL sites.

  23.2.  Information and support

  If you need information about these packages please check their web
  sites:

  ·  Python :      <http://www.python.org/>

  ·  PostgreSQL :
     <http://epoch.cs.berkeley.edu:8000/postgres95/index.html>

  ·  PyGres95 :    <http://www.via.ecp.fr/via/products/pygres.html>

  For support :

  ·  Python :     newsgroup comp.lang.python

  ·  PostgreSQL : mailing list (see package documentation for
     information)

  ·  PyGres95 :   contact me andre@via.ecp.fr for bug reports, ideas,
     remarks

     I will try to answer as long as my free time allow me to do that.

  24.  Gateway between PostgreSQL and the WWW - WDB-P95

  WDB-P95 - A Web interface to PostgreSQL Databases.  It is at
  <http://www.eol.ists.ca/~dunlop/wdb-p95/>

  The extract from the home page of WDB-P95 is given below:-

  Version 1.4b2 beta - Created by J. Douglas Dunlop

  About wdb-p95

  This is a modified version of wdb-1.3a2 which provides a gateway to a
  the WWW for PostgreSQL. This version also requires a Browser that is
  capable of handling HTML Tables for the tabular output. This is not
  required by the original wdb and can be fairly easily reverted.  (I
  only wanted tables because the < pre > stuff just didn't agree with
  me!)

  You can try out my CASI Tape and Image Query. You can have a peek at
  the Form Definition File (FDF) that I used to create the CASI Tape and
  Image Query too, which includes a JOIN of 2 tables.

  This release contains all files necessary to install and run WDB-P95
  as an interface to your PostgreSQL databases. To port this system to
  other database should be relatively easy - provided that it supports
  standard SQL and has a Perl interface.

  24.1.  Does the PostgreSQL server,pgperl, and httpd have to be on the
  same host?

  No - the PostgreSQL server does not have to be on the same host. As
  WDB-P95 is called by the http daemon, they have to be on the same
  host. - And as WDB-P95 was written to use Pg.pm - pgperl has to be on
  the same host too.  Pgperl was written using the libpq library, so it
  will be able to access any PostgreSQL server anywhere in the net, just
  like any other PostgreSQL client. As illustrated below

  {WWW Client (Netscape)} => {HTTP Server (NCSA's http) + WDB-P95 +
  pgperl + libpq}=> {PostgreSQL server}

  Curly brackets () represent machines.

  Each machine can be of a different type : NT, SUN, HP, ... but you
  need the libpq interface library for the machine type where you plan
  to use WDB-P95, as you need it to compile pgperl. (The system was
  designed to use HTML tables so a recent WWW client is best)

  24.2.  New Version

  New versions of the software and the above pages are always available
  from the WDB-P95 Home page.  <http://www.eol.ists.ca/~dunlop/wdb-p95/>

  For questions or to join Mailing lists contact dunlop@eol.ists.ca

  25.  C" language Interface for PostgreSQL

  Included in distribution and is called 'libpq'. Similar to Oracle OCI,
  Sybase DB-lib, Informix CLI libraries.

  26.  C++" language Interface for PostgreSQL

  Included in distribution and is called 'libpq++'.

  27.  ESQL/C for PostgreSQL

  Embedded C Pre-compiler for PostgreSQL ESQL/C like Oracle Pro*C,
  Informix ESQL/C:

  ·  <ftp://ftp.lysator.liu.se/pub/linus>

  ·  Email : linus@epact.se

  The PostgreSQL ESQL/C is an SQL application-programming interface
  (API) enables the C programmer to create custom applications with
  database-management capabilities. The PostgreSQL ESQL/C allows you to
  use a third-generation language with which you are familiar and still
  take advantage of the Structured Query Language (SQL).

  ESQL/C consists of the following pieces of software:

  ·  The ESQL/C libraries of C functions provide access to the database
     server.

  ·  The ESQL/C header files provide definitions for the data
     structures, constants, and macros useful to the ESQL/C program.

  ·  The ESQL/C preprocessor, is a source-code preprocessor that
     converts a C file containing SQL statements into an executable
     file.

  28.  BitWise Operators for PostgreSQL

  Bitwise operators was written by Nicolas Moldavsky nico@overnet.com.ar

  "C" functions that implement bitwise operators (AND, OR, XOR, bit
  complement) on pgsql. If anyone would like to use them, can get them
  by anonymous FTP from

  ·  <ftp://ftp.overnet.com.ar/pub/utils/linux/bitpgsql.tgz>

  There included is a Makefile that works fine on Linux.

  29.  Japanese Kanji Code for PostgreSQL

  Very useful for Japanese people.  It is at the following site
  <ftp://ftp.sra.co.jp/pub/cmd/postgres/>

  30.  PostgreSQL Port to Windows 95/Windows NT

  Port to Windows 95/Windows NT is underway.  Porting is being done
  using gcc, gmake for Win NT/95. To compile source code on win32 gnu-
  win32 program is used.  GNU gcc is available for win32. Check this
  site -

  ·  <http://www.cygnus.com/misc/gnu-win32>

     At this site and get the file cdk.exe (self-extractor file for gnu-
     win32)

  Porting can also be done using the following "Unix-Emulator on NT"
  tool from

  ·  <http://www.softway.com>

  31.  Mailing Lists and Newsgroups

  31.1.  Newsgroups

  There is newsgroup for PostgreSQL at news.postgresql.org Please follow
  these steps to subscribe

       1. Choose Window | Netscape News
       2. Choose File | Open News Host
       3. Type news.postgresql.org in the edit box.
       4. The name of the newsgroup is comp.databases.postgresql.questions.
       To add right-click on news.postgresql.org, and choose Add Newsgroup.
       Then type the newsgroup into the edit box. The newsgroup will be added
       to the list in the left hand pane.
       5. Newsgroups will be listed in the left hand pane. Any messages in
       the selected newsgroup will appear in the right hand pane.

  31.2.  Get a Free e-mail account

  Check out the free deals offered - get free e-mail accounts from

  ·  In Yahoo  <http://www.yahoo.com> click on e-mail

  ·  In Lycos  <http://www.lycos.com> click on new e-mail accounts

  ·  In hotmail  <http://www.hotmail.com> click on new e-mail accounts

     Subscribe to PostgreSQL mailing list and Yahoo has additional
     feature of creating a seperate folder for PostgreSQL e-mails, so
     that your regular e-mail is not cluttered. Select menu Email- >
     Options- > Filters and pick seperate folder for email.  With this
     e-mail account you can access mail from anywhere in the world as
     long as you have access to a web page.

  If you have any other e-mail, you can use "Mail Filters" to receive
  automatically the PostgreSQL mails into a seperate folder. This way it
  will be better organised and you avoid mail cluttering.

  31.3.  English Mailing List

  See the Mailing Lists Item on the main web page at :
  <http://www.postgresql.org/>

  ·  Email questions to: pgsql-questions@postgresql.org

  ·  Developers pgsql-hackers@postgresql.org

  ·  Port specific questions pgsql-ports@postgresql.org

  ·  Documentation questions pgsql-docs@postgresql.org

     You will get the answers/replies back by e-mail in less than a
     day!!

  You can also subscribe to mailing lists.  See also the section 'Get a
  Free e-mail account' above.  To subscribe or unsubscribe from the
  list, send mail to

  ·  pgsql-questions-request@postgresql.org

  ·  pgsql-hackers-request@postgresql.org

  ·  pgsql-ports-request@postgresql.org

  ·  pgsql-docs-request@postgresql.org

     The body of the message should contain the single line

  subscribe

  (or)

  unsubscribe

  31.4.  Archive of Mailing List

  Also mailing lists are archived in html format at the following
  location -

  ·  <ftp://ftp.postgresql.org> directory is /pub/majordomo

  31.5.  Spanish Mailing List

  Now there is an "unofficial" list of postgreSQL in Spanish.  See also
  the section 'Free Account to Organise your PostgreSQL e-mails' above.
  To subscribe the user has to send a message to:

  ·  majordomo@tlali.iztacala.unam.mx

     The body of the message should contain the single line:

  inscripcion pgsql-ayuda

  32.  Documentation and Reference Books

  32.1.  User Guides and Manuals

  The following are included in the PostgreSQL distribution in the
  postscript format and unix man-pages.  If you have access to internet,
  you can find the documents listed below at
  <http://www.postgresql.org/docs>

  ·  "User Guide" for PostgreSQL

  ·  "Implementation Guide" detailing database internals of PostgreSQL.

  ·  Online manuals.

  ·  Online manuals in HTML formats.

  ·  Also manuals in Postscript format for printing hard copies.

  32.2.  Online Documentation

  ·  Listing and description of default data types and operators

       Will be a part of PSQL command in the next release 6.3.  Already completed.

  ·  Listing of supported SQL keywords

       There is a script in the /tools directory to do that

  ·  Listings of supported statements -

       Use the command psql \h

  ·  Basic relational database concepts under PostgreSQL
     (implementation) and Tons of online examples (queries) -

       Look at the regression tests at src/test. There you can find the directories
       regress/sql and suite/*.sql.

  ·  Tutorial for PostgreSQL.

       SQL tutorial scripts is in the directory src/tutorial

  See also "SQL Tutorial for beginners" in Appendix C of this document
  ``''

  32.3.  Useful Reference Textbooks

  ·  "Understanding the New SQL: A Complete Guide" - by Jim Melton and
     Alan R.Simon

       Morgan Kaufman Publisher is one of best SQL books. This deals with SQL92.

  ·  "A Guide to THE SQL STANDARD" - by C.J.Date

       Addison-Wesley Publishing company is also a good book. Very popular book for SQL.

  ·  SQL - The Standard Handbook,  November 1992

       Stephen Cannan and Gerard Otten
       McGraw-Hill Book Company Europe , Berkshire, SL6 2QL, England

  ·  SQL Instant Reference, 1993

       Martin Gruber, Technical Editor: Joe Celko
       SYBEX Inc.  2021 Challenger Drive Alameda, CA 94501

  ·  C.J.Date, "An introduction to Database Systems" (6th Edition),
     Addison-Wesley, 1995, ISBN 0-201-82458-2

       This book is the Bible of Database Management Systems.
       The book details normalization, SQL, recovery, concurrency, security,
       integrity, and extensions to the original relational model, current issues
       like client/server systems and the Object Oriented model(s). Many
       references are included for further reading. Recommended for most users.

  ·  Stefan Stanczyk, "Theory and Practice of Relational Databases", UCL
     Press Ltd, 1990, ISBN 1-857-28232-9

       Book details theory of relational databases, relational algebra, calculus
       and normalisation. But it does not cover real world issues and examples
       beyond simple examples. Recommended for most users.

  ·  "The Practical SQL Handbook" Third Edition, Addison Wesley
     Developers Press ISBN 0-201-44787-8

       Recommended for most users.

  ·  Michael Stonebraker, "Readings in Database Systems", Morgan
     Kaufmann, 1988, ISBN 0-934613-65-6

       This book is a collection of papers that have been published over the
       years on databases. It's not for the casual user but it is really a
       reference for advanced (post-graduate) students or database system
       developers.

  ·  C.J.Date, "Relational Database - Selected Readings", Addison-
     Wesley, 1986, ISBN 0-201-14196-5

       This book is a collection of papers that have been published over the
       years on databases. It's not for the casual user but it is really a
       reference for advanced (post-graduate) students or database system
       developers.

  ·  Nick Ryan and Dan Smith, "Database Systems Engineering",
     International Thomson Computer Press, 1995, ISBN 1-85032-115-9

       This book goes into the details of access methods, storage techniques.

  ·  Bipin C. Desai, "An introduction to Database Systems", West
     Publishing Co., 1990, ISBN 0-314-66771-7

       It's not for the casual user but it is for advanced (post-graduate)
       students or database system developers.

  ·  Joe Celko "INSTANT SQL Programming"

       Wrox Press Ltd.
       Unit 16, 20 James Road, Tyseley
       Birmingham, B11 2BA, England
       1995

  ·  Michael Gorman "Database Management Systems: Understanding and
     Applying Database"

  Technology
  QED and John Wiley
  1991

  ·  Michael Gorman "Enterprise Database for a Client/Server
     Environment" QED and John Wiley

       Presents the requirements of building client/server database
       applications via repository metamodels and the use of ANSI standard SQL
       1993

  Hundreds of other titles on SQL are available! Check out a bookstore.

  32.4.  ANSI/ISO SQL Specifications documents  - SQL 1992, SQL 1998

  ANSI/ISO SQL specifications documents can be found at these sites
  listed below -

  ·  <http://www.naiua.org/std-orgs.html>

  ·  <http://www.ansi.org/docs> and click on file cat_c.html and search
     with "Database SQL"

  ·  SQL92 standard  <http://www.jcc.com> and click on file
     sql_stnd.html

  ·  ANSI/ISO SQL specifications
     <http://www.contrib.andrew.cmu.edu/~shadow/sql.html> You will find
     SQL Reference here.

  32.5.  Syntax of ANSI/ISO SQL 1992

  See Appendix A of this document ``''

  32.6.  Syntax of ANSI/ISO SQL 1998

  See Appendix B of this document ``''

  32.7.  SQL Tutorial for beginners

  See Appendix C of this document ``''

  32.8.  Temporal Extension to SQL92

  ·  Document for Temporal Extension to SQL-92
     <ftp://FTP.cs.arizona.edu/tsql/tsql2/>

  ·  Temporal SQL-3 specification
     <ftp://FTP.cs.arizona.edu/tsql/tsql2/sql3/>

  This directory contains the language specification for a temporal
  extension to the SQL-92 language standard. This new language is
  designated TSQL2.

  The language specification present here is the final version of the
  language.

  Correspondence may be directed to the chair of the TSQL2 Language
  Design Committee, Richard T.Snodgrass, Department of Computer Science,
  University of Arizona, Tucson, AZ 85721, rts@cs.arizona.edu .  The
  affiliations and e-mail addresses of the TSQL2 Language Design
  Committee members may be found in a separate section at the end of the
  language specification.

  The contents of this directory are as follows.

  spec.dvi,.ps    TSQL2 Language Specification, published in September,
  1994

  bookspec.ps     TSQL2 Language Specification, as it appears in the
  TSQL2 book, published in September, 1995 (see below).

  sql3            change proposals submitted to the ANSI and ISO SQL3
  committees.

  Associated with the language specification is a collection of
  commentaries which discuss design decisions, provide examples, and
  consider how the language may be implemented. These commentaries were
  originally proposals to the TSQL2 Language Design Committee. They now
  serve a different purpose: to provide examples of the constructs,
  motivate the many decisions made during the language design, and
  compare TSQL2 with the many other language proposals that have been
  made over the last fifteen years. It should be emphasized that these
  commentaries are not part of the TSQL2 language specification per se,
  but rather supplement and elaborate upon it. The language
  specification proper is the final word on TSQL2.

  The commentaries, along with the language specification, several
  indexes, and other supporting material, has been published as a book:

  Snodgrass, R.T., editor, The TSQL2 Temporal Query Language, Kluwer
  Academic Publishers, 1995, 674+xxiv pages.

  The evaluation commentary appears in the book in an abbreviated form;
  the full commentary is provided in this directory as file eval.ps

  The file tl2tsql2.pl is a prolog program that tranlates allowed
  temporal logic to TSQL2. This program was written by Michael Boehlen
  boehlen@iesd.auc.dk He may be contacted for a paper that describes
  this translation. This is a rather dated version of that program.
  Newer versions are available at
  <http://www.cs.auc.dk/general/DBS/tdb/TimeCenter/Software> (the TimeDB
  and Tiger systems).

  32.9.  Part 0 - Acquiring ISO/ANSI SQL Documents

    This document shows you how to (legally) acquire a copy
    of the SQL-92 standard and how to acquire a copy of the "current" SQL3
    Working Draft.

    The standard is copyrighted ANSI standard by ANSI, the ISO standard by ISO.

    There are two (2) current SQL standards, an ANSI publication
    and an ISO publication. The two standards are word-for-word identical
    except for such trivial matters as the title of the document, page
    headers, the phrase "International Standard" vs "American Standard", and
    so forth.

                      Buying the SQL-92 Standard

    The ISO standard, ISO/IEC 9075:1992, Information Technology - Database
    Languages - SQL, is currently (March, 1993) available and in stock from
    ANSI at:

       American National Standards Institute
       1430 Broadway
       New York, NY 10018 (USA)
       Phone (sales): +1.212.642.4900

    at a cost of US$230.00. The ANSI version, ANSI X3.135-1992, American
    National Standard for Information Systems - Database Language SQL, was
    not available from stock at this writing, but was expected to be
    available by some time between late March and early May, 1993). It is
    expected to be be priced at US$225.00.

    If you purchase either document from ANSI, it will have a handling
    charge of 7% added to it (that is, about US$9.10). Overseas shipping
    charges will undoubtedly add still more cost. ANSI requires a hardcopy
    of a company purchase order to accompany all orders; alternately, you
    can send a check drawn on a US bank in US dollars, which they will cash
    and clear before shipping your order. (An exception exists: If your
    organization is a corporate member of ANSI, then ANSI will ship the
    documents and simply bill your company.)

    The ISO standard is also available outside the United States from local
    national bodies (country standardization bodies) that are members of
    either ISO (International Organization for Standardization) or IEC
    (International Electrotechnical Commission). Copies of the list of
    national bodies and their addresses are available from ANSI or from
    other national bodies. They are also available from ISO:

       International Organization for Standardization
       Central Secretariat
       1, rue de Varembi
       CH-1211 Genhve 20
       Switzerland

    If you prefer to order the standard in a more convenient and quick
    fashion, you'll have to pay for the privilege. You can order ISO/IEC
    9075:1992, Information Technology - Database Languages - SQL, from:

       Global Engineering Documents
       2805 McGaw Ave
       Irvine, CA 92714 (USA)
       USA
       Phone (works from anywhere): +1.714.261.1455
       Phone (only in the USA): (800)854-7179

    for a cost of US$308.00. I do not know if that includes shipping or not,
    but I would guess that international shipping (at least) would cost
    extra. They will be able to ship you a document fairly quickly and will
    even accept "major credit cards". Global does not yet have the ANSI
    version nor do they have a price or an expected date (though I would
    expect it within a few weeks following the publication by ANSI and at a
    price near US$300.00).

               Buying a copy of the SQL3 Working Draft
    You can purchase a hardcopy of the SQL3 working draft from the ANSI X3
    Secretariat, CBEMA (Computer and Business Equipment Manufacturers
    Association). They intend to keep the "most recent" versions of the SQL3
    working draft available and sell them for about US$60.00 to US$65.00.
    You can contact CBEMA at:

       CBEMA, X3 Secretariat
       Attn: Lynn Barra
       1250 Eye St.
       Suite 200
       Washington, DC 20005 (USA)

    Lynn Barra can also be reached by telephone at +1.202.626.5738 to
    request a copy, though mail is probably more courteous.

             Electronic Access to the SQL3 Working Draft
    The most recent version (as of the date of this writing) of the SQL3
    (both ANSI and ISO) working draft (and all of its Parts) is available by
    "anonymous ftp" or by "ftpmail" on:

       gatekeeper.dec.com

    at

       /pub/standards/sql/

    In this directory are a number of files.  There are PostScript. files
    and "plain text" (not prettily formatted, but readable on a screen
    without special software).

    In general, you can find files with names like:

       sql-bindings-mar94.ps
       sql-bindings-mar94.txt
       sql-cli-mar94.ps
       sql-cli-mar94.txt
       sql-foundation-mar94.ps
       sql-foundation-mar94.txt
       sql-framework-mar94.ps
       sql-framework-mar94.txt
       sql-psm-mar94.ps
       sql-psm-mar94.txt

    As new versions of the documents are produced, the "mar94" will change
    to indicate the new date of publication (e.g., "aug94" is the expected
    date of the next publication after "mar94").

    In addition, for those readers unable to get a directory listing by FTP,
    we have placed a file with the name:

       ls

    into the same directory.  This file (surprise!) contains a directory
    listing of the directory.

                 Retrieving Files Directly Using ftp

    This is a sample of how to use FTP. Specifically, it shows how to
    connect to gatekeeper.dec.com, get to the directory where the base
    document is kept, and transfer the document to your host. Note that your
    host must have Internet access to do this. The login is 'ftp' and the
    password is your email address (this is sometimes referred to as
    'anonymous ftp'). The command 'type binary' is used to ensure that no
    bits are stripped from the file(s) received. 'get' gets one file at a
    time. Comments in the script below are inside angle brackets <like so>.

    % ftp gatekeeper.dec.com
    Connected to gatekeeper.dec.com.
    220- *** /etc/motd.ftp ***
         Gatekeeper.DEC.COM is an unsupported service of DEC Corporate Research.
         <...this goes on for a while...>
    220 gatekeeper.dec.com FTP server (Version 5.83 Sat ... 1992) ready.
    Name (gatekeeper.dec.com:<yourlogin here>): ftp  <anonymous also works>
    331 Guest login ok, send ident as password.
    Password: <enter your email address here >
    230 Guest login ok, access restrictions apply.
    Remote system type is UNIX.  <or whatever>
    Using binary mode to transfer files.
    ftp> cd pub/standards/sql
    250 CWD command successful.
    ftp> dir
    200 PORT command successful.
    150 Opening ASCII mode data connection for /bin/ls.
    total 9529
    -r--r--r--  1 root     system     357782 Feb 25 10:18 x3h2-93-081.ps
    -r--r--r--  1 root     system     158782 Feb 25 10:19 x3h2-93-081.txt
    -r--r--r--  1 root     system     195202 Feb 25 10:20 x3h2-93-082.ps
    -r--r--r--  1 root     system      90900 Feb 25 10:20 x3h2-93-082.txt
    -r--r--r--  1 root     system    5856284 Feb 25 09:55 x3h2-93-091.ps
    -r--r--r--  1 root     system    3043687 Feb 25 09:57 x3h2-93-091.txt
    226 Transfer complete.
    ftp> type binary
    200 Type set to I.
    ftp> get x3h2-93-082.txt
    200 PORT command successful.
    150 Opening BINARY mode data connection for x3h2-93-082.txt (90900 bytes).
    226 Transfer complete.
    90900 bytes received in 0.53 seconds (166.11 Kbytes/s)
    ftp> quit
    % <the file is now in your directory as x3h2-93-082.txt>

             Retrieving Files Without Direct ftp Support
    Digital Equipment Corporation, like several other companies, provides
    ftp email service. The response can take several days, but it does
    provide a service equivalent to ftp for those without direct Internet
    ftp access. The address of the server is:

       ftpmail@decwrl.dec.com

    The following script will retrieve the PostScript for the latest version
    of the SQL3 document:

       reply joe.programmer@imaginary-corp.com
       connect gatekeeper.dec.com anonymous
       binary
       compress
    The following script will retrieve the PostScript for the latest version
    of the SQL3 document:

       reply joe.programmer@imaginary-corp.com
       connect gatekeeper.dec.com anonymous
       binary
       compress
       uuencode
       chdir /pub/standards/sql
       get x3h2-93-091.ps
       quit
    The first line in the script commands the server to return the requested
    files to you; you should replace "joe.programmer@imaginary-corp.com"
    with your Internet address. The file in this example, x3h2-93-091.ps,
    is returned in "compress"ed "uuencode"d format as 34 separate email
    messages. If your environment does not provide tools for reconstructing
    such files, then you could retrieve the file as plain text with the
    following script:

       reply joe.programmer@imaginary-corp.com
       connect gatekeeper.dec.com anonymous
       chdir /pub/standards/sql
       get x3h2-93-091.ps
       quit

    But be warned, the .ps file will probably be sent to you in more than 70
    parts!

    To retrieve any particular file, other than x3h2-93-091.ps, simply
    replace "x3h2-93-091.ps" with the name of the desired file. To get a
    directory listing of all files available, replace "get x3h2-93-091.ps"
    with "dir".

  32.10.  Part 1 - ISO/ANSI SQL Current Status

  This chapter is a source of information about the SQL
  standards process and its current state.

  ----------------------------------------------------------------------------
  Current Status

  Development is currently underway to enhance SQL into a computationally
  complete language for the definition and management of persistent, complex
  objects. This includes: generalization and specialization hierarchies,
  multiple inheritance, user defined data types, triggers and assertions,
  support for knowledge based systems, recursive query expressions, and
  additional data administration tools. It also includes the specification of
  abstract data types (ADTs), object identifiers, methods, inheritance,
  polymorphism, encapsulation, and all of the other facilities normally
  associated with object data management.

  In the fall of 1996, several parts of SQL3 went through a ISO CD ballot.
  Those parts were SQL/Framework, SQL/Foundation, and SQL/Bindings. Those
  ballots failed (as expected) with 900 or so comments. In Late January, there
  was an ISO DBL editing meeting that processed a large number of problem
  solutions that were either included with ballot comments or submitted as
  separate papers. Since the DBL editing meeting was unable to process all of
  the comments, the editing meeting has been extended. The completion of the
  editing meeting is scheduled for the end of July, 1997, in London.

  Following the July editing meeting, the expectation is that a Final CD
  ballot will be requested for these parts of SQL. The Final CD process will
  take about 6 months and a DBL editing meeting, after which there will be a
  DIS ballot and a fairly quick IS ballot.

  The ISO procedures have changed since SQL/92, so the SQL committees are
  still working through the exact details of the process.

  If everything goes well, these parts of SQL3 will become an official ISO/IEC
  standard in late 1998, but the schedule is very tight.

  In 1993, the ANSI and ISO development committees decided to split future SQL
  development into a multi-part standard. The Parts are:

     * Part 1: Framework A non-technical description of how the document is
       structured.
     * Part 2: Foundation The core specification, including all of the new ADT
       features.
     * Part 3: SQL/CLI The Call Level Interface.
     * Part 4: SQL/PSM The stored procedures specification, including
       computational completeness.
     * Part 5: SQL/Bindings The Dynamic SQL and Embedded SQL bindings taken
       from SQL-92.
     * Part 6: SQL/XA An SQL specialization of the popular XA Interface
       developed by X/Open
     * Part 7:SQL/TemporalAdds time related capabilities to the SQL standards.

  In the USA, the entirety of SQL3 is being processed as both an ANSI Domestic
  ("D") project and as an ISO project. The expected time frame for completion
  of SQL3 is currently 1999.

  The SQL/CLI and SQL/PSM are being processed as fast as possible as addendums
  to SQL-92. In the USA, these are being processed only as International ("I")
  projects. SQL/CLI was completed in 1995. SQL/PSM should be completed
  sometime in late 1996.

  In addition to the SQL3 work, a number of additional projects are being
  persued:

     * SQL/MM An ongoing effort to define standard multi-media packages using
       the SQL3 ADT capabilities.
     * Remote Data Access (RDA)

  ----------------------------------------------------------------------------

  Standards Committee and Process

  There are actually a number of SQL standards committees around the world.
  There is an international SQL standards group as a part of ISO. A number of
  countries have committees that focus on SQL. These countries (usually) send
  representatives to ISO/IEC JTC1/SC 21/WG3 DBL meetings. The countries that
  actively participate in the ISO SQL standards process are:

     * Australia
     * Brazil
     * Canada
     * France
     * Germany
     * Japan
     * Korea
     * The Netherlands
     * United Kingdom
     * United States

  ----------------------------------------------------------------------------

  NIST Validation

  SQL implementations are validated (in the Unites States) by the National
  Institute of Standards and Testing (NIST). NIST currently has a validation
  test suite for entry level SQL-92. The exact details of the NIST validation
  requirements are defined as a Federal Information Processing Standard
  (FIPS). The current requirements for SQL are defined in FIPS 127-2. The
  Postscript and Text versions of this document can be retrieved from NIST.
  The current SQL Validated Products List can also be retrieved from NIST.

  ----------------------------------------------------------------------------

  Standard SQL Publications and Articles

  There are two versions of the SQL standard. Both are available from ANSI:

     * ISO/IEC 9075:1992, "Information Technology --- Database Languages ---
       SQL"
     * ANSI X3.135-1992, "Database Language SQL"

  The two versions of the SQL standard are identical except for the front
  matter and references to other standards. Both versions are available from:

     * American National Standards Institute
       1430 Broadway
       New York, NY 10018
       USA
       Phone (sales): +1.212.642.4900

  In additon to the SQL-92 standard, there is now a Technical Corrigendum (bug
  fixes):

     * Technical Corrigendum 1:1994 to ISO/IEC 9075:1992

  TC 1 should also be available from ANSI. There is only an ISO version of TC
  1 -- it applies both to the ISO and ANSI versions of SQL-92.

  In addition to the standards, several books have been written about the 1992
  SQL standard. These books provide a much more readable description of the
  standard than the actual standard.

  ----------------------------------------------------------------------------

  Related Standards

  A number of other standards are of interest to the SQL community. This
  section contains pointers to information on those efforts. These pointers
  will be augmented as additional information becomes available on the web.

     * SQL Environments (FIPS 193)
     * Next Generation Repository Systems (X3H4) - a News Release calling for
       particpation in "Developing Standards for the Next Generation
       Repository Systems."
  ----------------------------------------------------------------------------

  32.11.  Part 2 - ISO/ANSI SQL Foundation

       A significant portion of the SQL3 effort is in the SQL Foundation document:

          * Base SQL/PSM capabilities (moved form SQL/PSM-92)
          * New data types
          * Triggers
          * Subtables
          * Abstract Data Types (ADT)
          * Object Oriented Capabilities

       There are several prerequisites to the object oriented capabilities:

          * Capability of defining complex operations
          * Store complex operations in the database
          * External procedure calls ­ Some operations may not be in SQL, or may
            require external interactions

       These capabilities are defined as a part of SQL/PSM

       A great deal of work is currently being done to refine the SQL-3 object
       model and align it with the object model proposed by ODMG. This effort is
       described in the X3H2 and ISO DBL paper: Accomodating SQL3 and ODMG. A
       recent update on the SQL3/OQL Merger is also available.

       SQL3 Timing

       Work on SQL3 is well underway, but the final standards is several years
       away.

          * International ballot to progress SQL3 Foundation from Working Draft to
            Committee Draft (CD) taking place fall, 1996.
          * Ballot is expected to generate numerous comments
          * A second CD ballot is likely to be required
          * Draft International Standard ballot is likely to be take place in mid
            1998
          * International Standard could be completed by mid 1999.

       The ANSI version of the standard will be on a similar schedule.

       ----------------------------------------------------------------------------

  32.12.  Part 3 - ISO/ANSI SQL Call Level Interface

       The SQL/CLI is a programing call level interface to SQL databases. It is
       designed to support database access from shrink-wrapped applications. The
       CLI was originally created by a subcommittee of the SQL Access Group (SAG).
       The SAG/CLI specification was published as the Microsoft Open DataBase
       Connectivity (ODBC) specification in 1992. In 1993, SAG submitted the CLI to
       the ANSI and ISO SQL committees. (The SQL Access Group has now merged with
       X/Open consortium.)

       SQL/CLI provides an international standard for:

          * Implementation-independent CLI to access SQL databases
          * Client-server tools can easily access database through dynamic Link
            Libraries
          * Supports and encourages rich set of Client-server tools

       SQL/CLI Timing

       For the standards process, SQL/CLI is being processed with blinding speed.

          * SQL/CLI is an addendum to 1992 SQL standard (SQL-92)
          * Completed as an ISO standard in 1995
          * ISO/IEC 9075-3:1995 Information technology -- Database languages -- SQL
            -- Part 3: Call-Level Interface (SQL/CLI)
          * Current SQL/CLI effort is adding support for SQL3 features
       ----------------------------------------------------------------------------

  32.13.  Part 4 - ISO/ANSI SQL Persistent Stored Modules

  SQL/PSM expands SQL by adding:

     * Procedural language extensions
     * Multi-statement and Stored Procedures
     * External function and procedure calls

  In addition to being a valuable application development tool, SQL/PSM
  provides the foundation support for the object oriented capabilities in
  SQL3.

  Multi-statement and Stored Procedures

  Multi-statement and stored procedures offer a variety of advantages in a
  client/server environment:

     * Performance - Since a stored procedure can perform multiple SQL
       statements, network interaction with the client are reduced.
     * Security - A user can be given the right to call a stored procedure
       that updates a table or set of tables but denied the right to update
       the tables directly
     * Shared code - The code in a stored procedure does not have to be
       rewritten and retested for each client tool that accesses the database.
     * Control - Provides a single point of definition and control for
       application logic.

  Procedural Language Extensions

  Procedural language add the power of a traditional programming language to
  SQL through flow control statements and a variety of other programming
  constructs.

  Flow Control Statements

     * If-then-else
     * Looping constructs
     * Exception handling
     * Case statement
     * Begin-End blocks

  The procedural language extensions include other programming language
  constructs:

     * Variable declarations
     * Set statements for value assignment
     * Get diagnostics for process and status information

  In addition, all of the traditional SQL statements can be included in
  multi-statement procedures.

  External Procedure and Function Calls

  One feature frequently mentioned in the wish lists for many database
  products, and implemented in some, is a capability augmenting the built-in
  features with calls to user-written procedures external to the database
  software.

     * Allows a particular site or application to add their own database
       functions
     * Can be used throughout the database applications

  The benefit of this capability is that it gives the database (and therefore
  database applications) access to a rich set of procedures and functions too
  numerous to be defined by a standards committee.

  SQL/PSM Timing

  SQL/PSM is proceeding quickly:

     * SQL/PSM is an addendum to SQL-92
     * International ballot to progress SQL/PSM from a Draft International
       Standard to an International Standard ended January, 1996.
     * Editing meeting in May, 1996 did not resolve all of the comments
     * Continuation of PSM Editing meeting is scheduled for September 30
       through October 4, 1996
     * The schedule is tight but there is a chance that PSM will be published
       with a 1996 date.
     * The official designation will be:
       ISO/IEC DIS 9075-4:199? Information technology -- Database languages --
       SQL -- Part 4: SQL Persistent Stored Modules (SQL/PSM)
     * Work is well underway on adding SQL/PSM support for SQL3 features.

  ----------------------------------------------------------------------------

  32.14.  Part 5 - ISO/ANSI SQL/Bindings

       For ease of reference, the programming language bindings have been pulled
       out into a separate document. The current version is simply an extract of
       the dynamic and embedded bindings from SQL-92.

       A variety of issues remain unresolved for the programming language bindings.

       For traditional programming language, mappings exist for the SQL-92
       datatypes. However, mappings must be defined between SQL objects and
       programming language variables.

       For object oriented languages, mapping must be defined for the current SQL
       datatypes and between the SQL object model and the object model of the
       object-oriented language.

       The object model needs to stabilize before these can be addressed.

       The language bindings will be completed as a part of SQL3.

       ----------------------------------------------------------------------------

  32.15.  Part 6 - ISO/ANSI SQL XA Interface Specialization (SQL/XA)

  This specification would standardize an application program interface (API)
  between a global Transaction Manager and an SQL Resource Manager. It would
  standardize the function calls, based upon the semantics of ISO/IEC 10026,
  "Distributed Transaction Processing", that an SQL Resource Manager would
  have to support for two-phase commit. The base document is derived from an
  X/Open publication, with X/Open permission, that specifies explicit input
  and output parameters and semantics, in terms of SQL data types, for the
  following functions: xa_close, xa_commit, xa_complete, xa_end, xa_forget,
  xa_open, xa_prepare, xa_recover, xa_rollback, and xa_start.

  ISO is currently attempting to fast-track the X/Open XA specification. The
  fast-track process adopts a current industry specification with no changes.
  The XA fast-track ballot at the ISO SC21, JTC 1 level started on April 27,
  1995 and ends on October 27, 1995. If the XA specification is approved by
  75% of the votes, and by 2/3 of the p-members of JTC 1, it will become an
  International Standard. If the fast-track ballot is approved, SQL/XA could
  become a standard in 1996.
  ----------------------------------------------------------------------------

  32.16.  Part 7 - ISO/ANSI SQL Temporal

  Temporal SQL deals with time-related data. The concept is that it is useful
  to query data to discover what it looked like at a particular point in time.
  Temporal SQL is a December, 1994 paper by Rick Snodgrass describing the
  concepts.

  X3 Announces the Approval of a New Project, ISO/IEC 9075 Part 7:
  SQL/Temporal is a press release related to SQL/Temporal.

  ----------------------------------------------------------------------------
                                  Temporal SQL
                                  ************
  Rick Snodgrass (chair of the TSQL2 committee)
  31-Dec-1994

  Several people have questioned the need for additional support for time in
  SQL3 (as proposed by DBL RIO-75, requesting a new part of SQL to support
  temporal databases). The claim is that abstract data types (ADT's) are
  sufficient for temporal support. In this informational item, I argue, using
  concrete examples, that using columns typed with abstract data types is
  inadequate for temporal queries. In particular, many common temporal queries
  are either difficult to simulate in SQL, or require embedding SQL in a
  procedural language. Alternatives are expressed in TSQL2, a temporal
  extension to SQL-92.

  1. INTRODUCTION

  Valid-time support goes beyond that of a temporal ADT. With the latter, a
  column is specified as of a temporal domain, such as DATE or INTERVAL
  (examples will be given shortly). With valid time, the rows of a table vary
  over time, as reality changes. The timestamp associated with a row of a
  valid-time table is interpreted by the query language as the time when the
  combination of values of the columns in the row was valid. This implicit
  timestamp allows queries to be expressed succinctly and intuitively.

  2. A CASE STUDY

  2.1 STORING CURRENT INFORMATION

  The University of Arizona's Office of Appointed Personnel has some
  information in a database, including each employee's name, their current
  salary, and their current title. This can be represented by a simple table.

          Employee(Name, Salary, Title)

  Given this table, finding an employee's salary is easy.

          SELECT Salary

          FROM Employee

          WHERE Name = 'Bob'

  Now the OAP wishes to record the date of birth. To do so, a column is added
  to the table, yielding the following schema.

          Employee(Name, Salary, Title, DateofBirth DATE)

  Finding the employee's date of birth is analogous to determining the salary.

          SELECT DateofBirth

          FROM Employee

          WHERE Name = 'Bob'

  2.2 STORING HISTORY INFORMATION
  The OAP wishes to computerize the employment history. To do so, they append
  two columns, one indicating when the information in the row became valid,
  the other indicating when the information was no longer valid.

  Employee (Name, Salary, Title, DateofBirth, Start DATE, Stop DATE)

  To the data model, these new columns are identical to DateofBirth. However,
  their presence has wide-ranging consequences.

  2.3 PROJECTION

  To find an employee's current salary, things are more difficult.

          SELECT Salary

          FROM Employee

          WHERE Name = 'Bob' AND Start <= CURRENT_DATE AND CURRENT_DATE <= Stop

  This query is more complicated than the previous one. The culprit is
  obviously the two new columns. The OAP wants to distribute to each employee
  their salary history. Specifically, for each person, the maximal intervals
  at each salary needs to be determined. Unfortunately, this is not possible
  in SQL. An employee could have arbitrarily many title changes between salary
  changes.

  Name    Salary  Title             DateofBirth   Start           Stop

  ----    ------  -----             -----------   -----           ----

  Bob     60000   Assistant Provost 1945-04-09    1993-01-01      1993-05-30

  Bob     70000   Assistant Provost 1945-04-09    1993-06-01      1993-09-30

  Bob     70000   Provost           1945-04-09    1993-10-01      1994-01-31

  Bob     70000   Professor         1945-04-09    1994-02-01      1994-12-31

                                 Figure 1

  Note that there are three rows in which Bob's salary remained constant at
  $70,000. Hence, the result should be two rows for Bob.

  Name    Salary  Start           Stop

  ----    ------  -----           ----

  Bob     60000   1993-01-01      1993-05-30

  Bob     70000   1993-06-01      1994-12-31

  One alternative is to give the user a printout of Salary and Title
  information, and have user determine when his/her salary changed. This
  alternative is not very appealing or realistic. A second alternative is to
  use SQL as much as possible.

  CREATE TABLE Temp(Salary, Start, Stop)

  AS      SELECT Salary, Start, Stop

          FROM Employee;

  repeat

          UPDATE Temp T1

          SET (T1.Stop) = (SELECT MAX(T2.Stop)

                           FROM Temp AS T2

                           WHERE T1.Salary = T2.Salary AND T1.Start < T2.Start

                                  AND T1.Stop >= T2.Start AND T1.Stop < T2.Stop)

          WHERE EXISTS (SELECT *

                        FROM Temp AS T2

                        WHERE T1.Salary = T2.Salary AND T1.Start < T2.Start

                                  AND T1.Stop >= T2.Start AND T1.Stop < T2.Stop)

          until no rows updated;

  DELETE FROM Temp T1

  WHERE EXISTS (SELECT *

                FROM Temp AS T2

                WHERE T1.Salary = T2.Salary

                          AND ((T1.Start > T2.Start AND T1.Stop <= T2.Stop)

                          OR (T1.Start >= T2.Start AND T1.Stop < T2.Stop))

  The loop finds those intervals that overlap or are adjacent and thus should
  be merged. The loop is executed log N times in the worst case, where N is
  the number of rows in a chain of overlapping or adjacent value-equivalent
  rows. The reader can simulate the query on the example table to convince
  him/herself of its correctness.

  A third alternative is to use SQL only to open a cursor on the table. A
  linked list of periods is maintained, each with a salary. This linked list
  should be initialized to empty.

  DECLARE emp_cursor CURSOR FOR

          SELECT Salary, Title, Start, Stop

          FROM Employee;

  OPEN emp_cursor;

  loop:

          FETCH emp_cursor INTO :salary, :start, :stop;

          if no-data returned then goto finished;

          find position in linked list to insert this information;

          goto loop;

  finished:

  CLOSE emp_cursor;

  iterate through linked list, printing out dates and salaries

  The linked list may not be necessary in this case if the cursor is ORDER BY
  Start.
  In any case, the query, a natural one, is quite difficult to express using
  the facilities present in SQL-92. The query is trivial in TSQL2.

          SELECT Salary

          FROM Employee

  2.4 JOIN

  A more drastic approach is to avoid the problem of extracting the salary
  history by reorganizing the schema to separate salary, title, and date of
  birth information (in the following, we ignore the date of birth, for
  simplicity).

          Employee1 (Name, Salary, Start DATE, Stop DATE)

          Employee2 (Name, Title, Start DATE, Stop DATE)

  The Employee1 table is as follows.

  Name    Salary  Start           Stop

  ----    ------  -----           ----

  Bob     60000   1993-01-01      1993-05-30

  Bob     70000   1993-06-01      1993-12-31

  Here is the example Employee2 table.

  Name    Title                   Start           Stop

  ----    ------                  -----           ----

  Bob     Assistant Provost       1993-01-01      1993-09-30

  Bob     Provost                 1993-10-01      1994-01-31

  Bob     Professor               1994-02-01      1994-12-31

  With this change, getting the salary information for an employee is now
  easy.

          SELECT Salary, Start, Stop

          FROM Employee1

          WHERE Name = 'Bob'

  But what if the OAP wants a table of salary, title intervals (that is,
  suppose the OAP wishes a table to be computed in the form of Figure 1)? One
  alternative is to print out two tables, and let the user figure out the
  combinations. A second alternative is to use SQL entirely. Unfortunately,
  this query must do a case analysis of how each row of Employee1 overlaps
  each row of Employee2; there are four possible cases.

  SELECT Employee1.Name, Salary, Dept, Employee1.Start, Employee1.Stop

  FROM Employee1, Employee2

  WHERE Employee1.Name = Employee2.Name

       AND Employee2.Start <= Employee1.Start AND Employee1.Stop < Employee2.Stop

  UNION

  SELECT Employee1.Name, Salary, Dept, Employee1.Start, Employee2.Stop

  FROM Employee1, Employee2

  WHERE Employee1.Name = Employee2.Name

       AND Employee1.Start >= Employee2.Start AND Employee2.Stop < Employee1.Stop

          AND Employee1.Start < Employee2.Stop

  UNION

  SELECT Employee1.Name, Salary, Dept, Employee2.Start, Employee1.Stop

  FROM Employee1, Employee2

  WHERE Employee1.Name = Employee2.Name

       AND Employee2.Start > Employee1.Start AND Employee1.Stop < Employee2.Stop

          AND Employee2.Start < Employee1.Stop

  UNION

  SELECT Employee1.Name, Salary, Dept, Employee2.Start, Employee2.Stop

  FROM Employee1, Employee2

  WHERE Employee1.Name = Employee2.Name

       AND Employee2.Start > Employee1.Start AND Employee2.Stop < Employee1.Stop

  Getting all the cases right is a challenging task. In TSQL2, performing a
  temporal join is just what one would expect.

          SELECT Employee1.Name, Salary, Dept

          FROM Employee1, Employee2

          WHERE Employee1.Name = Employee2.Name

  2.5 AGGREGATES

  Now the OAP is asked, what is the maximum salary? Before adding time, this
  was easy.

          SELECT MAX(Salary)

          FROM Employee

  Now that the salary history is stored, we'd like a history of the maximum
  salary over time. The problem, of course, is that SQL does not provide
  temporal aggregates. The easy way to do this is to print out the
  information, and scan manually for the maximums. An alternative is to be
  tricky and convert the snapshot aggregate query into a non-aggregate query,
  then convert that into a temporal query. The non-aggregate query finds those
  salaries for which a greater salary does not exist.

          SELECT Salary

          FROM Employee AS E1

          WHERE NOT EXISTS (SELECT *

                            FROM Employee AS E2

                            WHERE E2.Salary > E1.Salary)

  Converting this query into a temporal query is far from obvious. The
  following is one approach.

  CREATE TABLE Temp (Salary, Start, Stop)

  AS      SELECT Salary, Start, Stop

          FROM Employee;

  INSERT INTO Temp

          SELECT T.Salary, T.Start, E.Start

          FROM Temp AS T, Employee AS E

          WHERE E.Start >= T.Start AND E.Start < T.Stop AND E.Salary > T.Salary;

  INSERT INTO Temp

          SELECT T.Salary, T.Stop, E.Stop

          FROM Temp AS T, Employee AS E

          WHERE E.Stop > T.Start AND E.Stop <= T.Stop AND E.Salary > T.Salary;

  DELETE FROM Temp T

  WHERE EXISTS (SELECT *

                FROM Employee AS E

                WHERE ((T.Start => E.Start AND T.Start < E.Stop)

                          OR (E.Start >= T.Start AND E.Start < T.Stop))

                      AND E.Salary > T.Salary;

  This approach creates an auxiliary table. We add to this table the lower
  period of a period subtraction and the upper period of a period subtraction.
  We then delete all periods that overlap with some row defined by the
  subquery, thereby effecting the NOT EXISTS. Finally we generate from the
  auxiliary table maximal periods, in the same way that the salary information
  was computed above. As one might imagine, such SQL code is extremely
  inefficient to execute, given the complex nested queries with inequality
  predicates.

  A third alternative is to use SQL as little as possible, and instead compute
  the desired maximum history in a host language using cursors.

  The query in TSQL2 is again straightforward and intuitive.

          SELECT MAX(Salary)

          FROM Employee

  3. SUMMARY

  Time-varying data is manipulated in most database applications. Valid-time
  support is absent in SQL. Many common temporal queries are either difficult
  to simulate in SQL, or require embedding SQL in a procedural language, due
  to SQL's lack of support for valid-time tables in its data model and query
  constructs.

  Elsewhere, we showed that adding valid-time support requires few changes to
  the DBMS implementation, can dramatically simplify some queries and enable
  others, and can later enable optimizations in storage structures, indexing
  methods, and optimization strategies that can yield significant performance
  improvements.

  With a new part of SQL3 supporting time-varying information, we can begin to
  address such applications, enabling SQL3 to better manage temporal data.

  ----------------------------------------------------------------------------
             Accredited Standards Committee* X3, Information Technology
  NEWS RELEASE

  Doc. No.:       PR/96-0002

  Reply to:       Barbara Bennett at bbennett@itic.nw.dc.us

               X3 Announces the Approval of a New Project, ISO/IEC

                           9075 Part 7:  SQL/Temporal

  Washington D.C., January 1996 -- Accredited Standards Committee

  X3, Information Technology is announcing the approval of a new

  project on SQL/Temporal Support, ISO/IEC 9075 Part 7, with the work

  being done in Technical Committee X3H2, Database.

  The scope of this proposed standard specifies a new Part of the emerging

  SQL3 standard, e.g., Part 7, Temporal SQL, to be extensions to the SQL

  language supporting storage, retrieval, and manipulation of temporal data

  in an SQL database environment.

  The next X3H2 meeting is scheduled for March 11-14, 1996 in

  Kansas.

  Inquiries regarding this project should be sent to the Chairman of

  X3H2, Dr. Donald R. Deutsch, Sybase, Inc., Suite 800, 6550 Rock Spring

  Drive, Bethesda, MD  20817.  Email: deutsch@sybase.com.

  An initial call for possible patents and other pertinent issues

  (copyrights, trademarks) is now being issued.  Please submit

  information on these issues to the X3 Secretariat at 1250 Eye Street

  NW, Suite 200, Washington DC  20005. Email: x3sec@itic.nw.dc.us

  FAX:  (202)638-4922.

  ----------------------------------------------------------------------------

  X3 Press Index

  X3 Home Page

  32.17.  Part 8 - ISO/ANSI SQL MULTIMEDIA (SQL/MM)

       A new ISO/IEC international standardization project for development of an
       SQL class library for multimedia applications was approved in early 1993.
       This new standardization activity, named SQL Multimedia (SQL/MM), will
       specify packages of SQL abstract data type (ADT) definitions using the
       facilities for ADT specification and invocation provided in the emerging
       SQL3 specification. SQL/MM intends to standardize class libraries for
       science and engineering, full-text and document processing, and methods for
       the management of multimedia objects such as image, sound, animation, music,
       and video. It will likely provide an SQL language binding for multimedia
       objects defined by other JTC1 standardization bodies (e.g. SC18 for
       documents, SC24 for images, and SC29 for photographs and motion pictures).

       The Project Plan for SQL/MM indicates that it will be a multi-part standard
       consisting of an evolving number of parts. Part 1 will be a Framework that
       specifies how the other parts are to be constructed. Each of the other parts
       will be devoted to a specific SQL application package. The following SQL/MM
       Part structure exists as of August 1994:

          * Part 1: Framework A non-technical description of how the document is
            structured.
          * Part 2: Full Text Methods and ADTs for text data processing. About 45
            pages.
          * Part 3: Spatial Methods and ADTs for spatial data management. About 200
            pages with active contributions from Spatial Data experts from 3
            national bodies.
          * Part 4: General Purpose Methods and ADTs for complex numbers,
            Facilities include trig and exponential functions, vectors, sets, etc.
            Currently about 90 pages.

       There are a number of standards efforts in the area of Spatial and
       Geographic information:

          * ANSI X3L1 - Geographic Information Systems.
            Mark Ashworth of Unisys is the liason between X3L1 and ANSI X3H2. He is
            also the editor for parts 1, 3, and 4 of the SQL/MM draft.
          * ISO TC 211 - Geographic information/Geomatics

       ----------------------------------------------------------------------------

  33.  Technical support for PostgreSQL

  If you have any technical question or encounter any problem you can e-
  mail to: pgsql-questions@postgresql.org and expect e-mail answer in
  less than a day. As the user-base of internet product is very vast,
  and users support other users, internet will be capable of giving
  technical support to billions of users easily. Email support is much
  more convenient than telephone support as you can cut and paste error
  messages, program output etc.. and easily transmit to mailing
  list/newsgroup.

  In the near future, PostgreSQL organisation will be selling technical
  support to large/small companies, the revenue generated will be used
  for maintaining several mirror sites (web and ftp) around the world.
  The revenue will also be used to produce printed documentation,
  guides, textbooks which will help the customers. The profits will also
  be used to construct buildings/class-rooms and offer technical courses
  in database administration/management and conduct annual user
  conferences.  This would help PostgreSQL organisation to stand on its
  feet.

  You can also take help from professional consulting firms like
  Anderson, WGS (Work Group Solutions). Contact them for help -

  ·  Work Group Solutions  <http://www.wgs.com>

  ·  Anderson Consulting  <http://www.ac.com>

  34.  Economic and Business Aspects

  Commercial databases pay many taxes like federal, state, sales,
  employment, social security, medicare taxes, health care for
  employees, bunch of benefits for employees, marketing and
  advertisement costs. All these costs do not go directly for the
  development of the database. When you buy a commercial database, some
  portion of the amount goes for overheads like taxes, expenses and
  balance for database R&D costs.

  Also commercial databases have to pay for buildings/real-estates and
  purchase Unix machines, install and maintain them. All of these costs
  are passed onto customers.

  PostgreSQL has the advantage over commercial databases as there is no
  direct tax since it is made on the internet. A very vast group of
  people contribute to the development of the PostgreSQL. For example,
  in a hypothetical case, if there are one million companies in U.S.A
  and each contribute about $ 10 (worth of software to PostgreSQL) than
  each and every company will get ten million dollars!! This is the
  magic of software development on internet.

  Currently, PostgreSQL source code is about 2,00,000 lines of "C",
  "C++" code. If cost of each line of "C" code is $ 10 than the total
  cost of PostgreSQL as of today is $ 2,000,000 (two million dollars!!).

  Many companies already develop in-house vast amount of "C", "C++"
  code. Hence by taking in the source code of PostgreSQL and
  collaborating with other companies on internet will greatly benefit
  the company saving time and efforts.

  35.  List of Other Databases

  Listed below are other SQL databases for Unix, Linux.

  ·  Click and go to Applications->databases.
     <http://www.caldera.com/tech-ref/linuxapps/linapps.html>

  ·  Click and go to Applications->databases.
     <http://www.xnet.com/~blatura/linapps.shtml>

  ·  Database resources  <http://linas.org/linux/db.html> This was
     written by Linas Vepstas: linas@fc.net

  ·  Free Database List
     <http://cuiwww.unige.ch:80/~scg/FreeDB/FreeDB.list.html>

  ·  Browne's RDBMS List <http://www.hex.net/~cbbrowne/rdbms.html>
     written by Christopher B. Browne cbbrowne@hex.net

  ·  SAL's List of Relational DBMS <http://SAL.KachinaTech.COM/H/1/>

  ·  SAL's List of Object-Oriented DBMS
     <http://SAL.KachinaTech.COM/H/2/>

  ·  SAL's List of Utilites and Other Databases
     <http://SAL.KachinaTech.COM/H/3/>

  ·  ACM SIGMOD Index of Publicly Available Database Software
     <http://bunny.cs.uiuc.edu/sigmod/databaseSoftware/>

  36.  Internet World Wide Web Searching Tips

  Internet is very vast and it has vast number of software and has a
  ocean of information underneath. It is growing at the rate of 500%
  annually world wide. It is estimated that there are about 90 million
  Web sites world wide!

  To search for a information you would use search engines like "Yahoo",
  "Netscape", "Lycos" etc. Go to Yahoo, click on search.  Use filtering
  options to narrow down your search criteria. The default search action
  is "Intelligent search" which is more general and lists all
  possiblities. Click on "Options" to select "EXACT phrase" search,
  "AND" search, "OR" search, etc.. This way you would find the
  information you need much faster.

  37.  Conclusion

  After researching all the available databases which are free and
  source code is available, it was found that ONLY PostgreSQL is the
  MOST mature, most widely used and robust RDBMS SQL free database
  (object relational) in the world.  PostgreSQL is very appealing as lot
  of work had already been done and it has ODBC, JDBC drivers using
  these it is possible to write applications independent of the
  databases. The applications written in PostgreSQL using ODBC, JDBC
  drivers are easily portable to other databases like Oracle, Sybase and
  Informix. And applications written for Oracle, Sybase and Informix
  using ODBC, JDBC drivers are easily portable to PostgreSQL database.

  38.  FAQ - Questions on PostgreSQL

  38.1.  Latest version of FAQ - Questions on PostgreSQL

  The FAQ is included here since not all the users have the browsers
  like Netscape and Internet access. Users may use GnuInfo, Ghostview,
  vi editor or man command. This document is generated in 10 different
  formats like GnuInfo, RTF, Plain-Text, Man page, Postscript etc.. and
  is distributed on Linux CDROMs.  Please refer to the latest version of
  FAQ which is at <http://www.postgresql.org/docs/faq-english.shtml> in
  case you have access to Internet."

  The FAQ is included here just for your convenience.

  38.2.  Extract of FAQ from main PostgreSQL Web site

  If you have access to internet, please click on this URL now for
  latest version

  ·  <http://www.postgresql.org/docs>

  Frequently Asked Questions (FAQ) for PostgreSQL

  Last updated: Mon Nov 17 19:47:15 EST 1997
  Version: 6.2.1

  Current maintainer: Bruce Momjian (maillist@candle.pha.pa.us)

  The most recent version of this document can be viewed at the postgreSQL
  Web site, http://postgreSQL.org.

  Linux-specific questions are answered in
  http://postgreSQL.org/docs/FAQ-linux.shtml.

  Irix-specific questions are answered in
  http://postgreSQL.org/docs/FAQ-irix.shtml.

  Changes in this version (* = modified, + = new):

  ---------------------------------------------------------------------------

  Questions answered:

  1) General questions

  1.1) What is PostgreSQL?
  1.2) What does PostgreSQL run on?
  1.3) Where can I get PostgreSQL?
  1.4) What's the copyright on PostgreSQL?
  1.5) Support for PostgreSQL
  1.6) Latest release of PostgreSQL
  1.7) Is there a commercial version of PostgreSQL?
  1.8) What documentation is available for PostgreSQL?
  1.9) What version of SQL does PostgreSQL use?
  1.10) Does PostgreSQL work with databases from earlier versions of
  postgres?
  1.11) Are there ODBC drivers for PostgreSQL?
  1.12) What tools are available for hooking postgres to Web pages?
  1.13) Does PostgreSQL have a graphical user interface? A report generator?
  A embedded query language interface?

  2) Installation/Configuration questions

  2.1) initdb doesn't run
  2.2) when I start up the postmaster, I get "FindBackend: could not find a
  backend to execute..." "postmaster: could not find backend to execute..."
  2.3) The system seems to be confused about commas, decimal points, and date
  formats.
  2.4) How do I install PostgreSQL somewhere other than /usr/local/pgsql?
  2.5) When I run postmaster, I get a Bad System Call core dumped message.
  2.6) When I try to start the postmaster, I get IpcMemoryCreate errors.
  2.7) I have changed a source file, but a recompile does not see the change?
  2.8) How do I prevent other hosts from accessing my PostgreSQL
  2.9) I can't access the database as the 'root' user.
  2.10) All my servers crash under concurrent table access. Why?
  2.11) How do I tune the database engine for better performance?
  2.12) What debugging features are available in PostgreSQL?
  2.13) How do I enable more than 32 concurrent backends?

  3) Operational questions

  3.1) Does PostgreSQL support nested subqueries?
  3.2) I've having a lot of problems using rules.
  3.3) I can't seem to write into the middle of large objects reliably.
  3.4) How can I write client applications to PostgreSQL?
  3.5) How do I set up a pg_group?
  3.6) What is the exact difference between binary cursors and normal
  cursors?
  3.7) What is a R-tree index and what is it used for?
  3.8) What is the maximum size for a tuple?
  3.9) I defined indices but my queries don't seem to make use of them. Why?
  3.10) How do I do regular expression searches? case-insensitive regexp
  searching?
  3.11) I experienced a server crash during a vacuum. How do I remove the
  lock file?
  3.12) What is the difference between the various character types?
  3.13) In a query, how do I detect if a field is NULL?
  3.14) How do I see how the query optimizer is evaluating my query?
  3.15) How do I create a serial field?
  3.16) What are the pg_psort.XXX files in my database directory?
  3.17) Why can't I connect to my database from another machine?
  3.18) How do I find out what indexes or operations are defined in the
  database?
  3.19) What is the time-warp feature and how does it relate to vacuum?
  3.20) What is an oid? What is a tid?
  3.21) What is the meaning of some of the terms used in Postgres?
  3.22) What is Genetic Query Optimization?
  3.23) How do you remove a column from a table?
  3.24) How do SELECT only the first few rows of a query?
  3.25) Why can't I create a column named "time"?

  4) Questions about extending PostgreSQL

  4.1) I wrote a user-defined function and when I run it in psql, it dumps
  core.
  4.2) I get messages of the type NOTICE:PortalHeapMemoryFree: 0x402251d0
  4.3) I've written some nifty new types and functions for PostgreSQL.
  4.4) How do I write a C function to return a tuple?

  5) Bugs

  5.1) How do I make a bug report?

  ---------------------------------------------------------------------------

  Section 1: General Questions

  1.1) What is PostgreSQL?

  PostgreSQL is an enhancement of the POSTGRES database management system, a
  next-generation DBMS research prototype. While PostgreSQL retains the
  powerful data model and rich data types of POSTGRES, it replaces the
  PostQuel query language with an extended subset of SQL. PostgreSQL is free
  and the complete source is available.

  PostgreSQL development is being performed by a team of Internet developers
  who all subscribe to the PostgreSQL development mailing list. The current
  coordinator is Marc G. Fournier (scrappy@postgreSQL.org). (See below on how
  to join). This team is now responsible for all current and future
  development of PostgreSQL.

  The authors of PostgreSQL 1.01 were Andrew Yu and Jolly Chen. Many others
  have contributed to the porting, testing, debugging and enhancement of the
  code. The original Postgres code, from which PostgreSQL is derived, was the
  effort of many graduate students, undergraduate students, and staff
  programmers working under the direction of Professor Michael Stonebraker at
  the University of California, Berkeley.

  The original name of the software at Berkeley was Postgres. When SQL
  functionality was added in 1995, its name was changed to Postgres95. The
  name was changed at the end of 1996 to PostgreSQL.

  1.2) What does PostgreSQL run on?
  The authors have compiled and tested PostgreSQL on the following
  platforms(some of these compiles require gcc 2.7.0):

     * aix - IBM on AIX 3.2.5 or 4.x
     * alpha - DEC Alpha AXP on Digital Unix 2.0, 3.2, 4.0
     * BSD44_derived - OSs derived from 4.4-lite BSD (NetBSD, FreeBSD)
     * bsdi - BSD/OS 2.0, 2.01, 2.1, 3.0
     * dgux - DG/UX 5.4R4.11
     * hpux - HP PA-RISC on HP-UX 9.0, 10
     * i386_solaris - i386 Solaris
     * irix5 - SGI MIPS on IRIX 5.3
     * linux - Intel x86 on Linux 2.0 and Linux ELF SPARC on Linux ELF PPC on
       Linux Elf (For non-ELF Linux, see LINUX_ELF below).
     * sco - SCO 3.2v5
     * sparc_solaris - SUN SPARC on Solaris 2.4, 2.5, 2.5.1
     * sunos4 - SUN SPARC on SunOS 4.1.3
     * svr4 - Intel x86 on Intel SVR4 and MIPS
     * ultrix4 - DEC MIPS on Ultrix 4.4

  The following platforms have known problems/bugs:

     * nextstep - Motorola MC68K or Intel x86 on NeXTSTEP 3.2

  1.3) Where can I get PostgreSQL?

  The primary anonymous ftp site for PostgreSQL is:

     * ftp://ftp.postgreSQL.org/pub

  A mirror site exists at:

     * ftp://postgres95.vnet.net/pub/postgres95
     * ftp://ftp.luga.or.at/pub/postgres95
     * ftp://cal011111.student.utwente.nl/pub/postgres95
     * ftp://ftp.uni-trier.de/pub/database/rdbms/postgres/postgres95
     * ftp://rocker.sch.bme.hu

  1.4) What's the copyright on PostgreSQL?

  PostgreSQL is subject to the following COPYRIGHT.

  PostgreSQL Data Base Management System

  Copyright (c) 1994-6 Regents of the University of California

  Permission to use, copy, modify, and distribute this software and its
  documentation for any purpose, without fee, and without a written agreement
  is hereby granted, provided that the above copyright notice and this
  paragraph and the following two paragraphs appear in all copies.

  IN NO EVENT SHALL THE UNIVERSITY OF CALIFORNIA BE LIABLE TO ANY PARTY FOR
  DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING
  LOST PROFITS, ARISING OUT OF THE USE OF THIS SOFTWARE AND ITS
  DOCUMENTATION, EVEN IF THE UNIVERSITY OF CALIFORNIA HAS BEEN ADVISED OF THE
  POSSIBILITY OF SUCH DAMAGE.

  THE UNIVERSITY OF CALIFORNIA SPECIFICALLY DISCLAIMS ANY WARRANTIES,
  INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
  AND FITNESS FOR A PARTICULAR PURPOSE. THE SOFTWARE PROVIDED HEREUNDER IS ON
  AN "AS IS" BASIS, AND THE UNIVERSITY OF CALIFORNIA HAS NO OBLIGATIONS TO
  PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.

  1.5) Support for PostgreSQL

  There is no official support for PostgreSQL from the original maintainers
  or from University of California, Berkeley. It is maintained through
  volunteer effort only.

  The main mailing list is: questions@postgreSQL.org. It is available for
  discussion o f matters pertaining to PostgreSQL, including but not limited
  to bug reports and fixes. For info on how to subscribe, send a mail with
  the lines in the body (not the subject line)

          subscribe
          end

  to questions-request@postgreSQL.org.

  There is also a digest list available. To subscribe to this list, send
  email to: questions-digest-request@postgreSQL.org with a BODY of:

          subscribe
          end

  Digests are sent out to members of this list whenever the main list has
  received around 30k of messages.

  There is a bugs mailing list available. To subscribe to this list, send
  email to bugs-request@postgreSQL.org with a BODY of:

  There is also a developers discussion mailing list available. To subscribe
  to this list, send email to hackers-request@postgreSQL.org with a BODY of:

          subscribe
          end

  Additional information about PostgreSQL can be found via the PostgreSQL WWW
  home page at:

       http://postgreSQL.org

  1.6) Latest release of PostgreSQL

  The latest release of PostgreSQL is version 6.2.1, which was released on
  October 17th, 1997. For information about what is new in 6.2.1, see our
  TODO list on our WWW page.

  We plan to have major releases every three months.

  1.7) Is there a commercial version of PostgreSQL?

  Illustra Information Technology (a wholly owned subsidiary of Informix
  Software, Inc.) sells an object-relational DBMS called Illustra that was
  originally based on postgres. Illustra has cosmetic similarities to
  PostgreSQL but has more features, is more robust, performs better, and
  offers real documentation and support. On the flip side, it costs money.
  For more information, contact sales@illustra.com

  1.8) What documentation is available for PostgreSQL?

  A user manual, manual pages, and some small test examples are included in
  the distribution. The sql and built-in manual pages are particularly
  important.

  The www page contains pointers to an implementation guide and five papers
  written about postgres design concepts and features.

  1.9) What version of SQL does PostgreSQL use?

  PostgreSQL supports a subset of SQL-92. It has most of the important
  constructs but lacks some of the functionality. The most visible
  differences are:
     * no support for nested subqueries
     * no HAVING clause under a GROUP BY

  On the other hand, you get to create user-defined types, functions,
  inheritance etc. If you're willing to help with PostgreSQL coding,
  eventually we can also add the missing features listed above.

  1.10) Does PostgreSQL work with databases from earlier versions of
  postgres?

  PostgreSQL v1.09 is compatible with databases created with v1.01.

  Upgrading to 6.2.1 from pre-6.2 requires a dump and restore.

  Upgrading to 6.2.1 from 6.2 does not require a dump, but see the
  appropriate /migration file in the distribution.

  Those ugrading from versions earlier than 1.09 must upgrade to 1.09 first
  without a dump/reload, then dump the data from 1.09, and then load it into
  6.2.1.

  1.11) Are there ODBC drivers for PostgreSQL?

  There are two ODBC drivers available, PostODBC and OpenLink ODBC.

  For all people being interested in PostODBC, there are now two mailing
  lists devoted to the discussion of PostODBC. The mailing lists are:

     * postodbc-users@listserv.direct. net
     * postodbc-developers@listse rv.direct.net

  these lists are ordinary majordomo mailing lists. You can subscribe by
  sending a mail to:

     * majordomo@listserv.direct.net

  OpenLink ODBC is very popular. You can get it from
  http://www.openlinksw.com/postgres.html. It works with our standard ODBC
  client software so you'll have Postgres ODBC available on every client
  platform we support (Win, Mac, Unix, VMS).

  We will probably be selling this product to people who need
  commercial-quality support, but a freeware version will always be
  available. Questions to postgres95@openlink.co.uk.

  1.12) What tools are available for hooking postgres to Web pages?

  For web integration, PHP is an excellent interface. The URL for that is
  http://php.iquest.net

  PHP is great for simple stuff, but for more complex stuff, some still use
  the perl interface and CGI.pm.

  An WWW gatway based on WDB using perl can be downloaded from:

     * http://www.eol.ists.ca/~dunlop/wdb -p95

  1.13) Does PostgreSQL have a graphical user interface? A report generator?
  A embedded query language interface?

  No. No. No. Not in the official distribution at least. Some users have
  reported some success at using 'pgbrowse' and 'onyx' as frontends to
  PostgreSQL. Several contributions are working on tk based frontend tools.
  Ask on the mailing list.

  ---------------------------------------------------------------------------
  Section 2: Installation Questions

  2.1) initdb doesn't run

     * check to see that you have the proper paths set
     * check that the 'postgres' user owns all the right files
     * ensure that there are files in $PGDATA/files, and that they are
       non-empty. If they aren't, then "gmake install" failed for some reason

  2.2) when I start up the postmaster, I get "FindBackend: could not find a
  backend to execute..." "postmaster: could not find backend to execute..."

  You probably do not have the right path set up. The 'postgres' executable
  needs to be in your path.

  2.3) The system seems to be confused about commas, decimal points, and date
  formats.

  Check your locale configuration. PostgreSQL uses the locale settings of the
  user that ran the postmaster process. Set those accordingly for your
  operating environment.

  2.4) How do I install PostgreSQL somewhere other than /usr/local/pgsql?

  You need to edit Makefile.global and change POSTGRESDIR accordingly, or
  create a Makefile.custom and define POSTGRESDIR there.

  2.5) When I run postmaster, I get a Bad System Call core dumped message.

  It could be a variety of problems, but first check to see that you have
  system V extensions installed on your kernel. PostgreSQL requires kernel
  support for shared memory.

  2.6) When I try to start the postmaster, I get IpcMemoryCreate errors.

  You either do not have shared memory configured properly in kernel or you
  need to enlarge the shared memory available in the kernel. The exact amount
  you need depends on your architecture and how many buffers you configure
  postmaster to run with. For most systems, with default buffer sizes, you
  need a minimum of ~760K.

  2.7) I have changed a source file, but a recompile does not see the change?

  The Makefiles do not have the proper dependencies for include files. You
  have to do a 'make clean' and then another 'make'.

  2.8) How do I prevent other hosts from accessing my PostgreSQL backend?

  Use host-based authentication by modifying the file $PGDATA/pg_hba
  accordingly.

  2.9) I can't access the database as the 'root' user.

  You should not create database users with user id 0(root). They will be
  unable to access the database. This is a security precaution because of the
  ability of any user to dynamically link object modules into the database
  engine.

  2.10) All my servers crash under concurrent table access. Why?

  This problem can be caused by a kernel that is not configured to support
  semaphores.

  2.11) How do I tune the database engine for better performance?

  There are two things that can be done. You can use Openlink's option to
  disable fsync() by starting the postmaster with a '-o -F' option. This will
  prevent fsync()'s from flushing to disk after every transaction.

  You can also use the postmaster -B option to increase the number of shared
  memory buffers shared among the backend processes. If you make this
  parameter too high, the process will not start or crash unexpectedly. Each
  buffer is 8K and the defualt is 64 buffers.

  You can also use the postmaster -S option to increase the maximum amount of
  memory used by each backend process for temporary sorts. Each buffer is 1K
  and the defualt is 512 buffers.

  2.12) What debugging features are available in PostgreSQL?

  PostgreSQL has several features that report status information that can be
  valuable for debugging purposes.

  First, by running configure with the -enable-cassert option, many
  assert()'s monitor the progress of the backend and halt the program when
  something unexpected occurs.

  Both postmaster and postgres have several debug options available. First,
  whenever you start the postmaster, make sure you send the standard output
  and error to a log file, like:

          cd /usr/local/pgsql
          ./bin/postmaster >server.log 2>&1 &

  This will put a server.log file in the top-level PostgreSQL directory. This
  file can contain useful information about problems or errors encountered by
  the server. Postmaster has a -d option that allows even more detailed
  information to be reported. The -d option takes a number 1-3 that specifies
  the debug level. Be warned that a debug level of 3 generates large log
  files.

  You can actuall run the postgres backend from the command line, and type
  your SQL statement directly. This is recommended ONLY for debugging
  purposes. Note that a newline terminates the query, not a semicolon. If you
  have compiled with debugging symbols, you can use a debugger to see what is
  happening. Because the backend was not started from the postmaster, it is
  not running in an identical environment and locking/backend interaction
  problems may not be duplicated. Some operating system can attach to a
  running backend directly to diagnose problems.

  The postgres program has a -s, -A, -t options that can be very useful for
  debugging and performance measurements.

  You can also compile with profiling to see what functions are taking
  execution time. The backend profile files will be deposited in the
  pgsql/data/base/dbname directory. The client profile file will be put in
  the current directory.

  The EXPLAIN command (see this FAQ) allows you to see how PostgreSQL is
  interpreting your query.

  2.13) How do I enable more than 32 concurrent backends?

  Edit include/storage/sinvaladt.h, and change the value of MaxBackendId. In
  the future, we plan to make this a configurable prameter.

  ---------------------------------------------------------------------------

  Section 3: PostgreSQL Features

  3.1) Does PostgreSQL support nested subqueries?

  Subqueries are not implemented, but they can be simulated using sql
  functions.

  3.2) I've having a lot of problems using rules.

  Currently, the rule system in PostgreSQL is mostly broken. It works enough
  to support the view mechanism, but that's about it. Use PostgreSQL rules at
  your own peril.

  3.3) I can't seem to write into the middle of large objects reliably.

  The Inversion large object system in PostgreSQL is also mostly broken. It
  works well enough for storing large wads of data and reading them back out,
  but the implementation has some underlying problems. Use PostgreSQL large
  objects at your own peril.

  3.4) How can I write client applications to PostgreSQL?

  PostgreSQL supports a C-callable library interface called libpq as well as
  many others. See the /src/interfaces directory.

  Others have contributed a perl interface and a WWW gateway to PostgreSQL.
  See the PostgreSQL home pages for more details.

  3.5) How do I set up a pg_group?

  Currently, there is no easy interface to set up user groups. You have to
  explicitly insert/update the pg_group table. For example:

          jolly=> insert into pg_group (groname, grosysid, grolist)
          jolly=>     values ('posthackers', '1234', '(5443, 8261)');
          INSERT 548224
          jolly=> grant insert on foo to group posthackers;
          CHANGE
          jolly=>

  The fields in pg_group are:

     * groname: the group name. This a char16 and should be purely
       alphanumeric. Do not include underscores or other punctuation.
     * grosysid: the group id. This is an int4. This should be unique for
       each group.
     * grolist: the list of pg_user id's that belong in the group. This is an
       int4[].

  3.6) What is the exact difference between binary cursors and normal
  cursors?

  See the declare manual page for a description.

  3.7) What is a R-tree index and what is it used for?

  An r-tree index is used for indexing spatial data. A hash index can't
  handle range searches. A B-tree index only handles range searches in a
  single dimension. R-tree's can handle multi-dimensional data. For example,
  if a R-tree index can be built on an attribute of type 'point', the system
  can more efficient answer queries like select all points within a bounding
  rectangle.

  The canonical paper that describes the original R-Tree design is:

  Guttman, A. "R-Trees: A Dynamic Index Structure for Spatial Searching."
  Proc of the 1984 ACM SIGMOD Int'l Conf on Mgmt of Data, 45-57.

  You can also find this paper in Stonebraker's "Readings in Database
  Systems"
  Builtin R-Trees can handle polygons and boxes. In theory, R-trees can be
  extended to handle higher number of dimensions. In practice, extending
  R-trees require a bit of work and we don't currently have any documentation
  on how to do it.

  3.8) What is the maximum size for a tuple?

  Tuples are limited to 8K bytes. Taking into account system attributes and
  other overhead, one should stay well shy of 8,000 bytes to be on the safe
  side. To use attributes larger than 8K, try using the large objects
  interface.

  Tuples do not cross 8k boundaries so a 5k tuple will require 8k of storage.

  3.9) I defined indices but my queries don't seem to make use of them. Why?

  PostgreSQL does not automatically maintain statistics. One has to make an
  explicit 'vacuum' call to update the statistics. After statistics are
  updated, the optimizer has a better shot at using indices. Note that the
  optimizer is limited and does not use indices in some circumstances (such
  as OR clauses). For column-specific optimization statistics, use 'vacuum
  analyze'.

  If the system still does not see the index, it is probably because you have
  created an index on a field with the improper *_ops type. For example, you
  have created a CHAR(4) field, but have specified a char_ops index
  type_class.

  See the create_index manual page for information on what type classes are
  available. It must match the field type.

  Postgres does not warn the user when the improper index is created.

  Indexes not used for ORDER BY operations.

  3.10) How do I do regular expression searches? case-insensitive regexp
  searching?

  See the pgbuiltin manual page. Search for regular expression.

  3.11) I experienced a server crash during a vacuum. How do I remove the
  lock file?

  See the vacuum manual page.

  3.12) What is the difference between the various character types?

  Type            Internal Name   Notes
  --------------------------------------------------
  CHAR            char            1 character   )
  CHAR2           char2           2 characters  )
  CHAR4           char4           4 characters  ) optimized for a fixed length
  CHAR8           char8           8 characters  )
  CHAR16          char16          16 characters )
  CHAR(#)         bpchar          blank padded to the specified fixed length
  VARCHAR(#)      varchar         size specifies maximum length, no padding
  TEXT            text            length limited only by maximum tuple length
  BYTEA           bytea           variable-length array of bytes

  Remember, you need to use the internal name when creating indexes on these
  fields or when doing other internal operations.

  The last four types above are "varlena" types (i.e. the first four bytes is
  the length, followed by the data). CHAR(#) and VARCHAR(#) allocate the
  maximum number of bytes no matter how much data is stored in the field.
  TEXT and BYTEA are the only character types that have variable length on
  the disk.

  3.13) In a query, how do I detect if a field is NULL?

  You test the column with IS NULL and IS NOT NULL.

  3.14) How do I see how the query optimizer is evaluating my query?

  See the explain manual page.

  3.15) How do I create a serial field?

  Postgres does not allow the user to specifiy a user column as type SERIAL.
  Instead, you can use each row's oid field as a unique value. However, if
  you need to dump and reload the database, you need to use pgdump's -o
  option or COPY's WITH OIDS option to preserver the oids.

  We also have a SEQUENCE function that is similar to SERIAL. See the
  create_sequence manual page.

  Another valid way of doing this is to create a function:

          create table my_oids (f1 int4);
          insert into my_oids values (1);
          create function new_oid () returns int4 as
                  'update my_oids set f1 = f1 + 1;  select f1 from my_oids; '
          language 'sql';

  then:

          create table my_stuff (my_key int4, value text);
          insert into my_stuff values (new_oid(), 'hello');

  However, keep in mind there is a race condition here where one server could
  do the update, then another one do an update, and they both could select
  the same new id. This statement should be performed within a transaction.

  Yet another way is to use general trigger function autoinc() from
  contrib/spi/autoinc.c.

  3.16) What are the pg_psort.XXX files in my database directory?

  They are temporary sort files generated by the query executor. For example,
  if a sort needs to be done to satisfy an ORDER BY, some temp files are
  generated as a result of the sort.

  If you have no transactions or sorts running at the time, it is safe to
  delete the pg_psort.XXX files.

  3.17) Why can't I connect to my database from another machine?

  The default configuration allows only connections from tcp/ip host
  localhost. You need to add a host entry to the file pgsql/data/pg_hba. See
  the hba_conf manual page.

  3.18) How do I find out what indexes or operations are defined in the
  database?

  Run the file pgsql/src/tutorial/syscat.source. It illustrates many of the

  3.19) What is the time-warp feature and how does it relate to vacuum?

  PostgreSQL handles data changes differently than most database systems.
  When a row is changed in a table, the original row is marked with the time
  it was changed, and a new row is created with the current data. By default,
  only current rows are used in a table. If you specify a date/time after the
  table name in a FROM clause, you can access the data that was current at
  that time, i.e.

          SELECT *
          FROM employees ['July 24, 1996 09:00:00']

  displays employee rows in the table at the specified time. You can specify
  intervals like [date,date], [date,], [,date], or [,]. This last option
  accesses all rows that ever existed.

  INSERTed rows get a timestamp too, so rows that were not in the table at
  the desired time will not appear.

  Vacuum removes rows that are no longer current. This time-warp feature is
  used by the engine for rollback and crash recovery. Expiration times can be
  set with purge.

  In 6.0, once a table is vacuumed, the creation time of a row may be
  incorrect, causing time-traval to fail.

  The time-travel feature will be removed in 6.3.

  3.20) What is an oid? What is a tid?

  Oids are Postgres's answer to unique row ids or serial columns. Every row
  that is created in Postgres gets a unique oid. All oids generated by initdb
  are less than 16384 (from backend/access/transam.h). All post-initdb
  (user-created) oids are equal or greater that this. All these oids are
  unique not only within a table, or database, but unique within the entire
  postgres installation.

  Postgres uses oids in its internal system tables to link rows in separate
  tables. These oids can be used to identify specific user rows and used in
  joins. It is recommended you use column type oid to store oid values. See
  the sql(l) manual page to see the other internal columns.

  Tids are used to indentify specific physical rows with block and offset
  values. Tids change after rows are modified or reloaded. They are used by
  index entries to point to physical rows. They can not be accessed through
  sql.

  3.21) What is the meaning of some of the terms used in Postgres?

  Some of the source code and older documentation use terms that have more
  common usage. Here are some:

     * row, record, tuple
     * attribute, field, column
     * table, class
     * retrieve, select
     * replace, update
     * append, insert
     * oid, serial value
     * portal, cursor
     * range variable, table name, table alias

  Please let me know if you think of any more.

  3.22) What is Genetic Query Optimization?

  The GEQO module in PostgreSQL is intended to solve the query optimization
  problem of joining many tables by means of a Genetic Algorithm (GA). It
  allows the handling of large join queries through non-exhaustive search.

  For further information see README.GEQO <utesch@aut.tu-freiberg.de>.

  3.23) How do you remove a column from a table?

  We do not support ALTER TABLE DROP COLUMN, but do this:

          SELECT ...  -- select all columns but the one you want to remove
          INTO TABLE new_table
          FROM old_table;
          DROP TABLE old_table;
          ALTER TABLE new_table RENAME TO old_table;

  3.24) How do SELECT only the first few rows of a query?

  See the fetch manual page.

  This only prevents all row results from being transfered to the client. The
  entire query must be evaluated, even if you only want just first few rows.
  Consider a query that has and ORDER BY. There is no way to return any rows
  until the entire query is evaluated and sorted.

  3.25) Why can't I create a column named "time"?

  6.2.1 has added some new restricted keywords as we make PostgreSQL more
  ANSI-92 compilant. The next release will have this restriction removed.
  There is a patch on ftp.postgresql.org that will allow this feature now.
  ---------------------------------------------------------------------------

  Section 4: Extending PostgreSQL

  4.1) I wrote a user-defined function and when I run it in psql, it dumps
  core.

  The problem could be a number of things. Try testing your user-defined
  function in a stand alone test program first. Also, make sure you are not
  sending elog NOTICES when the front-end is expecting data, such as during a
  type_in() or type_out() functions

  4.2) I get messages of the type NOTICE:PortalHeapMemoryFree: 0x402251d0 not
  in alloc set!

  You are pfree'ing something that was not palloc'ed. When writing
  user-defined functions, do not include the file "libpq-fe.h". Doing so will
  cause your palloc to be a malloc instead of a free. Then, when the backend
  pfrees the storage, you get the notice message.

  4.3) I've written some nifty new types and functions for PostgreSQL.

  Please share them with other PostgreSQL users. Send your extensions to
  mailing list, and they will eventually end up in the contrib/ subdirectory.

  4.4) How do I write a C function to return a tuple?

  This requires extreme wizardry, so extreme that the authors have not ever
  tried it, though in principle it can be done. The short answer is ... you
  can't. This capability is forthcoming in the future.

  ---------------------------------------------------------------------------

  Section 5: Bugs

  5.1) How do I make a bug report?

  Check the current FAQ at http://postgreSQL.org

  Also check out our ftp site ftp://ftp.postgreSQL.org/pub to see if there is
  a more recent PostgreSQL version.

  You can also fill out the "bug-template" file and send it to:

     * bugs@postgreSQL.org

  This is the address of the developers mailing list.

  39.  FAQ Linux-PostgreSQL

  39.1.  Latest version of FAQ Linux-PostgreSQL

  The FAQ is included here since not all the users have the browsers
  like Netscape and Internet access. Users may use GnuInfo, Ghostview,
  vi editor or man command to read the FAQ document.  This document is
  generated in 10 different formats like GnuInfo, RTF, Plain-Text, Man
  page, Postscript etc.. and is distributed on Linux CDROMs.  Please
  refer to the latest version of FAQ which is at
  <http://www.postgresql.org/docs/faq-english.shtml> in case you have
  access to Internet."

  The FAQ is included here just for your convenience.

  39.2.  Extract of Linux FAQ from main PostgreSQL Web site

  If you have access to internet, please click on this URL now for
  latest version

  ·  <http://www.postgresql.org/docs>

  =======================================================
  Frequently Asked Questions (FAQ) for PostgreSQL >= V6.1
  Linux Specific
  TO BE READ IN CONJUNCTION WITH THE NORMAL FAQ
  =======================================================
  last updated:           Wed Oct 01 11:45:00 BST 1997

  current maintainer:     Andrew C.R. Martin (martin@biochem.ucl.ac.uk)
  original author:        Andrew C.R. Martin (martin@biochem.ucl.ac.uk)

  Changes in this version (* = modified, + = new, - = removed):

  +3.9)   Why does Query 32 in the regression tests take so long?

  This file is divided approximately as follows:
  1.*)    Installing PostgreSQL
  2.*)    Compiling accessory programs
  3.*)    Runtime Problems

  Questions answered:
  1.1)    What changes do I need to make to src/Makefile.global or
          src/Makefile.custom and are there any other changes needed?
  1.2)    Why do I get problems with missing libreadline?
  1.3)    [REDHAT] Why do I get problems with missing libdl and dlfcn.h?
  1.4)    [SLACKWARE 3.1] Why do I get problems with missing libdl and dlfcn.h?
  1.5)    My compile of the backend dies complaining about the include file
          dlfcn.h missing
  1.6)    GCC complains about an ignored option -fpic
  1.7)    I get warnings of the form
          warning: cast from pointer to integer of different size
  1.8)    [SuSE-Linux 4.2-4.4] Where is curses and termcap?
  1.9)    Why do I get problems with ld.so?
  1.10)   Why do I get `yy_flush_buffer undefined' errors?
  1.11)   How do I compile PostgreSQL on an a.out system?
  1.12)   Why does make fail with:
          yacc -d /disk2/PostgreSQL/src/backend/parser/gram.y
          make: /usr/bin/make: cannot execute binary file
  1.13)   What are the references in X11_LIB to libsocket and libnsl in
          src/Makefile.global?
  1.14)   [DEBIAN] Where is libtermcap?
  1.15)   [REDHAT] Can I get PostgreSQL as an RPM?
  1.16)   While trying to compile a development version under Linux, compilation
          fails with a message like:
          In file included from /usr/include/sys/sem.h:8,
                   from ipc.c:37:
          /usr/include/asm/bitops.h:32: warning: no previous prototype for Set_bit'
          ....
          make: *** [ipc.o] Error 1
  1.17)   When compiling postgres, gcc reports signal 11 and aborts.
  1.18)   Can I install 6.1.1 under MkLinux?
  2.1)    The linker fails to find libX11 when compiling pgtclsh
  3.1)    I get an error reporting _fUnKy_POSTPORT_sTuFf_ undefined when
          running scripts like createuser
  3.2)    I run postmaster and after that system says 'Bad system call(Core
          dumped)'
  3.3)    When I try to start the Postmaster, why do I get an error of the form
          Failed Assertion("!(file != 0):(null)", File:
          "/usr/local/PostgreSQL/src/backend/storage/file/fd.c", Line: 257)
          !(file != 0) (0)
          initdb: could not create template database
          initdb: cleaning up.
  3.4)    Why doesn't createuser work?
  3.5)    Why do I get an error like:
          IpcMemoryCreate: memKey=155356396 , size=760632 ,
          permission=384IpcMemoryCreate: shmget(..., create, ...)
          failed: Invalid argument
  3.6)    Why does psql fail with:
          psql: can't load library 'libpq.so.1'
  3.7)    Other strange behaviour
  3.8)    When PostgreSQL is running when the system is shutdown, Linux
          always fsck's the disk when rebooted.
  3.9)    Why does Query 32 in the regression tests take so long?

  ----------------------------------------------------------------------
  Section 1:      Compiling PostgreSQL
  ----------------------------------------------------------------------

  1.1)    What changes do I need to make to src/Makefile.global or
          src/Makefile.custom and are there any other changes needed?

          Changes to the makefiles are most easily made by running the
          customize shell script in the src directory which will write a
          Makefile.custom for you.

          The only other change you may have to make is to replace
          Flex if you have version 2.5.3 which has a bug which generally
          manifests itself as createuser failing (See Question 3.4)

          If you modify the makefiles by hand, you *must* set the
          following variable:
                  PORTNAME=       linux

          You will also need to change the following to match your own
          installation:
                  POSTGRESDIR

          If you switch on the USE_TCL option, you will need to set these:
                  TCL_INCDIR=
                  TCL_LIBDIR=
                  TCL_LIB=
                  TK_INCDIR=
                  TK_LIBDIR=
                  TK_LIB=
                  X11_INCDIR=
                  X11_LIBDIR=
                  X11_LIB=

          On my Slackware3.0 system, these are:
                  TCL_INCDIR=     /usr/include/tcl
                  TCL_LIBDIR=     /usr/lib
                  TCL_LIB=        -ltcl
                  TK_INCDIR=      /usr/include/tcl
                  TK_LIBDIR=      /usr/lib
                  TK_LIB=         -ltk
                  X11_INCDIR=     /usr/include/X11
                  X11_LIBDIR=     /usr/X386/lib
                  X11_LIB=        -lX11

          You may also make any other changes you need as documented in
          the INSTALL file and in Makefile.global

  1.2)    Why do I get problems with missing libreadline?

          Linux systems generally don't come with the GNU readline library
          installed. Either ensure you do not activate the readline options
          in src/Makefile.global or src/Makefile.custom or install the GNU
          readline library.

          Note that Debian Linux (like FreeBSD) does come with readline
          installed.

  1.3)    [REDHAT] Why do I get problems with missing libdl and dlfcn.h?
          This manifests itself as being unable to link with functions
          such as dlopen(), dlclose(), etc. during the last phase of the
          compilation.

          The libdl library is used for dynamic linking of user-supplied
          functions at run-time. For some reason this library was missed out
          from the Redhat distribution. It seems that the latest Redhat 4.0
          (Colgate) fixes this.

          RedHat now have a new ld.so RPM package on their FTP site.
          Simply grab:

                  ftp://ftp.redhat.com/pub/redhat/devel/i386/RedHat/RPMS/ld.so-1.7.14-4.i386.rpm

          Install the RPM file in the usual way and off you go!

          There has been one report of a corrupted system resulting from
          programs accessing these libraries while updating them (not
          altogether surprising). Consequently it is a good idea to reboot
          the system before installing the new libraries and to
          have as little running as possible during this upgrade. Going
          into single-user mode is probably a good idea!

          If you want to do it the hard way, you can obtain the library and the
          header file from:

                  ftp://tsx-11.mit.edu/pub/linux/packages/GCC/ld.so-1.7.14.tar.gz

          Alternatively, you may find precompiled binaries in
          distributions/debian/buzz/binary-i386/base/ld.so-1.7.14-4.deb
          on the same site, or follow the instructions given for question 1.2 for
          correcting the same error with early releases of Slackware 3.1.
          Don't use this method unless you know what you are doing!

  1.4)    [SLACKWARE 3.1] Why do I get problems with missing libdl and dlfcn.h?

          This manifests itself as being unable to link with functions
          such as dlopen(), dlclose(), etc. during the last phase of the
          compilation.

          See the answer to question 1.3. Slackware up to version 3.0 was
          supplied with this library and include file and they seem to be
          back in again in the latest versions of 3.1, but the early 3.1
          releases (before 9th September 1996) had them missing and many
          CD-ROM versions will have been pressed from the first 3.1 releases.

          There has been one report of a corrupted system resulting from
          programs accessing these libraries while updating them (not
          altogether surprising). Consequently it is a good idea to reboot
          the system before installing the new libraries and to
          have as little running as possible during this upgrade. Going
          into single-user mode is probably a good idea!

          The easiest fix is to obtain the file ldso.tgz from the a4 disk of
          a more recent Slackware 3.1 distribution and unpack this file
          from the root (/) directory, then do

                  sh install/doinst.sh

          to complete the installation. Follow this with

                  ldconfig

          If you want to install manually, you must first install the file
          dlfcn.h in /usr/include.

          Second, install the file libdl.so.1.7.14 (or whatever the latest
          release is) in /lib, then do:

                  cd /lib
                  ln -sf libdl.so.1.7.14 libdl.so.1
                  ln -sf libdl.so.1 libdl.so

          On some systems (depending on your GCC configuration) it may be
          necessary to do:

                  cd /usr/lib
                  ln -sf /lib/libdl.so .

          Finally

                  ldconfig

  1.5)    My compile of the backend dies complaining about the include file
          dlfcn.h missing

          See the answer to question 1.3/1.4. Don't forget that if you are using
          an a.out system you must first have installed the dld package
          (which is not supplied with most a.out systems) to have dlfcn.h
          at all. See Question 1.11.

  1.6)    GCC complains about an ignored option -fpic

          Earlier versions of GCC accepted either -fpic or -fPIC.
          It appears that more recent versions (V2.7.2?) require -fPIC.
          If you are using an ELF version of Linux, this can safely be
          ignored as -fPIC is the default.

          You can correct this by editing src/Makefile.global and
          changing CFLAGS_SL

  1.7)    I get warnings of the form
          warning: cast from pointer to integer of different size

          These were seen in earlier versions of Postgres95 and could
          safely be ignored. PostgreSQL V6.0 should compile with no warnings
          except those related to system header files (which can also
          be safely ignored).

  1.8)    [SuSE-Linux 4.2-4.4] Where is curses and termcap?

          SuSE-Linux 4.2 has ncurses but not curses. 4.4 appears to have both.
          SuSE-Linux also has the termcap library is in /usr/lib/termcap
          instead of in /usr/lib.

          PostgreSQL (up to V6.0)
          -----------------------
          Set the value of CURSES_LIB in src/Makefile.custom to -lncurses
          (or do this through the customize script).
          Add the following line to src/Makefile.custom:

                  LDADD_BE+= -L/usr/lib/termcap

          You may need to edit src/bin/psql/Makefile and change:
                  ifeq ($(PORTNAME), linux)
                     LD_ADD+=
          to:
                  ifeq ($(PORTNAME), linux)
                     LD_ADD+= -ltermcap

          PostgreSQL (V6.1)
          -----------------
          The configure script doesn't know to look in /usr/lib/termcap for
          the termcap library, so you should specify this as one of the
          library directories when asked for additional directories to
          search.

          If this doesn't work (I don't have SuSE to verify that it does)
          then after running configure, you need to edit
          src/Makefile.global and add -ltermcap to the LDFLAGS line
          (after -lreadline).

          You may also wish to force use of ncurses rather than curses by
          changing -lcurses to -lncurses.

  1.9)    Why do I get problems with ld.so?

          If you get problems with ld.so, another library required under
          ELF for dynamic loading, then you have messed up your installation
          or (more likely) upgrade of Linux.

          See the answers to Question 1.3/1.4. You may need to install
          ld.so.x.y.z in /lib and run ldconfig.

          The most recent stable release of the ld package is 1.7.14
          At the time of writing, 1.8.x versions of ld are experimental.

  1.10)   Why do I get `yy_flush_buffer undefined' errors?

          This isn't really Linux specific, but is common on older Linux
          installations. You must have a recent version of flex (2.5.2 or later)
          to compile PostgreSQL. Note that flex 2.5.3 has a bug: see
          Question 3.4.

  1.11)   How do I compile PostgreSQL on an a.out system?

          First, you must install the dld library. This may be obtained
          from Sunsite as:
          Linux/libs/dld.3.2.7.tar.gz
          (ftp://sunsite.unc.edu/pub/Linux/libs/dld.3.2.7.tar.gz)

          Second, add the following line to src/Makefile.custom:
                  LINUX_ELF=
          (or use the customize script)

  1.12)   Why does make fail with:
          yacc -d /disk2/PostgreSQL/src/backend/parser/gram.y
          make: /usr/bin/make: cannot execute binary file

          This was a problem in earlier versions of Postgres95. The default
          for PostgreSQL is to use bison -y rather than yacc.

          yacc is generally implemented as a script which invokes bison -y
          For some reason (certain versions of make? certain versions of
          bash?) make is unable to execute this script file.

          To correct this, simply edit src/mk/port/postgres.mk.linux
          and, at the end of the file, change:
                  # YACC = bison -y
          to
                  YACC = bison -y

  1.13)   What are the references in X11_LIB to libsocket and libnsl in
          src/Makefile.global?

          This was a problem in 1.08 (they are Sun Solaris specific).
          It is fixed in 1.09 and 6.0

  1.14)   [DEBIAN] Where is libtermcap?

          Debian Linux comes without the termcap library and uses ncurses
          (which uses terminfo instead). There is no need to change the
          CURSES_LIB variable in src/bin/psql/Makefile since Debian provides
          a link from libncurses to libcurses (unlike SuSE-Linux --- see
          Question 1.8).

          You may need to edit src/bin/psql/Makefile and comment out the
          change:
                  ifeq ($(PORTNAME), linux)
                     LD_ADD+= -ltermcap
          to:
                  ifeq ($(PORTNAME), linux)
                     LD_ADD+=

  1.15)   [REDHAT] Can I get PostgreSQL as an RPM?

          Yes! Michal Mosiewicz
          (http://www.pdi.lodz.pl/~mimo) has kindly put together an RPM
          for PostgreSQL V6.0 on Intel architectures which he has uploaded to
          ftp://ftp.redhat.org/pub/Incoming/Postgres-6.0-1.i386.rpm

          This is a pre-compiled version, the source RPM is on its
          was as I write (3rd Feb 1997).

  1.16)   While trying to compile a development version under Linux, compilation
          fails with a message like:
          In file included from /usr/include/sys/sem.h:8,
                   from ipc.c:37:
          /usr/include/asm/bitops.h:32: warning: no previous prototype for Set_bit'
          ....
          make: *** [ipc.o] Error 1

          The problem is that Linux provides no prototypes for these
          inline functions. The solution is to go into the
          .../src/backend/storage/ipc directory and edit the Makefile.
          Change the line
             CFLAGS+=$(INCLUDE_OPT)
          to
             CFLAGS+=$(INCLUDE_OPT) -Wno-error

          Do the same in the ../src/backend/storage/lmgr directory.

  1.17)   When compiling postgres, gcc reports signal 11 and aborts.
          More specifically:
             gcc: Internal compiler error: program cc1 got fatal
                  signal 11

          This may be a hardware/memory problem. PortgreSQL is a big
          program, and large gcc compilations (such as building
          PostgreSQL or bebuilding the kernel) stress memory like
          few other programs, resulting in errors that do not occur
          in normal operation. Lesser operating systems are also
          unlikely to stress the hardware to this degree so you
          may never see any problems under DOS/Windows.

          More information on this problem at:
             http://www.bitwizard.nl/sig11

  1.18)   Can I install 6.1.1 under MkLinux?

          Tatsuo Ishii  has done this under
          MkLinux DR2.1 update2 after a small patch available from:
          ftp://ftp.sra.co.jp/pub/cmd/postgres/6.1.1/mklinux.patch.gz

  ----------------------------------------------------------------------
  Section 2:      Compiling accessory programs
  ----------------------------------------------------------------------

  2.1)    The linker fails to find libX11 when compiling pgtclsh

          Add the following to src/Makefile.custom
                  X11_LIBDIR = /usr/X11R6/lib

  ----------------------------------------------------------------------
  Section 3:      Runtime Problems
  ----------------------------------------------------------------------

  3.1)    I get an error reporting _fUnKy_POSTPORT_sTuFf_ undefined when
          running scripts like createuser

          This is a bug in V1.06-V1.07 of Postgres and is fixed in V1.08
          and above.

  3.2)    I run postmaster and after that system says 'Bad system call(Core
          dumped)'

          This indicates that you have not compiled shared memory support
          into your kernel. You need to recompile the Linux kernel to add this
          feature.

  3.3)    When I try to start the Postmaster, why do I get an error of the form
          Failed Assertion("!(file != 0):(null)", File:
          "/usr/local/PostgreSQL/src/backend/storage/file/fd.c", Line: 257)
          !(file != 0) (0)
          initdb: could not create template database
          initdb: cleaning up.

          Your permissions on the file /dev/null are wrong.

          ls -l /dev/null should give you something like:

                  crw-rw-rw-  1 root  wheel    2,   2 Oct  8 18:41 /dev/null

          Correct the permissions using:

                  chmod a+rw /dev/null

  3.4)    Why doesn't createuser work?

          There is a problem with Version 2.5.3 of GNU flex and createuser.
          Your options are to downgrade flex to V2.5.2, upgrade to V2.5.4
          or apply a patch to V2.5.3 which is supplied in doc/README.flex
          You may obtain V2.5.4 from
          ftp://prep.ai.mit.edu/pub/gnu/flex-2.5.4.tar.gz

  3.5)    Why do I get an error like:
          IpcMemoryCreate: memKey=155356396 , size=760632 ,
          permission=384IpcMemoryCreate: shmget(..., create, ...)
          failed: Invalid argument

          You haven't build IPC support into your Linux kernel. You
          will have to rebuild the kernel and switch on this option.

  3.6)    Why does psql fail with:
          psql: can't load library 'libpq.so.1'

          Psql has been compiled to link dynamically with the libpq
          library.

          To solve this, you should log in as root and edit the file
                  /etc/ld.so.conf
          Add a single line at the end which gives the name of the
          PostgreSQL library directory (the lib subdirectory of your
          PostgreSQL installation) and run
                  /sbin/ldconfig -v

          Alternatively, (and if you don't have root access), you may
          use the LD_LIBRARY_PATH environment variable.

          The LD_LIBRARY_PATH variable contains a colon separated list of
          paths to be searched for shared libraries.  This list is
          searched before the libraries specified by ldconfig.

          Therefore under Bash, you would do something like:
                  export LD_LIBRARY_PATH='PathToPGSQL'/lib
          or, using tcsh
                  setenv LD_LIBRARY_PATH 'PathToPGSQL'/lib
          replacing 'PathToPGSQL' with the appropriate path to your top level
          PostgreSQL directory

          Note that the ldd command can be used on a dynamically linked
          executable to list the paths to all the shared libraries upon
          which the executable depends.

  3.7)    Other strange behaviour

          I'm not sure what the symptoms might be except for nothing
          working properly, but it has been pointed out that one needs
          to be careful that the dynamic loader loads the correct version
          of the libpq library. If you have old versions lying around
          in your library path (for example in /usr/lib) these may get
          loaded instead of the new version you intended to load. Make
          sure you get them out of the way and look at Q3.6 for
          details of loading libraries.

  3.8)    When PostgreSQL is running when the system is shutdown, Linux
          always fsck's the disk when rebooted.

          There have been some reports of this happening and it seems
          to be a result of running PostgreSQL from /etc/inittab as
          suggested in the INSTALL document.

          You are therefore recommended to start the postmaster from an
          rc script. Under a Slackware-like release, you would modify
          /etc/rc.d/rc.local to start the postmaster. Under a RedHat-like
          release you should create a SysV style script in
          /etc/rc.d/rc3.d based on the /etc/rc.d/init.d skeleton file.

          There's a sample file in contrib/linux/postgres.init

          Here's another sample file supplied by John Robinson
           which you should modify as needed:

  #!/bin/sh
  #
  # postgreSQL.init This shell script takes care of starting and stopping
  #               the PostgreSQL postmaster.
  #

  # Source function library.
  \&. /etc/rc.d/init.d/functions

  # Source networking configuration.
  \&. /etc/sysconfig/network

  # Check that networking is up.
  [ $(NETWORKING) = "no" ] && exit 0

  # See how we were called.
  case "$1" in
    start)
          # Start daemons.
          echo -n "Starting postgres Postmaster daemon:"
          if [ -z "`pidofproc postmaster`" ]
          then
                  su postgres -c "/usr/local/pgsql/bin/postmaster -D /home/postgreSQL/data -p 5432 &"
                  echo -n " postmaster"
          else
                  echo -n " (already running)"
          fi
          echo
          touch /var/lock/subsys/postgres
          ;;
    stop)
          # Stop daemons.
          echo -n "Shutting down postgres Postmaster daemon: "
          killall -TERM postmaster 2>/dev/null
          killall -TERM postgres 2>/dev/null
          echo
          rm -f /var/lock/subsys/postgres
          ;;
    *)
          echo "Usage: postgres (start|stop)"
          exit 1
  esac

  exit 0

  3.9)    Why does Query 32 in the regression tests take so long?

          This is due to a bug in regression scripts which only happens
          on linux boxes. There are two workarounds as far as I know
          (information from Tatsuo Ishii ):

          1. change following in regress.sh:
                  time postgres -texecutor -tplanner -Q bench < bench.sql
          to:
                  postgres -texecutor -tplanner -Q bench < bench.sql

          2. after running the test, remove a line at the very end of
          bench.out something like:
                  85.86user 114.47system 4:49.20elapsed 69%CPU (0avgtext+0avgdata 0maxresident)k
          then type:
                  sh ./perquery < bench.out > & bench.out.perquery

  ----------------------------------------------------------------------------
  Dr. Andrew C.R. Martin                             University College London
  EMAIL: (Work) martin@biochem.ucl.ac.uk    (Home) andrew@stagleys.demon.co.uk
  URL:   http://www.biochem.ucl.ac.uk/~martin
  Tel:   (Work) +44(0)171 419 3890                    (Home) +44(0)1372 275775

  40.  FAQ IRIX-PostgreSQL

  40.1.  Latest version of FAQ IRIX-PostgreSQL

  The FAQ is included here since not all the users have the browsers
  like Netscape and Internet access. Users may use GnuInfo, Ghostview,
  vi editor or man command to read the FAQ document.  This document is
  generated in 10 different formats like GnuInfo, RTF, Plain-Text, Man
  page, Postscript etc.. and is distributed on Linux CDROMs.  Please
  refer to the latest version of FAQ which is at
  <http://www.postgresql.org/docs/faq-english.shtml> in case you have
  access to Internet."

  The FAQ is included here just for your convenience.

  40.2.  Extract of IRIX FAQ from main PostgreSQL Web site

  If you have access to internet, please click on this URL now for the
  latest version

  ·  <http://www.postgresql.org/docs>

  ======================================================
  Frequently Asked Questions (FAQ) for PostgreSQL >=V6.1
  IRIX Specific
  TO BE READ IN CONJUNCTION WITH THE NORMAL FAQ
  ======================================================
  last updated:           Mon Dec 04 10:20:00 GMT 1997

  current maintainer:     Andrew C.R. Martin (martin@biochem.ucl.ac.uk)
  original author:        Andrew C.R. Martin (martin@biochem.ucl.ac.uk)

  Changes in this version (* = modified, + = new, - = removed):
  +1.9)   Why does IRIX5 lex fail with PostgreSQL 6.2.1?

  This file is divided approximately as follows:
  1.*)    Installing PostgreSQL
  2.*)    Uninstalling PostgreSQL
  3.*)    Extending PostgreSQL

  Questions answered:
  1.1)    What extra items do I need to install PostgreSQL under Irix?
  1.2)    What changes do I need to make to src/Makefile.global?
  1.3)    What are the references in X11_LIB to libsocket and libnsl in
          src/Makefile.global?
  1.4)    Are there any other changes I should make?
  1.5)    Can I install PostgreSQL under Irix 6.x?
  1.6)    The make fails with the following message:
          ld32: ERROR 4: Conflicting flag setting: -call_shared
  1.7)    Why won't it link? (Problems with lorder)
  1.8)    I have major problems with IRIX 6!
  1.9)    Why does lex fail with PostgreSQL 6.2.1?
  2.1)    Why can't I move the executable files?
  3.1)    How do I compile a C program to create a function for extending
          PostgreSQL

  ----------------------------------------------------------------------
  Section 1:      Installing PostgreSQL
  ----------------------------------------------------------------------

  1.1)    What extra items do I need to install PostgreSQL under Irix?

          You *must* have the following installed:
          a) Gnu make (installed as gmake)

          You are recommended to install the following:
          a) GNU install (installed as ginstall)
             (This is part of the GNU fileutils package)

          You may choose to install the following:
          a) GNU readline library (if you wish psql to have readline
             support).
          b) tcl/tk (if you wish to compile pgtclsh)

  1.2)    What changes do I need to make to src/Makefile.global or
          src/Makefile.custom?

          The easiest way to do this is to use the customize script in
          the src directory.

          You *must* set the following variables:
                  PORTNAME=       irix5

          You will also need to change the following to match your own
          installation:
                  POSTGRESDIR

          If you switch on the USE_TCL option, you will need to set these:
                  TCL_INCDIR=
                  TCL_LIBDIR=
                  TCL_LIB =
                  TK_INCDIR=
                  TK_LIBDIR=
                  TK_LIB =

          You may also make any other changes you need as documented in
          the INSTALL file and in Makefile.global

  1.3)    What are the references in X11_LIB to libsocket and libnsl in
          src/Makefile.global?

          This was a problem in 1.08 (they are Sun Solaris specific).
          It is fixed in 1.09 and above.

  1.4)    Are there any other changes I should make?

          If you have installed the GNU install program (ginstall), you
          should add the following line to src/Makefile.custom:
                  CUSTOM_INSTALL=ginstall

          For an explanation as to why this is a good idea, see Question 2.1
          Ginstall is part of the GNU fileutils package.

  1.5)    Can I install PostgreSQL under Irix 6.x?

          Irix 6.2-6.4 has a bug in ld which mishandles the addresses of
          static procedures when object files are assembled into
          larger object files using 'ld -r'. This bug has been reported
          to Silicon Graphics.

          One option is to use the Gnu version of ld. Alternatively,
          the following patch should be applied as a workaround.
          (Supplied by Bob Bruccoleri )

  *** ./backend/Makefile.orig     Thu May 22 00:00:15 1997
  --- ./backend/Makefile  Thu Jun  5 16:47:27 1997
  ***************
  *** 54,60 ****
    all: postgres $(POSTGRES_IMP) global1.bki.source local1_template1.bki.source

    postgres: $(OBJS) ../utils/version.o
  !       $(CC) -o postgres $(OBJS) ../utils/version.o $(LDFLAGS)

    $(OBJS): $(DIRS:%=%.dir)

  --- 54,64 ----
    all: postgres $(POSTGRES_IMP) global1.bki.source local1_template1.bki.source

    postgres: $(OBJS) ../utils/version.o
  ! #     $(CC) -o postgres $(OBJS) ../utils/version.o $(LDFLAGS)
  !       -rm -f *.o
  !       find . -name "*.o" -exec cp \(\) . \;
  !       rm -f SUBSYS.o
  !       $(CC) -o postgres *.o ../utils/version.o $(LDFLAGS)

    $(OBJS): $(DIRS:%=%.dir)

  1.6)    The make fails with the following message:
          ld32: ERROR 4: Conflicting flag setting: -call_shared

          If gmake fails in .../src/backend while building obj/ACCESS.o
          with a message from ld32, you can work around this by using
          ld for the LD environment variable rather than cc.

          The problem has been observed under Irix 5.3 when compiling both
          Postgres95-1.09 and PostgreSQL-6.2Beta6, but on some systems
          these appear to compile with no such problems.

          Fix supplied by Brian Sanders (bsanders@netcom.com,
          brian@fresnelsoft.com)

  1.7)    Why won't it link? (Problems with lorder)

          According to the IRIX man pages, lorder is useless, but harmless
          under IRIX. However, it has caused problems for some people
          using both IRIX 6.2.

          The solution is to add the following line to
          .../src/makefiles/Makefile.irix5

          MK_NO_LORDER=true

  1.8)    I have major problems with IRIX 6!

          The following is quoted directly from Bob Bruccoleri

  There is a really nasty loader bug in the compiler system (7.1)
  on Irix 6.x, and the error that Lasse Petersen is the result of it.
  Here is the original message. I don't know if all the changes have been
  folded into the current release.

  Date: Fri, 06 Jun 1997 17:12:20 -0400 (EDT)
  From: bruc@bms.com (Robert Bruccoleri)
  Subject: [PORTS] Patches for Irix 6.4

  I have worked out how to compile PostgreSQL on Irix 6.4 using the -n32 compiler
  mode and version 7.1 of the C compiler. (The n32 compiler use 32 bits addressing,
  but allows access to all the instructions in the MIPS4 instruction set.)
  There were several problems:

  1) The ld command is not referenced as a macro in all the Makefiles. On
  this platform, you have to include -n32 on all the ld commands. Makefiles
  were changed as needed.

  2) There is a bug in "ld" which mishandles the addresses of static procedures
  when object files are assembled into larger object files using "ld -r".
  Because of this, I put a hack into src/backend/Makefile to avoid all the
  SUBSYS.o files and just link all the objects. I have contacted SGI about the
  problem, and hopefully, it will be fixed in the near future.

  3) Lots of warnings are generated from the compiler. Since the regression
  tests worked OK, I didn't attempt to fix them. If anyone wants the compilation
  log, please let me know, and I'll email it to you.

  The version of postgresql was 970602. Here is Makefile.custom:

  CUSTOM_COPT = -O2 -n32
  MK_NO_LORDER = 1
  LD = ld -n32
  CC += -n32

  Here are the patches:

  *** ./backend/access/Makefile.orig      Sun Nov 10 00:00:15 1996
  - --- ./backend/access/Makefile Tue Jun  3 10:22:32 1997
  ***************
  *** 8,13 ****
  - --- 8,16 ----
    #
    #-------------------------------------------------------------------------
  + SRCDIR = ../..
  + include ../../Makefile.global
  +
    OBJS = common/SUBSYS.o gist/SUBSYS.o hash/SUBSYS.o heap/SUBSYS.o \
           index/SUBSYS.o rtree/SUBSYS.o nbtree/SUBSYS.o transam/SUBSYS.o

  *** ./backend/bootstrap/Makefile.orig   Fri Apr 18 06:00:23 1997
  - --- ./backend/bootstrap/Makefile      Tue Jun  3 10:23:59 1997
  ***************
  *** 38,44 ****
    all: SUBSYS.o

    SUBSYS.o: $(OBJS)
  !       ld -r -o SUBSYS.o $(OBJS)

    # bootstrap.o's dependency on bootstrap_tokens.h is computed by the
    # make depend, but we state it here explicitly anyway because
  - --- 38,44 ----
    all: SUBSYS.o

    SUBSYS.o: $(OBJS)
  !       $(LD) -r -o SUBSYS.o $(OBJS)

    # bootstrap.o's dependency on bootstrap_tokens.h is computed by the
    # make depend, but we state it here explicitly anyway because

  *** ./backend/Makefile.orig     Thu May 22 00:00:15 1997
  - --- ./backend/Makefile        Thu Jun  5 16:47:27 1997
  ***************
  *** 54,60 ****
    all: postgres $(POSTGRES_IMP) global1.bki.source local1_template1.bki.source

    postgres: $(OBJS) ../utils/version.o
  !       $(CC) -o postgres $(OBJS) ../utils/version.o $(LDFLAGS)

    $(OBJS): $(DIRS:%=%.dir)

  - --- 54,64 ----
    all: postgres $(POSTGRES_IMP) global1.bki.source local1_template1.bki.source

    postgres: $(OBJS) ../utils/version.o
  ! #     $(CC) -o postgres $(OBJS) ../utils/version.o $(LDFLAGS)
  !       -rm -f *.o
  !       find . -name "*.o" -exec cp \(\) . \;
  !       rm -f SUBSYS.o
  !       $(CC) -o postgres *.o ../utils/version.o $(LDFLAGS)

    $(OBJS): $(DIRS:%=%.dir)

  ***************
  *** 116,122 ****
    install: $(LIBDIR) $(BINDIR) $(HEADERDIR) postgres $(POSTGRES_IMP) fmgr.h\
             global1.bki.source local1_template1.bki.source \
             libpq/pg_hba.conf.sample optimizer/geqo/pg_geqo.sample
  !
          $(INSTALL) $(INSTL_EXE_OPTS) postgres $(BINDIR)/postgres
    ifeq ($(MAKE_EXPORTS), true)
          $(INSTALL) $(INSTLOPTS) $(POSTGRES_IMP) $(LIBDIR)/$(POSTGRES_IMP)
  - --- 120,126 ----
    install: $(LIBDIR) $(BINDIR) $(HEADERDIR) postgres $(POSTGRES_IMP) fmgr.h\
             global1.bki.source local1_template1.bki.source \
             libpq/pg_hba.conf.sample optimizer/geqo/pg_geqo.sample
  !
          $(INSTALL) $(INSTL_EXE_OPTS) postgres $(BINDIR)/postgres
    ifeq ($(MAKE_EXPORTS), true)
          $(INSTALL) $(INSTLOPTS) $(POSTGRES_IMP) $(LIBDIR)/$(POSTGRES_IMP)
  *** ./backend/optimizer/Makefile.orig   Wed Feb 19 12:00:34 1997
  - --- ./backend/optimizer/Makefile      Tue Jun  3 10:39:47 1997
  ***************
  *** 8,13 ****
  - --- 8,16 ----
    #
    #-------------------------------------------------------------------------

  + SRCDIR= ../..
  + include ../../Makefile.global
  +
    all: submake SUBSYS.o

    OBJS = path/SUBSYS.o plan/SUBSYS.o prep/SUBSYS.o util/SUBSYS.o geqo/SUBSYS.o

  *** ./backend/libpq/pqcomprim.c.orig    Mon May 26 00:00:23 1997
  - --- ./backend/libpq/pqcomprim.c       Fri Jun  6 16:02:24 1997
  ***************
  *** 32,40 ****
    #    define hton_l(n) (ntoh_l(n))
    #  else       /* BYTE_ORDER != BIG_ENDIAN */
    #    if BYTE_ORDER == PDP_ENDIAN
  ! #      #error PDP_ENDIAN macros not written yet
    #    else     /* BYTE_ORDER !=  anything known */
  ! #      #error BYTE_ORDER not defined as anything understood
    #    endif    /* BYTE_ORDER == PDP_ENDIAN */
    #  endif      /* BYTE_ORDER == BIG_ENDIAN */
    #endif                /* BYTE_ORDER == LITTLE_ENDIAN */
  - --- 32,40 ----
    #    define hton_l(n) (ntoh_l(n))
    #  else       /* BYTE_ORDER != BIG_ENDIAN */
    #    if BYTE_ORDER == PDP_ENDIAN
  ! #      error PDP_ENDIAN macros not written yet
    #    else     /* BYTE_ORDER !=  anything known */
  ! #      error BYTE_ORDER not defined as anything understood
    #    endif    /* BYTE_ORDER == PDP_ENDIAN */
    #  endif      /* BYTE_ORDER == BIG_ENDIAN */
    #endif                /* BYTE_ORDER == LITTLE_ENDIAN */

  *** ./backend/storage/Makefile.orig     Sun Nov 10 00:01:06 1996
  - --- ./backend/storage/Makefile        Tue Jun  3 10:41:29 1997
  ***************
  *** 8,13 ****
  - --- 8,16 ----
    #
    #-------------------------------------------------------------------------

  + SRCDIR= ../..
  + include ../../Makefile.global
  +
    all: submake SUBSYS.o

    OBJS = buffer/SUBSYS.o file/SUBSYS.o ipc/SUBSYS.o large_object/SUBSYS.o \

  1.9)    Why does lex fail with PostgreSQL 6.2.1?

          IRIX 5.3 lex has been reported to fail in
          postgresql-6.2.1/src/backend/parser with the error:

          lex scan.l
          "scan.l":line 86: Error: Invalid request %x xc
          gmake[2]: *** [scan.c] Error 1

          The answer is to use GNU flex 2.5.4 or later. Use the command
             flex --version
          to check you have a new enough version of flex
  ----------------------------------------------------------------------
  Section 2:      Deinstalling PostgreSQL
  ----------------------------------------------------------------------

  2.1)    Why can't I move the executable files?

          By default, the IRIX port uses the BSD compatible version of
          install from /usr/bin/X11. If you read the man page for this
          version of install, you will see that it is not meant for
          end-user use; it has the interesting side-effect of chowning
          files it installs to root.

          You should still be able to delete the files as you (the
          postgres user) will own the directory in which they are
          stored.

          The normal IRIX install program cannot be used easily as it
          takes its arguments in the reverse order. It is therefore
          recommended to use the GNU version of install (ginstall).
          See Question 1.4

  ----------------------------------------------------------------------
  Section 3:      Extending PostgreSQL
  ----------------------------------------------------------------------
  3.1)    How do I compile a C program to create a function for extending
          PostgreSQL

          Here is a sample command line:

          cc -I/usr/local/PostgreSQL/include/ -I/usr/local/PostgreSQL/src/backend
                  -shared -o funcs.so funcs.c

  ----------------------------------------------------------------------------
  Dr. Andrew C.R. Martin                             University College London
  EMAIL: (Work) martin@biochem.ucl.ac.uk    (Home) andrew@stagleys.demon.co.uk
  URL:   http://www.biochem.ucl.ac.uk/~martin
  Tel:   (Work) +44(0)171 419 3890                    (Home) +44(0)1372 275775

  41.  Copyright Notice

  Copyright (c) 1997 Al Dev (Alavoor Vasudevan). All rights reserved.

  NO LIABILITY FOR CONSEQUENTIAL DAMAGES. In no event shall the author
  of this document be liable for any damages whatsoever (including
  without limitation, special, incidental, consequential, or
  direct/indirect damages for personal injury, loss of business profits,
  business interruption, loss of business information, or any other
  pecuniary loss) arising out of the use of this document.

  Author offers no warranties or guarantees on fitness, usablity,
  mechantability of this document. Brands, companies and product names
  mentioned in this document are trademarks or registered trademarks of
  their respective holders.  Please refer to individual copyright
  notices of brands, companies and products mentioned in this document.
  It is your responsibility to read and understand the copyright notices
  of the organisations/companies/products/authors mentioned in this
  document before using their respective information.

  42.  Appendix A - Syntax of ANSI/ISO SQL 1992

  This file contains a depth-first tree traversal of the BNF
  for the  language done at about 27-AUG-1992 11:03:41.64.
  The specific version of the BNF included here is:  ANSI-only, SQL2-only.

  <SQL terminal character> ::=
        <SQL language character>
      | <SQL embedded language character>

  <SQL language character> ::=
        <simple Latin letter>
      | <digit>
      | <SQL special character>

  <simple Latin letter> ::=
        <simple Latin upper case letter>
      | <simple Latin lower case letter>

  <simple Latin upper case letter> ::=
            A | B | C | D | E | F | G | H | I | J | K | L | M | N | O
      | P | Q | R | S | T | U | V | W | X | Y | Z

  <simple Latin lower case letter> ::=
            a | b | c | d | e | f | g | h | i | j | k | l | m | n | o
      | p | q | r | s | t | u | v | w | x | y | z

  <digit> ::=
      0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9

  <SQL special character> ::=
        <space>
      | <double quote>
      | <percent>
      | <ampersand>
      | <quote>
      | <left paren>
      | <right paren>
      | <asterisk>
      | <plus sign>
      | <comma>
      | <minus sign>
      | <period>
      | <solidus>
      | <colon>
      | <semicolon>
      | <less than operator>
      | <equals operator>
      | <greater than operator>
      | <question mark>
      | <underscore>
      | <vertical bar>

  <space> ::= !! <EMPHASIS>(space character in character set in use)

  <double quote> ::= "

  <percent> ::= %

  <ampersand> ::= &

  <quote> ::= '

  <left paren> ::= (

  <right paren> ::= )

  <asterisk> ::= *

  <plus sign> ::= +

  <comma> ::= ,

  <minus sign> ::= -

  <period> ::= .

  <solidus> ::= /

  <colon> ::= :

  <semicolon> ::= ;

  <less than operator> ::= <

  <equals operator> ::= =

  <greater than operator> ::= >

  <question mark> ::= ?

  <underscore> ::= _

  <vertical bar> ::= |

  <SQL embedded language character> ::=
        <left bracket>
      | <right bracket>

  <left bracket> ::= [

  <right bracket> ::= ]

  <token> ::=
        <nondelimiter token>
      | <delimiter token>

  <nondelimiter token> ::=
        <regular identifier>
      | <key word>
      | <unsigned numeric literal>
      | <national character string literal>
      | <bit string literal>
      | <hex string literal>

  <regular identifier> ::= <identifier body>

  <identifier body> ::=
      <identifier start> [ ( <underscore> | <identifier part> )... ]

  <identifier start> ::= <EMPHASIS>(!! See the Syntax Rules)

  <identifier part> ::=
        <identifier start>
      | <digit>

  <key word> ::=
        <reserved word>
      | <non-reserved word>

  <reserved word> ::=
        ABSOLUTE | ACTION | ADD | ALL
      | ALLOCATE | ALTER | AND
      | ANY | ARE
      | AS | ASC
      | ASSERTION | AT
      | AUTHORIZATION | AVG
      | BEGIN | BETWEEN | BIT | BIT_LENGTH
      | BOTH | BY
      | CASCADE | CASCADED | CASE | CAST
      | CATALOG
      | CHAR | CHARACTER | CHAR_LENGTH
      | CHARACTER_LENGTH | CHECK | CLOSE | COALESCE
      | COLLATE | COLLATION
      | COLUMN | COMMIT
      | CONNECT
      | CONNECTION | CONSTRAINT
      | CONSTRAINTS | CONTINUE
      | CONVERT | CORRESPONDING | COUNT | CREATE | CROSS
      | CURRENT
      | CURRENT_DATE | CURRENT_TIME
      | CURRENT_TIMESTAMP | CURRENT_USER | CURSOR
      | DATE | DAY | DEALLOCATE | DEC
      | DECIMAL | DECLARE | DEFAULT | DEFERRABLE
      | DEFERRED | DELETE | DESC | DESCRIBE | DESCRIPTOR
      | DIAGNOSTICS
      | DISCONNECT | DISTINCT | DOMAIN | DOUBLE | DROP
      | ELSE | END | END-EXEC | ESCAPE
      | EXCEPT | EXCEPTION
      | EXEC | EXECUTE | EXISTS
      | EXTERNAL | EXTRACT
      | FALSE | FETCH | FIRST | FLOAT | FOR
      | FOREIGN | FOUND | FROM | FULL
      | GET | GLOBAL | GO | GOTO
      | GRANT | GROUP
      | HAVING | HOUR
      | IDENTITY | IMMEDIATE | IN | INDICATOR
      | INITIALLY | INNER | INPUT
      | INSENSITIVE | INSERT | INT | INTEGER | INTERSECT
      | INTERVAL | INTO | IS
      | ISOLATION
      | JOIN
      | KEY
      | LANGUAGE | LAST | LEADING | LEFT
      | LEVEL | LIKE | LOCAL | LOWER
      | MATCH | MAX | MIN | MINUTE | MODULE
      | MONTH
      | NAMES | NATIONAL | NATURAL | NCHAR | NEXT | NO
      | NOT | NULL
      | NULLIF | NUMERIC
      | OCTET_LENGTH | OF
      | ON | ONLY | OPEN | OPTION | OR
      | ORDER | OUTER
      | OUTPUT | OVERLAPS
      | PAD | PARTIAL | POSITION | PRECISION | PREPARE
      | PRESERVE | PRIMARY
      | PRIOR | PRIVILEGES | PROCEDURE | PUBLIC
      | READ | REAL | REFERENCES | RELATIVE | RESTRICT
      | REVOKE | RIGHT
      | ROLLBACK | ROWS
      | SCHEMA | SCROLL | SECOND | SECTION
      | SELECT
      | SESSION | SESSION_USER | SET
      | SIZE | SMALLINT | SOME | SPACE | SQL | SQLCODE
      | SQLERROR | SQLSTATE
      | SUBSTRING | SUM | SYSTEM_USER
      | TABLE | TEMPORARY
      | THEN | TIME | TIMESTAMP
      | TIMEZONE_HOUR | TIMEZONE_MINUTE
      | TO | TRAILING | TRANSACTION
      | TRANSLATE | TRANSLATION | TRIM | TRUE
      | UNION | UNIQUE | UNKNOWN | UPDATE | UPPER | USAGE
      | USER | USING
      | VALUE | VALUES | VARCHAR | VARYING | VIEW
      | WHEN | WHENEVER | WHERE | WITH | WORK | WRITE
      | YEAR
      | ZONE

  <non-reserved word> ::=

        ADA
      | C | CATALOG_NAME
      | CHARACTER_SET_CATALOG | CHARACTER_SET_NAME
      | CHARACTER_SET_SCHEMA | CLASS_ORIGIN | COBOL | COLLATION_CATALOG
      | COLLATION_NAME | COLLATION_SCHEMA | COLUMN_NAME | COMMAND_FUNCTION
      | COMMITTED
      | CONDITION_NUMBER | CONNECTION_NAME | CONSTRAINT_CATALOG | CONSTRAINT_NAME
      | CONSTRAINT_SCHEMA | CURSOR_NAME
      | DATA | DATETIME_INTERVAL_CODE
      | DATETIME_INTERVAL_PRECISION | DYNAMIC_FUNCTION
      | FORTRAN
      | LENGTH
      | MESSAGE_LENGTH | MESSAGE_OCTET_LENGTH | MESSAGE_TEXT | MORE | MUMPS
      | NAME | NULLABLE | NUMBER
      | PASCAL | PLI
      | REPEATABLE | RETURNED_LENGTH | RETURNED_OCTET_LENGTH | RETURNED_SQLSTATE
      | ROW_COUNT
      | SCALE | SCHEMA_NAME | SERIALIZABLE | SERVER_NAME | SUBCLASS_ORIGIN
      | TABLE_NAME | TYPE
      | UNCOMMITTED | UNNAMED

  <unsigned numeric literal> ::=
        <exact numeric literal>
      | <approximate numeric literal>

  <exact numeric literal> ::=
        <unsigned integer> [ <period> [ <unsigned integer> ] ]
      | <period> <unsigned integer>

  <unsigned integer> ::= <digit>...

  <approximate numeric literal> ::= <mantissa> E <exponent>

  <mantissa> ::= <exact numeric literal>

  <exponent> ::= <signed integer>

  <signed integer> ::= [ <sign> ] <unsigned integer>

  <sign> ::= <plus sign> | <minus sign>

  <national character string literal> ::=
      N <quote> [ <character representation>... ] <quote>
        [ ( <separator>... <quote> [ <character representation>... ] <quote> )... ]

  <character representation> ::=
        <nonquote character>
      | <quote symbol>

  <nonquote character> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <quote symbol> ::= <quote><quote>

  <separator> ::= ( <comment> | <space> | <newline> )...

  <comment> ::=
      <comment introducer> [ <comment character>... ] <newline>

  <comment introducer> ::= <minus sign><minus sign>[<minus sign>...]

  <comment character> ::=
        <nonquote character>
      | <quote>

  <newline> ::= !! <EMPHASIS>(implementation-defined end-of-line indicator)

  <bit string literal> ::=
      B <quote> [ <bit>... ] <quote>
        [ ( <separator>... <quote> [ <bit>... ] <quote> )... ]

  <bit> ::= 0 | 1

  <hex string literal> ::=
      X <quote> [ <hexit>... ] <quote>
        [ ( <separator>... <quote> [ <hexit>... ] <quote> )... ]

  <hexit> ::= <digit> | A | B | C | D | E | F | a | b | c | d | e | f

  <delimiter token> ::=
        <character string literal>
      | <date string>
      | <time string>
      | <timestamp string>
      | <interval string>
      | <delimited identifier>
      | <SQL special character>
      | <not equals operator>
      | <greater than or equals operator>
      | <less than or equals operator>
      | <concatenation operator>
      | <double period>
      | <left bracket>
      | <right bracket>

  <character string literal> ::=
      [ <introducer><character set specification> ]
      <quote> [ <character representation>... ] <quote>
        [ ( <separator>... <quote> [ <character representation>... ] <quote> )... ]

  <introducer> ::= <underscore>

  <character set specification> ::=
        <standard character repertoire name>
      | <implementation-defined character repertoire name>
      | <user-defined character repertoire name>
      | <standard universal character form-of-use name>
      | <implementation-defined universal character form-of-use name>

  <standard character repertoire name> ::= <character set name>

  <character set name> ::= [ <schema name> <period> ]
        <SQL language identifier>

  <schema name> ::=
      [ <catalog name> <period> ] <unqualified schema name>

  <catalog name> ::= <identifier>

  <identifier> ::=
      [ <introducer><character set specification> ] <actual identifier>

  <actual identifier> ::=
        <regular identifier>
      | <delimited identifier>

  <delimited identifier> ::=
      <double quote> <delimited identifier body> <double quote>

  <delimited identifier body> ::= <delimited identifier part>...

  <delimited identifier part> ::=
        <nondoublequote character>
      | <doublequote symbol>

  <nondoublequote character> ::= <EMPHASIS>(!! See the Syntax Rules)

  <doublequote symbol> ::= <double quote><double quote>

  <unqualified schema name> ::= <identifier>

  <SQL language identifier> ::=
      <SQL language identifier start>
         [ ( <underscore> | <SQL language identifier part> )... ]

  <SQL language identifier start> ::= <simple Latin letter>

  <SQL language identifier part> ::=
        <simple Latin letter>
      | <digit>

  <implementation-defined character repertoire name> ::=
      <character set name>

  <user-defined character repertoire name> ::= <character set name>

  <standard universal character form-of-use name> ::=
      <character set name>

  <implementation-defined universal character form-of-use name> ::=
      <character set name>

  <date string> ::=
      <quote> <date value> <quote>

  <date value> ::=
      <years value> <minus sign> <months value>
          <minus sign> <days value>

  <years value> ::= <datetime value>

  <datetime value> ::= <unsigned integer>

  <months value> ::= <datetime value>

  <days value> ::= <datetime value>

  <time string> ::=
      <quote> <time value> [ <time zone interval> ] <quote>

  <time value> ::=
      <hours value> <colon> <minutes value> <colon> <seconds value>

  <hours value> ::= <datetime value>

  <minutes value> ::= <datetime value>

  <seconds value> ::=
        <seconds integer value> [ <period> [ <seconds fraction> ] ]

  <seconds integer value> ::= <unsigned integer>

  <seconds fraction> ::= <unsigned integer>

  <time zone interval> ::=
      <sign> <hours value> <colon> <minutes value>

  <timestamp string> ::=
      <quote> <date value> <space> <time value>
          [ <time zone interval> ] <quote>

  <interval string> ::=
      <quote> ( <year-month literal> | <day-time literal> ) <quote>

  <year-month literal> ::=
        <years value>
      | [ <years value> <minus sign> ] <months value>

  <day-time literal> ::=
        <day-time interval>
      | <time interval>

  <day-time interval> ::=
      <days value>
        [ <space> <hours value> [ <colon> <minutes value>
          [ <colon> <seconds value> ] ] ]

  <time interval> ::=
        <hours value> [ <colon> <minutes value> [ <colon> <seconds value> ] ]
      | <minutes value> [ <colon> <seconds value> ]
      | <seconds value>

  <not equals operator> ::= <>

  <greater than or equals operator> ::= >=

  <less than or equals operator> ::= <=

  <concatenation operator> ::= ||

  <double period> ::= ..

  <module> ::=
      <module name clause>
      <language clause>
      <module authorization clause>
      [ <temporary table declaration>... ]
      <module contents>...

  <module name clause> ::=
      MODULE [ <module name> ]
        [ <module character set specification> ]

  <module name> ::= <identifier>

  <module character set specification> ::=
      NAMES ARE <character set specification>

  <language clause> ::=
      LANGUAGE <language name>

  <language name> ::=
      ADA | C | COBOL | FORTRAN | MUMPS | PASCAL | PLI

  <module authorization clause> ::=
        SCHEMA <schema name>
      | AUTHORIZATION <module authorization identifier>
      | SCHEMA <schema name>
            AUTHORIZATION <module authorization identifier>

  <module authorization identifier> ::=
      <authorization identifier>

  <authorization identifier> ::= <identifier>

  <temporary table declaration> ::=
      DECLARE LOCAL TEMPORARY TABLE
          <qualified local table name>
        <table element list>
        [ ON COMMIT ( PRESERVE | DELETE ) ROWS ]

  <qualified local table name> ::=
      MODULE <period> <local table name>

  <local table name> ::= <qualified identifier>

  <qualified identifier> ::= <identifier>

  <table element list> ::=
        <left paren> <table element> [ ( <comma> <table element> )... ] <right paren>

  <table element> ::=
        <column definition>
      | <table constraint definition>

  <column definition> ::=
      <column name> ( <data type> | <domain name> )
      [ <default clause> ]
      [ <column constraint definition>... ]
      [ <collate clause> ]

  <column name> ::= <identifier>

  <data type> ::=
        <character string type>
             [ CHARACTER SET <character set specification> ]
      | <national character string type>
      | <bit string type>
      | <numeric type>
      | <datetime type>
      | <interval type>

  <character string type> ::=
        CHARACTER [ <left paren> <length> <right paren> ]
      | CHAR [ <left paren> <length> <right paren> ]
      | CHARACTER VARYING <left paren> <length> <right paren>
      | CHAR VARYING <left paren> <length> <right paren>
      | VARCHAR <left paren> <length> <right paren>

  <length> ::= <unsigned integer>

  <national character string type> ::=
        NATIONAL CHARACTER [ <left paren> <length> <right paren> ]
      | NATIONAL CHAR [ <left paren> <length> <right paren> ]
      | NCHAR [ <left paren> <length> <right paren> ]
      | NATIONAL CHARACTER VARYING <left paren> <length> <right paren>
      | NATIONAL CHAR VARYING <left paren> <length> <right paren>
      | NCHAR VARYING <left paren> <length> <right paren>

  <bit string type> ::=
        BIT [ <left paren> <length> <right paren> ]
      | BIT VARYING <left paren> <length> <right paren>

  <numeric type> ::=
        <exact numeric type>
      | <approximate numeric type>

  <exact numeric type> ::=
        NUMERIC [ <left paren> <precision> [ <comma> <scale> ] <right paren> ]
      | DECIMAL [ <left paren> <precision> [ <comma> <scale> ] <right paren> ]
      | DEC [ <left paren> <precision> [ <comma> <scale> ] <right paren> ]
      | INTEGER
      | INT
      | SMALLINT

  <precision> ::= <unsigned integer>

  <scale> ::= <unsigned integer>

  <approximate numeric type> ::=
        FLOAT [ <left paren> <precision> <right paren> ]
      | REAL
      | DOUBLE PRECISION

  <datetime type> ::=
        DATE
      | TIME [ <left paren> <time precision> <right paren> ]
            [ WITH TIME ZONE ]
      | TIMESTAMP [ <left paren> <timestamp precision> <right paren> ]
            [ WITH TIME ZONE ]

  <time precision> ::= <time fractional seconds precision>

  <time fractional seconds precision> ::= <unsigned integer>

  <timestamp precision> ::= <time fractional seconds precision>

  <interval type> ::= INTERVAL <interval qualifier>

  <interval qualifier> ::=
        <start field> TO <end field>
      | <single datetime field>

  <start field> ::=
      <non-second datetime field>
          [ <left paren> <interval leading field precision> <right paren> ]

  <non-second datetime field> ::= YEAR | MONTH | DAY | HOUR
      | MINUTE

  <interval leading field precision> ::= <unsigned integer>

  <end field> ::=
        <non-second datetime field>
      | SECOND [ <left paren> <interval fractional seconds precision> <right paren> ]

  <interval fractional seconds precision> ::= <unsigned integer>

  <single datetime field> ::=
        <non-second datetime field>
            [ <left paren> <interval leading field precision> <right paren> ]
      | SECOND [ <left paren> <interval leading field precision>
            [ <comma> <interval fractional seconds precision> ] <right paren> ]

  <domain name> ::= <qualified name>

  <qualified name> ::=
      [ <schema name> <period> ] <qualified identifier>

  <default clause> ::=
        DEFAULT <default option>

  <default option> ::=
        <literal>
      | <datetime value function>
      | USER
      | CURRENT_USER
      | SESSION_USER
      | SYSTEM_USER
      | NULL

  <literal> ::=
        <signed numeric literal>
      | <general literal>

  <signed numeric literal> ::=
      [ <sign> ] <unsigned numeric literal>

  <general literal> ::=
        <character string literal>
      | <national character string literal>
      | <bit string literal>
      | <hex string literal>
      | <datetime literal>
      | <interval literal>

  <datetime literal> ::=
        <date literal>
      | <time literal>
      | <timestamp literal>

  <date literal> ::=
      DATE <date string>

  <time literal> ::=
      TIME <time string>

  <timestamp literal> ::=
      TIMESTAMP <timestamp string>

  <interval literal> ::=
      INTERVAL [ <sign> ] <interval string> <interval qualifier>

  <datetime value function> ::=
        <current date value function>
      | <current time value function>
      | <current timestamp value function>

  <current date value function> ::= CURRENT_DATE

  <current time value function> ::=
        CURRENT_TIME [ <left paren> <time precision> <right paren> ]

  <current timestamp value function> ::=
        CURRENT_TIMESTAMP [ <left paren> <timestamp precision> <right paren> ]

  <column constraint definition> ::=
      [ <constraint name definition> ]
      <column constraint>
        [ <constraint attributes> ]

  <constraint name definition> ::= CONSTRAINT <constraint name>
  <constraint name> ::= <qualified name>

  <column constraint> ::=
        NOT NULL
      | <unique specification>
      | <references specification>
      | <check constraint definition>

  <unique specification> ::=
      UNIQUE | PRIMARY KEY

  <references specification> ::=
      REFERENCES <referenced table and columns>
        [ MATCH <match type> ]
        [ <referential triggered action> ]

  <referenced table and columns> ::=
       <table name> [ <left paren> <reference column list> <right paren> ]

  <table name> ::=
        <qualified name>
      | <qualified local table name>

  <reference column list> ::= <column name list>

  <column name list> ::=
      <column name> [ ( <comma> <column name> )... ]

  <match type> ::=
        FULL
      | PARTIAL

  <referential triggered action> ::=
        <update rule> [ <delete rule> ]
      | <delete rule> [ <update rule> ]

  <update rule> ::= ON UPDATE <referential action>

  <referential action> ::=
        CASCADE
      | SET NULL
      | SET DEFAULT
      | NO ACTION

  <delete rule> ::= ON DELETE <referential action>

  <check constraint definition> ::=
      CHECK
          <left paren> <search condition> <right paren>

  <search condition> ::=
        <boolean term>
      | <search condition> OR <boolean term>

  <boolean term> ::=
        <boolean factor>
      | <boolean term> AND <boolean factor>

  <boolean factor> ::=
      [ NOT ] <boolean test>

  <boolean test> ::=
      <boolean primary> [ IS [ NOT ]
            <truth value> ]

  <boolean primary> ::=
        <predicate>
      | <left paren> <search condition> <right paren>

  <predicate> ::=
        <comparison predicate>
      | <between predicate>
      | <in predicate>
      | <like predicate>
      | <null predicate>
      | <quantified comparison predicate>
      | <exists predicate>
      | <unique predicate>
      | <match predicate>
      | <overlaps predicate>

  <comparison predicate> ::=
      <row value constructor> <comp op>
          <row value constructor>

  <row value constructor> ::=
         <row value constructor element>
      | <left paren> <row value constructor list> <right paren>
      | <row subquery>

  <row value constructor element> ::=
        <value expression>
      | <null specification>
      | <default specification>

  <value expression> ::=
        <numeric value expression>
      | <string value expression>
      | <datetime value expression>
      | <interval value expression>

  <numeric value expression> ::=
        <term>
      | <numeric value expression> <plus sign> <term>
      | <numeric value expression> <minus sign> <term>

  <term> ::=
        <factor>
      | <term> <asterisk> <factor>
      | <term> <solidus> <factor>

  <factor> ::=
      [ <sign> ] <numeric primary>

  <numeric primary> ::=
        <value expression primary>
      | <numeric value function>

  <value expression primary> ::=
        <unsigned value specification>
      | <column reference>
      | <set function specification>
      | <scalar subquery>
      | <case expression>
      | <left paren> <value expression> <right paren>
      | <cast specification>

  <unsigned value specification> ::=
        <unsigned literal>
      | <general value specification>

  <unsigned literal> ::=
        <unsigned numeric literal>
      | <general literal>

  <general value specification> ::=
        <parameter specification>
      | <dynamic parameter specification>
      | <variable specification>
      | USER
      | CURRENT_USER
      | SESSION_USER
      | SYSTEM_USER
      | VALUE

  <parameter specification> ::=
      <parameter name> [ <indicator parameter> ]

  <parameter name> ::= <colon> <identifier>

  <indicator parameter> ::=
      [ INDICATOR ] <parameter name>

  <dynamic parameter specification> ::= <question mark>

  <variable specification> ::=
      <embedded variable name> [ <indicator variable> ]

  <embedded variable name> ::=
      <colon><host identifier>

  <host identifier> ::=
        <Ada host identifier>
      | <C host identifier>
      | <COBOL host identifier>
      | <Fortran host identifier>
      | <MUMPS host identifier>
      | <Pascal host identifier>
      | <PL/I host identifier>

  <Ada host identifier> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <C host identifier> ::=
      !! <EMPHASIS>(See the Syntax Rules.)

  <COBOL host identifier> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <Fortran host identifier> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <MUMPS host identifier> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <Pascal host identifier> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <PL/I host identifier> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <indicator variable> ::=
      [ INDICATOR ] <embedded variable name>

  <column reference> ::= [ <qualifier> <period> ] <column name>

  <qualifier> ::=
        <table name>
      | <correlation name>

  <correlation name> ::= <identifier>

  <set function specification> ::=
        COUNT <left paren> <asterisk> <right paren>
      | <general set function>

  <general set function> ::=
        <set function type>
            <left paren> [ <set quantifier> ] <value expression> <right paren>

  <set function type> ::=
      AVG | MAX | MIN | SUM | COUNT

  <set quantifier> ::= DISTINCT | ALL

  <scalar subquery> ::= <subquery>

  <subquery> ::= <left paren> <query expression> <right paren>

  <query expression> ::=
        <non-join query expression>
      | <joined table>

  <non-join query expression> ::=
        <non-join query term>
      | <query expression> UNION  [ ALL ]
            [ <corresponding spec> ] <query term>
      | <query expression> EXCEPT [ ALL ]
            [ <corresponding spec> ] <query term>

  <non-join query term> ::=
        <non-join query primary>
      | <query term> INTERSECT [ ALL ]
            [ <corresponding spec> ] <query primary>

  <non-join query primary> ::=
        <simple table>
      | <left paren> <non-join query expression> <right paren>

  <simple table> ::=
        <query specification>
      | <table value constructor>
      | <explicit table>

  <query specification> ::=
      SELECT [ <set quantifier> ] <select list> <table expression>

  <select list> ::=
        <asterisk>
      | <select sublist> [ ( <comma> <select sublist> )... ]

  <select sublist> ::=
        <derived column>
      | <qualifier> <period> <asterisk>

  <derived column> ::= <value expression> [ <as clause> ]

  <as clause> ::= [ AS ] <column name>

  <table expression> ::=
      <from clause>
      [ <where clause> ]
      [ <group by clause> ]
      [ <having clause> ]

  <from clause> ::= FROM <table reference>
      [ ( <comma> <table reference> )... ]

  <table reference> ::=
        <table name> [ [ AS ] <correlation name>
            [ <left paren> <derived column list> <right paren> ] ]
      | <derived table> [ AS ] <correlation name>
            [ <left paren> <derived column list> <right paren> ]
      | <joined table>

  <derived column list> ::= <column name list>

  <derived table> ::= <table subquery>

  <table subquery> ::= <subquery>

  <joined table> ::=
        <cross join>
      | <qualified join>
      | <left paren> <joined table> <right paren>

  <cross join> ::=
      <table reference> CROSS JOIN <table reference>

  <qualified join> ::=
      <table reference> [ NATURAL ] [ <join type> ] JOIN
        <table reference> [ <join specification> ]

  <join type> ::=
        INNER
      | <outer join type> [ OUTER ]
      | UNION

  <outer join type> ::=
        LEFT
      | RIGHT
      | FULL

  <join specification> ::=
        <join condition>
      | <named columns join>

  <join condition> ::= ON <search condition>

  <named columns join> ::=
      USING <left paren> <join column list> <right paren>

  <join column list> ::= <column name list>

  <where clause> ::= WHERE <search condition>

  <group by clause> ::=
      GROUP BY <grouping column reference list>

  <grouping column reference list> ::=
      <grouping column reference>
          [ ( <comma> <grouping column reference> )... ]

  <grouping column reference> ::=
      <column reference> [ <collate clause> ]

  <collate clause> ::= COLLATE <collation name>

  <collation name> ::= <qualified name>

  <having clause> ::= HAVING <search condition>

  <table value constructor> ::=
      VALUES <table value constructor list>

  <table value constructor list> ::=
      <row value constructor> [ ( <comma> <row value constructor> )... ]

  <explicit table> ::= TABLE <table name>

  <query term> ::=
        <non-join query term>
      | <joined table>

  <corresponding spec> ::=
      CORRESPONDING [ BY <left paren> <corresponding column list> <right paren> ]

  <corresponding column list> ::= <column name list>

  <query primary> ::=
        <non-join query primary>
      | <joined table>

  <case expression> ::=
        <case abbreviation>
      | <case specification>

  <case abbreviation> ::=
        NULLIF <left paren> <value expression> <comma>
              <value expression> <right paren>
      | COALESCE <left paren> <value expression>
              ( <comma> <value expression> )... <right paren>

  <case specification> ::=
        <simple case>
      | <searched case>

  <simple case> ::=
      CASE <case operand>
        <simple when clause>...
        [ <else clause> ]
      END

  <case operand> ::= <value expression>

  <simple when clause> ::= WHEN <when operand> THEN <result>

  <when operand> ::= <value expression>

  <result> ::= <result expression> | NULL

  <result expression> ::= <value expression>

  <else clause> ::= ELSE <result>

  <searched case> ::=
      CASE
        <searched when clause>...
        [ <else clause> ]
      END

  <searched when clause> ::= WHEN <search condition> THEN <result>

  <cast specification> ::=
      CAST <left paren> <cast operand> AS
          <cast target> <right paren>

  <cast operand> ::=
        <value expression>
      | NULL

  <cast target> ::=
        <domain name>
      | <data type>

  <numeric value function> ::=
        <position expression>
      | <extract expression>
      | <length expression>

  <position expression> ::=
      POSITION <left paren> <character value expression>
          IN <character value expression> <right paren>

  <character value expression> ::=
        <concatenation>
      | <character factor>

  <concatenation> ::=
      <character value expression> <concatenation operator>
          <character factor>

  <character factor> ::=
      <character primary> [ <collate clause> ]

  <character primary> ::=
        <value expression primary>
      | <string value function>

  <string value function> ::=
        <character value function>
      | <bit value function>

  <character value function> ::=
        <character substring function>
      | <fold>
      | <form-of-use conversion>
      | <character translation>
      | <trim function>

  <character substring function> ::=
      SUBSTRING <left paren> <character value expression> FROM <start position>
                  [ FOR <string length> ] <right paren>

  <start position> ::= <numeric value expression>

  <string length> ::= <numeric value expression>

  <fold> ::= ( UPPER | LOWER )
       <left paren> <character value expression> <right paren>

  <form-of-use conversion> ::=
      CONVERT <left paren> <character value expression>
          USING <form-of-use conversion name> <right paren>

  <form-of-use conversion name> ::= <qualified name>

  <character translation> ::=
      TRANSLATE <left paren> <character value expression>
          USING <translation name> <right paren>

  <translation name> ::= <qualified name>

  <trim function> ::=
      TRIM <left paren> <trim operands> <right paren>

  <trim operands> ::=
      [ [ <trim specification> ] [ <trim character> ] FROM ] <trim source>
  <trim specification> ::=
        LEADING
      | TRAILING
      | BOTH

  <trim character> ::= <character value expression>

  <trim source> ::= <character value expression>

  <bit value function> ::=
      <bit substring function>

  <bit substring function> ::=
      SUBSTRING <left paren> <bit value expression> FROM <start position>
          [ FOR <string length> ] <right paren>

  <bit value expression> ::=
        <bit concatenation>
      | <bit factor>

  <bit concatenation> ::=
      <bit value expression> <concatenation operator> <bit factor>

  <bit factor> ::= <bit primary>

  <bit primary> ::=
        <value expression primary>
      | <string value function>

  <extract expression> ::=
      EXTRACT <left paren> <extract field>
          FROM <extract source> <right paren>

  <extract field> ::=
        <datetime field>
      | <time zone field>

  <datetime field> ::=
        <non-second datetime field>
      | SECOND

  <time zone field> ::=
        TIMEZONE_HOUR
      | TIMEZONE_MINUTE

  <extract source> ::=
        <datetime value expression>
      | <interval value expression>

  <datetime value expression> ::=
        <datetime term>
      | <interval value expression> <plus sign> <datetime term>
      | <datetime value expression> <plus sign> <interval term>
      | <datetime value expression> <minus sign> <interval term>

  <interval term> ::=
        <interval factor>
      | <interval term 2> <asterisk> <factor>
      | <interval term 2> <solidus> <factor>
      | <term> <asterisk> <interval factor>

  <interval factor> ::=
      [ <sign> ] <interval primary>

  <interval primary> ::=
        <value expression primary> [ <interval qualifier> ]
  <interval term 2> ::= <interval term>

  <interval value expression> ::=
        <interval term>
      | <interval value expression 1> <plus sign> <interval term 1>
      | <interval value expression 1> <minus sign> <interval term 1>
      | <left paren> <datetime value expression> <minus sign>
            <datetime term> <right paren> <interval qualifier>

  <interval value expression 1> ::= <interval value expression>

  <interval term 1> ::= <interval term>

  <datetime term> ::=
        <datetime factor>

  <datetime factor> ::=
        <datetime primary> [ <time zone> ]

  <datetime primary> ::=
        <value expression primary>
      | <datetime value function>

  <time zone> ::=
      AT <time zone specifier>

  <time zone specifier> ::=
        LOCAL
      | TIME ZONE <interval value expression>

  <length expression> ::=
        <char length expression>
      | <octet length expression>
      | <bit length expression>

  <char length expression> ::=
      ( CHAR_LENGTH | CHARACTER_LENGTH )
          <left paren> <string value expression> <right paren>

  <string value expression> ::=
        <character value expression>
      | <bit value expression>

  <octet length expression> ::=
      OCTET_LENGTH <left paren> <string value expression> <right paren>

  <bit length expression> ::=
      BIT_LENGTH <left paren> <string value expression> <right paren>

  <null specification> ::=
      NULL

  <default specification> ::=
      DEFAULT

  <row value constructor list> ::=
      <row value constructor element>
          [ ( <comma> <row value constructor element> )... ]

  <row subquery> ::= <subquery>

  <comp op> ::=
        <equals operator>
      | <not equals operator>
      | <less than operator>
      | <greater than operator>
      | <less than or equals operator>
      | <greater than or equals operator>

  <between predicate> ::=
      <row value constructor> [ NOT ] BETWEEN
        <row value constructor> AND <row value constructor>

  <in predicate> ::=
      <row value constructor>
        [ NOT ] IN <in predicate value>

  <in predicate value> ::=
        <table subquery>
      | <left paren> <in value list> <right paren>

  <in value list> ::=
      <value expression> ( <comma> <value expression> )...

  <like predicate> ::=
      <match value> [ NOT ] LIKE <pattern>
        [ ESCAPE <escape character> ]

  <match value> ::= <character value expression>

  <pattern> ::= <character value expression>

  <escape character> ::= <character value expression>

  <null predicate> ::= <row value constructor>
      IS [ NOT ] NULL

  <quantified comparison predicate> ::=
      <row value constructor> <comp op> <quantifier> <table subquery>

  <quantifier> ::= <all> | <some>

  <all> ::= ALL

  <some> ::= SOME | ANY

  <exists predicate> ::= EXISTS <table subquery>

  <unique predicate> ::= UNIQUE <table subquery>

  <match predicate> ::=
      <row value constructor> MATCH [ UNIQUE ]
          [ PARTIAL | FULL ] <table subquery>

  <overlaps predicate> ::=
      <row value constructor 1> OVERLAPS <row value constructor 2>

  <row value constructor 1> ::= <row value constructor>

  <row value constructor 2> ::= <row value constructor>

  <truth value> ::=
        TRUE
      | FALSE
      | UNKNOWN

  <constraint attributes> ::=
        <constraint check time> [ [ NOT ] DEFERRABLE ]
      | [ NOT ] DEFERRABLE [ <constraint check time> ]

  <constraint check time> ::=
        INITIALLY DEFERRED
      | INITIALLY IMMEDIATE

  <table constraint definition> ::=
      [ <constraint name definition> ]
      <table constraint> [ <constraint attributes> ]

  <table constraint> ::=
        <unique constraint definition>
      | <referential constraint definition>
      | <check constraint definition>

  <unique constraint definition> ::=
              <unique specification> even in SQL3)
      <unique specification>
        <left paren> <unique column list> <right paren>

  <unique column list> ::= <column name list>

  <referential constraint definition> ::=
      FOREIGN KEY
          <left paren> <referencing columns> <right paren>
        <references specification>

  <referencing columns> ::=
      <reference column list>

  <module contents> ::=
        <declare cursor>
      | <dynamic declare cursor>
      | <procedure>

  <declare cursor> ::=
      DECLARE <cursor name> [ INSENSITIVE ] [ SCROLL ] CURSOR
        FOR <cursor specification>

  <cursor name> ::= <identifier>

  <cursor specification> ::=
      <query expression> [ <order by clause> ]
        [ <updatability clause> ]

  <order by clause> ::=
      ORDER BY <sort specification list>

  <sort specification list> ::=
      <sort specification> [ ( <comma> <sort specification> )... ]

  <sort specification> ::=
      <sort key> [ <collate clause> ] [ <ordering specification> ]

  <sort key> ::=
        <column name>
      | <unsigned integer>

  <ordering specification> ::= ASC | DESC

  <updatability clause> ::=
      FOR
          ( READ ONLY |
            UPDATE [ OF <column name list> ] )

  <dynamic declare cursor> ::=
      DECLARE <cursor name> [ INSENSITIVE ] [ SCROLL ] CURSOR
          FOR <statement name>

  <statement name> ::= <identifier>
  <procedure> ::=
      PROCEDURE <procedure name>
          <parameter declaration list> <semicolon>
        <SQL procedure statement> <semicolon>

  <procedure name> ::= <identifier>

  <parameter declaration list> ::=
        <left paren> <parameter declaration>
            [ ( <comma> <parameter declaration> )... ] <right paren>
      | <parameter declaration>...

  <parameter declaration> ::=
        <parameter name> <data type>
      | <status parameter>

  <status parameter> ::=
      SQLCODE | SQLSTATE

  <SQL procedure statement> ::=
        <SQL schema statement>
      | <SQL data statement>
      | <SQL transaction statement>
      | <SQL connection statement>
      | <SQL session statement>
      | <SQL dynamic statement>
      | <SQL diagnostics statement>

  <SQL schema statement> ::=
        <SQL schema definition statement>
      | <SQL schema manipulation statement>

  <SQL schema definition statement> ::=
        <schema definition>
      | <table definition>
      | <view definition>
      | <grant statement>
      | <domain definition>
      | <character set definition>
      | <collation definition>
      | <translation definition>
      | <assertion definition>

  <schema definition> ::=
      CREATE SCHEMA <schema name clause>
        [ <schema character set specification> ]
        [ <schema element>... ]

  <schema name clause> ::=
        <schema name>
      | AUTHORIZATION <schema authorization identifier>
      | <schema name> AUTHORIZATION
            <schema authorization identifier>

  <schema authorization identifier> ::=
      <authorization identifier>

  <schema character set specification> ::=
      DEFAULT CHARACTER
          SET <character set specification>

  <schema element> ::=
        <domain definition>
      | <table definition>
      | <view definition>
      | <grant statement>
      | <assertion definition>
      | <character set definition>
      | <collation definition>
      | <translation definition>

  <domain definition> ::=
      CREATE DOMAIN <domain name>
          [ AS ] <data type>
        [ <default clause> ]
        [ <domain constraint>... ]
        [ <collate clause> ]

  <domain constraint> ::=
      [ <constraint name definition> ]
      <check constraint definition> [ <constraint attributes> ]

  <table definition> ::=
      CREATE [ ( GLOBAL | LOCAL ) TEMPORARY ] TABLE
          <table name>
        <table element list>
        [ ON COMMIT ( DELETE | PRESERVE ) ROWS ]

  <view definition> ::=
      CREATE VIEW <table name> [ <left paren> <view column list>
                                    <right paren> ]
        AS <query expression>
        [ WITH [ <levels clause> ] CHECK OPTION ]

  <view column list> ::= <column name list>

  <levels clause> ::=
      CASCADED | LOCAL

  <grant statement> ::=
     GRANT <privileges> ON <object name>
       TO <grantee> [ ( <comma> <grantee> )... ]
         [ WITH GRANT OPTION ]

  <privileges> ::=
        ALL PRIVILEGES
      | <action list>

  <action list> ::= <action> [ ( <comma> <action> )... ]

  <action> ::=
        SELECT
      | DELETE
      | INSERT [ <left paren> <privilege column list> <right paren> ]
      | UPDATE [ <left paren> <privilege column list> <right paren> ]
      | REFERENCES [ <left paren> <privilege column list> <right paren> ]
      | USAGE

  <privilege column list> ::= <column name list>

  <object name> ::=
        [ TABLE ] <table name>
      | DOMAIN <domain name>
      | COLLATION <collation name>
      | CHARACTER SET <character set name>
      | TRANSLATION <translation name>

  <grantee> ::=
        PUBLIC
      | <authorization identifier>

  <assertion definition> ::=
      CREATE ASSERTION <constraint name> <assertion check>
        [ <constraint attributes> ]

  <assertion check> ::=
      CHECK
          <left paren> <search condition> <right paren>

  <character set definition> ::=
      CREATE CHARACTER SET <character set name>
          [ AS ]
        <character set source>
        [ <collate clause> | <limited collation definition> ]

  <character set source> ::=
        GET <existing character set name>

  <existing character set name> ::=
        <standard character repertoire name>
      | <implementation-defined character repertoire name>
      | <schema character set name>

  <schema character set name> ::= <character set name>

  <limited collation definition> ::=
      COLLATION FROM <collation source>

  <collation source> ::=
        <collating sequence definition>
      | <translation collation>

  <collating sequence definition> ::=
        <external collation>
      | <schema collation name>
      | DESC <left paren> <collation name> <right paren>
      | DEFAULT

  <external collation> ::=
      EXTERNAL <left paren> <quote> <external collation name> <quote> <right paren>

  <external collation name> ::=
        <standard collation name>
      | <implementation-defined collation name>

  <standard collation name> ::= <collation name>

  <implementation-defined collation name> ::= <collation name>

  <schema collation name> ::= <collation name>

  <translation collation> ::=
      TRANSLATION <translation name>
          [ THEN COLLATION <collation name> ]

  <collation definition> ::=
      CREATE COLLATION <collation name> FOR
          <character set specification>
        FROM <collation source>
          [ <pad attribute> ]

  <pad attribute> ::=
        NO PAD
      | PAD SPACE

  <translation definition> ::=
      CREATE TRANSLATION <translation name>
        FOR <source character set specification>
          TO <target character set specification>
        FROM <translation source>

  <source character set specification> ::= <character set specification>

  <target character set specification> ::= <character set specification>

  <translation source> ::=
        <translation specification>

  <translation specification> ::=
        <external translation>
      | IDENTITY
      | <schema translation name>

  <external translation> ::=
      EXTERNAL <left paren> <quote> <external translation name> <quote> <right paren>

  <external translation name> ::=
        <standard translation name>
      | <implementation-defined translation name>

  <standard translation name> ::= <translation name>

  <implementation-defined translation name> ::= <translation name>

  <schema translation name> ::= <translation name>

  <SQL schema manipulation statement> ::=
        <drop schema statement>
      | <alter table statement>
      | <drop table statement>
      | <drop view statement>
      | <revoke statement>
      | <alter domain statement>
      | <drop domain statement>
      | <drop character set statement>
      | <drop collation statement>
      | <drop translation statement>
      | <drop assertion statement>

  <drop schema statement> ::=
      DROP SCHEMA <schema name> <drop behavior>

  <drop behavior> ::= CASCADE | RESTRICT

  <alter table statement> ::=
      ALTER TABLE <table name> <alter table action>

  <alter table action> ::=
        <add column definition>
      | <alter column definition>
      | <drop column definition>
      | <add table constraint definition>
      | <drop table constraint definition>

  <add column definition> ::=
      ADD [ COLUMN ] <column definition>

  <alter column definition> ::=
      ALTER [ COLUMN ] <column name> <alter column action>

  <alter column action> ::=
        <set column default clause>
      | <drop column default clause>

  <set column default clause> ::=
      SET <default clause>

  <drop column default clause> ::=
      DROP DEFAULT

  <drop column definition> ::=
      DROP [ COLUMN ] <column name> <drop behavior>

  <add table constraint definition> ::=
      ADD <table constraint definition>

  <drop table constraint definition> ::=
      DROP CONSTRAINT <constraint name> <drop behavior>

  <drop table statement> ::=
      DROP TABLE <table name> <drop behavior>

  <drop view statement> ::=
      DROP VIEW <table name> <drop behavior>

  <revoke statement> ::=
      REVOKE [ GRANT OPTION FOR ]
          <privileges>
          ON <object name>
        FROM <grantee> [ ( <comma> <grantee> )... ] <drop behavior>

  <alter domain statement> ::=
      ALTER DOMAIN <domain name> <alter domain action>

  <alter domain action> ::=
        <set domain default clause>
      | <drop domain default clause>
      | <add domain constraint definition>
      | <drop domain constraint definition>

  <set domain default clause> ::= SET <default clause>

  <drop domain default clause> ::= DROP DEFAULT

  <add domain constraint definition> ::=
      ADD <domain constraint>

  <drop domain constraint definition> ::=
      DROP CONSTRAINT <constraint name>

  <drop domain statement> ::=
      DROP DOMAIN <domain name> <drop behavior>

  <drop character set statement> ::=
      DROP CHARACTER SET <character set name>

  <drop collation statement> ::=
      DROP COLLATION <collation name>

  <drop translation statement> ::=
      DROP TRANSLATION <translation name>

  <drop assertion statement> ::=
      DROP ASSERTION <constraint name>

  <SQL data statement> ::=
        <open statement>
      | <fetch statement>
      | <close statement>
      | <select statement: single row>
      | <SQL data change statement>

  <open statement> ::=
      OPEN <cursor name>

  <fetch statement> ::=
      FETCH [ [ <fetch orientation> ] FROM ]
        <cursor name> INTO <fetch target list>

  <fetch orientation> ::=
        NEXT
      | PRIOR
      | FIRST
      | LAST
      | ( ABSOLUTE | RELATIVE ) <simple value specification>

  <simple value specification> ::=
        <parameter name>
      | <embedded variable name>
      | <literal>

  <fetch target list> ::=
      <target specification> [ ( <comma> <target specification> )... ]

  <target specification> ::=
        <parameter specification>
      | <variable specification>

  <close statement> ::=
      CLOSE <cursor name>

  <select statement: single row> ::=
      SELECT [ <set quantifier> ] <select list>
        INTO <select target list>
          <table expression>

  <select target list> ::=
      <target specification> [ ( <comma> <target specification> )... ]

  <SQL data change statement> ::=
        <delete statement: positioned>
      | <delete statement: searched>
      | <insert statement>
      | <update statement: positioned>
      | <update statement: searched>

  <delete statement: positioned> ::=
      DELETE FROM <table name>
        WHERE CURRENT OF <cursor name>

  <delete statement: searched> ::=
      DELETE FROM <table name>
        [ WHERE <search condition> ]

  <insert statement> ::=
      INSERT INTO <table name>
        <insert columns and source>

  <insert columns and source> ::=
        [ <left paren> <insert column list> <right paren> ]
              <query expression>
      | DEFAULT VALUES

  <insert column list> ::= <column name list>

  <update statement: positioned> ::=
      UPDATE <table name>
        SET <set clause list>
          WHERE CURRENT OF <cursor name>

  <set clause list> ::=
      <set clause> [ ( <comma> <set clause> )... ]

  <set clause> ::=
      <object column> <equals operator> <update source>

  <object column> ::= <column name>

  <update source> ::=
        <value expression>
      | <null specification>
      | DEFAULT

  <update statement: searched> ::=
      UPDATE <table name>
        SET <set clause list>
        [ WHERE <search condition> ]

  <SQL transaction statement> ::=
        <set transaction statement>
      | <set constraints mode statement>
      | <commit statement>
      | <rollback statement>

  <set transaction statement> ::=
      SET TRANSACTION <transaction mode>
          [ ( <comma> <transaction mode> )... ]

  <transaction mode> ::=
        <isolation level>
      | <transaction access mode>
      | <diagnostics size>

  <isolation level> ::=
      ISOLATION LEVEL <level of isolation>

  <level of isolation> ::=
        READ UNCOMMITTED
      | READ COMMITTED
      | REPEATABLE READ
      | SERIALIZABLE

  <transaction access mode> ::=
        READ ONLY
      | READ WRITE

  <diagnostics size> ::=
      DIAGNOSTICS SIZE <number of conditions>

  <number of conditions> ::= <simple value specification>

  <set constraints mode statement> ::=
      SET CONSTRAINTS <constraint name list>
          ( DEFERRED | IMMEDIATE )

  <constraint name list> ::=
        ALL
      | <constraint name> [ ( <comma> <constraint name> )... ]

  <commit statement> ::=
      COMMIT [ WORK ]

  <rollback statement> ::=
      ROLLBACK [ WORK ]

  <SQL connection statement> ::=
        <connect statement>
      | <set connection statement>
      | <disconnect statement>

  <connect statement> ::=
      CONNECT TO <connection target>

  <connection target> ::=
        <SQL-server name>
          [ AS <connection name> ]
            correspondence with Tony Gordon)
          [ USER <user name> ]
      | DEFAULT

  <SQL-server name> ::= <simple value specification>

  <connection name> ::= <simple value specification>

  <user name> ::= <simple value specification>

  <set connection statement> ::=
      SET CONNECTION <connection object>

  <connection object> ::=
        DEFAULT
      | <connection name>

  <disconnect statement> ::=
      DISCONNECT <disconnect object>

  <disconnect object> ::=
        <connection object>
      | ALL
      | CURRENT

  <SQL session statement> ::=
        <set catalog statement>
      | <set schema statement>
      | <set names statement>
      | <set session authorization identifier statement>
      | <set local time zone statement>

  <set catalog statement> ::=
      SET CATALOG <value specification>

  <value specification> ::=
        <literal>
      | <general value specification>

  <set schema statement> ::=
      SET SCHEMA <value specification>

  <set names statement> ::=
      SET NAMES <value specification>

  <set session authorization identifier statement> ::=
      SET SESSION AUTHORIZATION
          <value specification>

  <set local time zone statement> ::=
      SET TIME ZONE
          <set time zone value>
  <set time zone value> ::=
        <interval value expression>
      | LOCAL

  <SQL dynamic statement> ::=
        <system descriptor statement>
      | <prepare statement>
      | <deallocate prepared statement>
      | <describe statement>
      | <execute statement>
      | <execute immediate statement>
      | <SQL dynamic data statement>

  <system descriptor statement> ::=
        <allocate descriptor statement>
      | <deallocate descriptor statement>
      | <set descriptor statement>
      | <get descriptor statement>

  <allocate descriptor statement> ::=
      ALLOCATE DESCRIPTOR <descriptor name>
         [ WITH MAX <occurrences> ]

  <descriptor name> ::=
      [ <scope option> ] <simple value specification>

  <scope option> ::=
        GLOBAL
      | LOCAL

  <occurrences> ::= <simple value specification>

  <deallocate descriptor statement> ::=
      DEALLOCATE DESCRIPTOR <descriptor name>

  <set descriptor statement> ::=
      SET DESCRIPTOR <descriptor name>
          <set descriptor information>

  <set descriptor information> ::=
        <set count>
      | VALUE <item number>
          <set item information> [ ( <comma> <set item information> )... ]

  <set count> ::=
      COUNT <equals operator> <simple value specification 1>

  <simple value specification 1> ::= <simple value specification>

  <item number> ::= <simple value specification>

  <set item information> ::=
      <descriptor item name> <equals operator> <simple value specification 2>

  <descriptor item name> ::=
        TYPE
      | LENGTH
      | OCTET_LENGTH
      | RETURNED_LENGTH
      | RETURNED_OCTET_LENGTH
      | PRECISION
      | SCALE
      | DATETIME_INTERVAL_CODE
      | DATETIME_INTERVAL_PRECISION
      | NULLABLE
      | INDICATOR
      | DATA
      | NAME
      | UNNAMED
      | COLLATION_CATALOG
      | COLLATION_SCHEMA
      | COLLATION_NAME
      | CHARACTER_SET_CATALOG
      | CHARACTER_SET_SCHEMA
      | CHARACTER_SET_NAME

  <simple value specification 2> ::= <simple value specification>

  <item number> ::= <simple value specification>

  <get descriptor statement> ::=
      GET DESCRIPTOR <descriptor name> <get descriptor information>

  <get descriptor information> ::=
        <get count>
      | VALUE <item number>
          <get item information> [ ( <comma> <get item information> )... ]

  <get count> ::=
      <simple target specification 1> <equals operator>
           COUNT

  <simple target specification 1> ::= <simple target specification>

  <simple target specification> ::=
        <parameter name>
      | <embedded variable name>

  <get item information> ::=
      <simple target specification 2> <equals operator> <descriptor item name>>

  <simple target specification 2> ::= <simple target specification>

  <prepare statement> ::=
      PREPARE <SQL statement name> FROM <SQL statement variable>

  <SQL statement name> ::=
        <statement name>
      | <extended statement name>

  <extended statement name> ::=
      [ <scope option> ] <simple value specification>

  <SQL statement variable> ::= <simple value specification>

  <deallocate prepared statement> ::=
      DEALLOCATE PREPARE <SQL statement name>

  <describe statement> ::=
        <describe input statement>
      | <describe output statement>

  <describe input statement> ::=
      DESCRIBE INPUT <SQL statement name> <using descriptor>

  <using descriptor> ::=
      ( USING | INTO ) SQL DESCRIPTOR <descriptor name>

  <describe output statement> ::=
      DESCRIBE [ OUTPUT ] <SQL statement name> <using descriptor>

  <execute statement> ::=
      EXECUTE <SQL statement name>
        [ <result using clause> ]
        [ <parameter using clause> ]

  <result using clause> ::= <using clause>

  <using clause> ::=
        <using arguments>
      | <using descriptor>

  <using arguments> ::=
      ( USING | INTO ) <argument> [ ( <comma> <argument> )... ]

  <argument> ::= <target specification>

  <parameter using clause> ::= <using clause>

  <execute immediate statement> ::=
      EXECUTE IMMEDIATE <SQL statement variable>

  <SQL dynamic data statement> ::=
        <allocate cursor statement>
      | <dynamic open statement>
      | <dynamic fetch statement>
      | <dynamic close statement>
      | <dynamic delete statement: positioned>
      | <dynamic update statement: positioned>

  <allocate cursor statement> ::=
      ALLOCATE <extended cursor name> [ INSENSITIVE ]
          [ SCROLL ] CURSOR
        FOR <extended statement name>

  <extended cursor name> ::=
      [ <scope option> ] <simple value specification>

  <dynamic open statement> ::=
      OPEN <dynamic cursor name> [ <using clause> ]

  <dynamic cursor name> ::=
        <cursor name>
      | <extended cursor name>

  <dynamic fetch statement> ::=
      FETCH [ [ <fetch orientation> ] FROM ] <dynamic cursor name>
          <using clause>

  <dynamic close statement> ::=
      CLOSE <dynamic cursor name>

  <dynamic delete statement: positioned> ::=
      DELETE FROM <table name>
        WHERE CURRENT OF
            <dynamic cursor name>

  <dynamic update statement: positioned> ::=
      UPDATE <table name>
        SET <set clause>
            [ ( <comma> <set clause> )... ]
          WHERE CURRENT OF
              <dynamic cursor name>

  <SQL diagnostics statement> ::=
      <get diagnostics statement>

  <get diagnostics statement> ::=
      GET DIAGNOSTICS <sql diagnostics information>

  <sql diagnostics information> ::=
        <statement information>
      | <condition information>

  <statement information> ::=
      <statement information item> [ ( <comma> <statement information item> )... ]

  <statement information item> ::=
      <simple target specification> <equals operator> <statement information item name>

  <statement information item name> ::=
        NUMBER
      | MORE
      | COMMAND_FUNCTION
      | DYNAMIC_FUNCTION
      | ROW_COUNT

  <condition information> ::=
      EXCEPTION <condition number>
        <condition information item> [ ( <comma> <condition information item> )... ]

  <condition number> ::= <simple value specification>

  <condition information item> ::=
      <simple target specification> <equals operator> <condition information item name>

  <condition information item name> ::=
        CONDITION_NUMBER
      | RETURNED_SQLSTATE
      | CLASS_ORIGIN
      | SUBCLASS_ORIGIN
      | SERVER_NAME
      | CONNECTION_NAME
      | CONSTRAINT_CATALOG
      | CONSTRAINT_SCHEMA
      | CONSTRAINT_NAME
      | CATALOG_NAME
      | SCHEMA_NAME
      | TABLE_NAME
      | COLUMN_NAME
      | CURSOR_NAME
      | MESSAGE_TEXT
      | MESSAGE_LENGTH
      | MESSAGE_OCTET_LENGTH

  <embedded SQL host program> ::=
        <embedded SQL Ada program>
      | <embedded SQL C program>
      | <embedded SQL COBOL program>
      | <embedded SQL Fortran program>
      | <embedded SQL MUMPS program>
      | <embedded SQL Pascal program>
      | <embedded SQL PL/I program>

  <embedded SQL Ada program> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <embedded SQL C program> ::=
        !! <EMPHASIS>(See the Syntax Rules.)

  <embedded SQL COBOL program> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <embedded SQL Fortran program> ::=
      !! <EMPHASIS>(See the Syntax Rules.)

  <embedded SQL MUMPS program> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <embedded SQL Pascal program> ::=
      !! <EMPHASIS>(See the Syntax Rules.)

  <embedded SQL PL/I program> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <embedded SQL declare section> ::=
        <embedded SQL begin declare>
          [ <embedded character set declaration> ]
          [ <host variable definition>... ]
        <embedded SQL end declare>
      | <embedded SQL MUMPS declare>

  <embedded SQL begin declare> ::=
      <SQL prefix> BEGIN DECLARE SECTION
          [ <SQL terminator> ]

  <SQL prefix> ::=
        EXEC SQL
      | <ampersand>SQL<left paren>

  <SQL terminator> ::=
        END-EXEC
      | <semicolon>
      | <right paren>

  <embedded character set declaration> ::=
      SQL NAMES ARE <character set specification>

  <host variable definition> ::=
        <Ada variable definition>
      | <C variable definition>
      | <COBOL variable definition>
      | <Fortran variable definition>
      | <MUMPS variable definition>
      | <Pascal variable definition>
      | <PL/I variable definition>

  <Ada variable definition> ::=
      <Ada host identifier> [ ( <comma> <Ada host identifier> )... ] :
      <Ada type specification> [ <Ada initial value> ]

  <Ada type specification> ::=
        <Ada qualified type specification>
      | <Ada unqualified type specification>

  <Ada qualified type specification> ::=
        SQL_STANDARD.CHAR [ CHARACTER SET
           [ IS ] <character set specification> ]
            <left paren> 1 <double period> <length> <right paren>
      | SQL_STANDARD.BIT
            <left paren> 1 <double period> <length> <right paren>
      | SQL_STANDARD.SMALLINT
      | SQL_STANDARD.INT
      | SQL_STANDARD.REAL
      | SQL_STANDARD.DOUBLE_PRECISION
      | SQL_STANDARD.SQLCODE_TYPE
      | SQL_STANDARD.SQLSTATE_TYPE
      | SQL_STANDARD.INDICATOR_TYPE

  <Ada unqualified type specification> ::=
        CHAR
            <left paren> 1 <double period> <length> <right paren>
      | BIT
            <left paren> 1 <double period> <length> <right paren>
      | SMALLINT
      | INT
      | REAL
      | DOUBLE_PRECISION
      | SQLCODE_TYPE
      | SQLSTATE_TYPE
      | INDICATOR_TYPE

  <Ada initial value> ::=
      <Ada assignment operator> <character representation>...

  <Ada assignment operator> ::= <colon><equals operator>

  <C variable definition> ::=
        [ <C storage class> ]
        [ <C class modifier> ]
        <C variable specification>
      <semicolon>

  <C storage class> ::=
        auto
      | extern
      | static

  <C class modifier> ::= const | volatile

  <C variable specification> ::=
        <C numeric variable>
      | <C character variable>
      | <C derived variable>

  <C numeric variable> ::=
      ( long | short | float | double )
        <C host identifier> [ <C initial value> ]
              [ ( <comma> <C host identifier> [ <C initial value> ] )... ]

  <C initial value> ::=
      <equals operator> <character representation>...

  <C character variable> ::=
      char [ CHARACTER SET
               [ IS ] <character set specification> ]
        <C host identifier>
          <C array specification> [ <C initial value> ]
          [ ( <comma> <C host identifier>
            <C array specification>
                   [ <C initial value> ] )... ]

  <C array specification> ::=
      <left bracket> <length> <right bracket>

  <C derived variable> ::=
        <C VARCHAR variable>
      | <C bit variable>

  <C VARCHAR variable> ::=
      VARCHAR [ CHARACTER SET [ IS ]
          <character set specification> ]
          <C host identifier>
              <C array specification> [ <C initial value> ]
            [ ( <comma> <C host identifier>
                <C array specification>
                        [ <C initial value> ] )... ]

  <C bit variable> ::=
      BIT <C host identifier>
          <C array specification> [ <C initial value> ]
        [ ( <comma> <C host identifier>
          <C array specification>
                     [ <C initial value> ] )... ]

  <COBOL variable definition> ::=
      (01|77) <COBOL host identifier> <COBOL type specification>
        [ <character representation>... ] <period>

  <COBOL type specification> ::=
        <COBOL character type>
      | <COBOL bit type>
      | <COBOL numeric type>
      | <COBOL integer type>

  <COBOL character type> ::=
      [ CHARACTER SET [ IS ]
            <character set specification> ]
      ( PIC | PICTURE ) [ IS ] ( X [ <left paren> <length> <right paren> ] )...

  <COBOL bit type> ::=
      ( PIC | PICTURE ) [ IS ]
          ( B [ <left paren> <length> <right paren> ] )...

  <COBOL numeric type> ::=
      ( PIC | PICTURE ) [ IS ]
        S <COBOL nines specification>
      [ USAGE [ IS ] ] DISPLAY SIGN LEADING SEPARATE

  <COBOL nines specification> ::=
        <COBOL nines> [ V [ <COBOL nines> ] ]
      | V <COBOL nines>

  <COBOL nines> ::= ( 9 [ <left paren> <length> <right paren> ] )...

  <COBOL integer type> ::=
        <COBOL computational integer>
      | <COBOL binary integer>

  <COBOL computational integer> ::=
      ( PIC | PICTURE ) [ IS ] S<COBOL nines>
        [ USAGE [ IS ] ] ( COMP | COMPUTATIONAL )

  <COBOL binary integer> ::=
      ( PIC | PICTURE ) [ IS ] S<COBOL nines>
        [ USAGE [ IS ] ] BINARY

  <Fortran variable definition> ::=
      <Fortran type specification>
      <Fortran host identifier>
          [ ( <comma> <Fortran host identifier> )... ]

  <Fortran type specification> ::=
        CHARACTER [ <asterisk> <length> ]
            [ CHARACTER SET [ IS ]
                  <character set specification> ]
      | BIT [ <asterisk> <length> ]
      | INTEGER
      | REAL
      | DOUBLE PRECISION

  <MUMPS variable definition> ::=
      ( <MUMPS numeric variable> | <MUMPS character variable> )
          <semicolon>

  <MUMPS numeric variable> ::=
      <MUMPS type specification>
        <MUMPS host identifier> [ ( <comma> <MUMPS host identifier> )... ]

  <MUMPS type specification> ::=
        INT
      | DEC
            [ <left paren> <precision> [ <comma> <scale> ] <right paren> ]
      | REAL

  <MUMPS character variable> ::=
      VARCHAR <MUMPS host identifier> <MUMPS length specification>
        [ ( <comma> <MUMPS host identifier> <MUMPS length specification> )... ]

  <MUMPS length specification> ::=
      <left paren> <length> <right paren>

  <Pascal variable definition> ::=
      <Pascal host identifier> [ ( <comma> <Pascal host identifier> )... ] <colon>
        <Pascal type specification> <semicolon>

  <Pascal type specification> ::=
        PACKED ARRAY
            <left bracket> 1 <double period> <length> <right bracket>
          OF CHAR
            [ CHARACTER SET [ IS ]
                  <character set specification> ]
      | PACKED ARRAY
            <left bracket> 1 <double period> <length> <right bracket>
          OF BIT
      | INTEGER
      | REAL
      | CHAR [ CHARACTER SET
                                  [ IS ] <character set specification> ]
      | BIT

  <PL/I variable definition> ::=
      (DCL | DECLARE)
          (   <PL/I host identifier>
            | <left paren> <PL/I host identifier>
                  [ ( <comma> <PL/I host identifier> )... ] <right paren> )
      <PL/I type specification>
      [ <character representation>... ] <semicolon>

  <PL/I type specification> ::=
        ( CHAR | CHARACTER ) [ VARYING ]
            <left paren><length><right paren>
            [ CHARACTER SET
                  [ IS ] <character set specification> ]
      | BIT [ VARYING ] <left paren><length><right paren>
      | <PL/I type fixed decimal> <left paren> <precision>
            [ <comma> <scale> ] <right paren>
      | <PL/I type fixed binary> [ <left paren> <precision> <right paren> ]
      | <PL/I type float binary> <left paren> <precision> <right paren>

  <PL/I type fixed decimal> ::=
        ( DEC | DECIMAL ) FIXED
      | FIXED ( DEC | DECIMAL )

  <PL/I type fixed binary> ::=
        ( BIN | BINARY ) FIXED
      | FIXED ( BIN | BINARY )

  <PL/I type float binary> ::=
        ( BIN | BINARY ) FLOAT
      | FLOAT ( BIN | BINARY )

  <embedded SQL end declare> ::=
      <SQL prefix> END DECLARE SECTION
          [ <SQL terminator> ]

  <embedded SQL MUMPS declare> ::=
      <SQL prefix>
        BEGIN DECLARE SECTION
          [ <embedded character set declaration> ]
          [ <host variable definition>... ]
        END DECLARE SECTION
      <SQL terminator>

  <embedded SQL statement> ::=
      <SQL prefix>
        <statement or declaration>
      [ <SQL terminator> ]

  <statement or declaration> ::=
        <declare cursor>
      | <dynamic declare cursor>
      | <temporary table declaration>
      | <embedded exception declaration>
      | <SQL procedure statement>

  <embedded exception declaration> ::=
      WHENEVER <condition> <condition action>

  <condition> ::=
      SQLERROR | NOT FOUND

  <condition action> ::=
      CONTINUE | <go to>

  <go to> ::=
      ( GOTO | GO TO ) <goto target>

  <goto target> ::=
        <host label identifier>
      | <unsigned integer>
      | <host PL/I label variable>

  <host label identifier> ::= !!<EMPHASIS>(See the Syntax Rules.)

  <host PL/I label variable> ::= !!<EMPHASIS>(See the Syntax Rules.)

  <preparable statement> ::=
        <preparable SQL data statement>
      | <preparable SQL schema statement>
      | <preparable SQL transaction statement>
      | <preparable SQL session statement>
      | <preparable implementation-defined statement>

  <preparable SQL data statement> ::=
        <delete statement: searched>
      | <dynamic single row select statement>
      | <insert statement>
      | <dynamic select statement>
      | <update statement: searched>
      | <preparable dynamic delete statement: positioned>
      | <preparable dynamic update statement: positioned>

  <dynamic single row select statement> ::= <query specification>

  <dynamic select statement> ::= <cursor specification>

  <preparable dynamic delete statement: positioned> ::=
     DELETE [ FROM <table name> ]
        WHERE CURRENT OF <cursor name>

  <preparable dynamic update statement: positioned> ::=
     UPDATE [ <table name> ]
        SET <set clause list>
        WHERE CURRENT OF <cursor name>

  <preparable SQL schema statement> ::=
        <SQL schema statement>

  <preparable SQL transaction statement> ::=
        <SQL transaction statement>

  <preparable SQL session statement> ::=
        <SQL session statement>

  <preparable implementation-defined statement> ::=
      !! <EMPHASIS>(See the Syntax Rules.)

  <direct SQL statement> ::=
      <directly executable statement> <semicolon>

  <directly executable statement> ::=
        <direct SQL data statement>
      | <SQL schema statement>
      | <SQL transaction statement>
      | <SQL connection statement>
      | <SQL session statement>
      | <direct implementation-defined statement>

  <direct SQL data statement> ::=
        <delete statement: searched>
      | <direct select statement: multiple rows>
      | <insert statement>
      | <update statement: searched>
      | <temporary table declaration>

  <direct select statement: multiple rows> ::=
      <query expression> [ <order by clause> ]

  <direct implementation-defined statement> ::=
      !!<EMPHASIS>(See the Syntax Rules)

  <SQL object identifier> ::=
      <SQL provenance> <SQL variant>

  <SQL provenance> ::= <arc1> <arc2> <arc3>

  <arc1> ::= iso | 1 | iso <left paren> 1 <right paren>

  <arc2> ::= standard | 0 | standard <left paren> 0 <right paren>

  <arc3> ::= 9075

  <SQL variant> ::= <SQL edition> <SQL conformance>

  <SQL edition> ::= <1987> | <1989> | <1992>

  <1987> ::= 0 | edition1987 <left paren> 0 <right paren>

  <1989> ::= <1989 base> <1989 package>

  <1989 base> ::= 1 | edition1989 <left paren> 1 <right paren>

  <1989 package> ::= <integrity no> | <integrity yes>
  <integrity no> ::= 0 | IntegrityNo <left paren> 0 <right paren>

  <integrity yes> ::= 1 | IntegrityYes <left paren> 1 <right paren>

  <1992> ::= 2 | edition1992 <left paren> 2 <right paren>

  <SQL conformance> ::= <low> | <intermediate> | <high>

  <low> ::= 0 | Low <left paren> 0 <right paren>

  <intermediate> ::= 1 | Intermediate <left paren> 1 <right paren>

  <high> ::= 2 | High <left paren> 2 <right paren>

  43.  Appendix B - Syntax of ANSI/ISO SQL 1998

  SQL syntax specification for ANSI/ISO SQL 1998 also called SQL-3 as below -
  Under is a copy of the SQL3 bnf.  SQL3 is a superset of SQL-92
  [which is a superset of SQL-89 level 2].  SQL3 is not yet a standard,
  but SQL-92 is a standard.
  ENTRY LEVEL SQL-92 is the "current" implementation state of most
  vendors.  There are only a few differences between SQL-92 ENTRY LEVEL
  and SQL-89 Level II, but two of them are very important:

     - Delimited identifiers

     - The handling of the WITH CHECK option on views defaults to
       CASCADE.  In SQL-89 the default was [effectively] LOCAL.

  for the  language done at about  1-SEP-1993 15:13:55.88.
  The specific version of the BNF included here is:  ANSI-only, SQL3-only.

  <SQL terminal character> ::=
      <SQL language character>

  <SQL language character> ::=
        <simple Latin letter>
      | <digit>
      | <SQL special character>

  <simple Latin letter> ::=
        <simple Latin upper case letter>
      | <simple Latin lower case letter>

  <simple Latin upper case letter> ::=
            A | B | C | D | E | F | G | H | I | J | K | L | M | N | O
      | P | Q | R | S | T | U | V | W | X | Y | Z

  <simple Latin lower case letter> ::=
            a | b | c | d | e | f | g | h | i | j | k | l | m | n | o
      | p | q | r | s | t | u | v | w | x | y | z

  <digit> ::=
      0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9

  <SQL special character> ::=
        <space>
      | <double quote>
      | <percent>
      | <ampersand>
      | <quote>
      | <left paren>
      | <right paren>
      | <asterisk>
      | <plus sign>
      | <comma>
      | <minus sign>
      | <period>
      | <solidus>
      | <colon>
      | <semicolon>
      | <less than operator>
      | <equals operator>
      | <greater than operator>
      | <question mark>
      | <left bracket>
      | <right bracket>
      | <circumflex>
      | <underscore>
      | <vertical bar>

  <space> ::= !! <EMPHASIS>(space character in character set in use)

  <double quote> ::= "

  <percent> ::= %

  <ampersand> ::= &

  <quote> ::= '

  <left paren> ::= (

  <right paren> ::= )

  <asterisk> ::= *

  <plus sign> ::= +

  <comma> ::= ,

  <minus sign> ::= -

  <period> ::= .

  <solidus> ::= /

  <colon> ::= :

  <semicolon> ::= ;

  <less than operator> ::= <

  <equals operator> ::= =

  <greater than operator> ::= >

  <question mark> ::= ?

  <left bracket> ::= [

  <right bracket> ::= ]

  <circumflex> ::= ^

  <underscore> ::= _

  <vertical bar> ::= |

  <separator> ::= ( <comment> | <space> | <newline> )...

  <comment> ::=
        <simple comment>
      | <bracketed comment>

  <simple comment> ::=
      <simple comment introducer> [ <comment character>... ] <newline>

  <simple comment introducer> ::= <minus sign><minus sign>[<minus sign>...]

  <comment character> ::=
        <nonquote character>
      | <quote>

  <nonquote character> ::= !! <EMPHASIS>(See the Syntax Rules.)

  <newline> ::= !! <EMPHASIS>(implementation-defined end-of-line indicator)
  <bracketed comment> ::=             !! (<EMPHASIS>(See the Syntax Rules))
      <bracketed comment introducer>
        <bracketed comment contents>
      <bracketed comment terminator>

  <bracketed comment introducer> ::= <solidus><asterisk>

  <bracketed comment contents> ::=
      [ ( <comment character> | <separator> )... ]

  <bracketed comment terminator> ::= <asterisk><solidus>

  <token> ::=
        <nondelimiter token>
      | <delimiter token>

  <nondelimiter token> ::=
        <regular identifier>
      | <key word>
      | <unsigned numeric literal>
      | <national character string literal>
      | <bit string literal>
      | <hex string literal>
      | <user-defined operator symbol>

  <regular identifier> ::= <identifier body>

  <identifier body> ::=
      <identifier start> [ ( <underscore> | <identifier part> )... ]

  <identifier start> ::= !! <EMPHASIS>(See the Syntax Rules)

  <identifier part> ::=
        <identifier start>
      | <digit>

  <key word> ::=
        <reserved word>
      | <non-reserved word>

  <reserved word> ::=
        ABSOLUTE | ACTION | ACTOR | ADD | AFTER | ALIAS
      | ALL | ALLOCATE | ALTER
      | AND | ANY | ARE
      | AS | ASC | ASSERTION
      | ASYNC | AT
      | ATTRIBUTES
      | AUTHORIZATION | AVG
      | BEFORE | BEGIN | BETWEEN | BIT | BIT_LENGTH
      | BOOLEAN | BOTH | BREADTH | BY
      | CASCADE | CASCADED | CASE | CAST
      | CATALOG
      | CHAR | CHARACTER
      | CHAR_LENGTH | CHARACTER_LENGTH | CHECK | CLASS | CLOSE | COALESCE
      | COLLATE
      | COLLATION | COLUMN | COMMIT | COMPLETION
      | CONNECT | CONNECTION | CONSTRAINT
      | CONSTRAINTS | CONSTRUCTOR | CONTINUE | CONVERT | CORRESPONDING
      | COUNT
      | CREATE | CROSS | CURRENT | CURRENT_DATE
      | CURRENT_PATH
      | CURRENT_TIME
      | CURRENT_TIMESTAMP | CURRENT_USER | CURSOR | CYCLE
      | DATA | DATE | DAY | DEALLOCATE
      | DEC | DECIMAL | DECLARE | DEFAULT
      | DEFERRABLE | DEFERRED | DELETE | DEPTH
      | DESC | DESCRIBE
      | DESCRIPTOR
      | DESIGNATOR
      | DESTROY | DESTRUCTOR | DICTIONARY
      | DIAGNOSTICS | DISCONNECT | DISTINCT | DOMAIN
      | DOUBLE | DROP
      | EACH
      | ELEMENT
      | ELSE
      | END | END-EXEC | EQUALS
      | ESCAPE | EXCEPT
      | EXEC | EXECUTE | EXISTS | EXTERNAL | EXTRACT
      | FACTOR
      | FALSE | FETCH | FIRST | FLOAT | FOR | FOREIGN
      | FOUND | FROM | FULL
      | FUNCTION
      | GENERAL | GET | GLOBAL | GO | GOTO
      | GRANT | GROUP
      | HAVING | HOUR
      | IDENTITY | IGNORE | IMMEDIATE
      | IN | INDICATOR
      | INITIALLY | INNER | INOUT
      | INPUT | INSENSITIVE | INSERT
      | INSTEAD
      | INT | INTEGER | INTERSECT | INTERVAL
      | INTO | IS | ISOLATION
      | JOIN
      | KEY
      | LANGUAGE | LAST | LEADING | LEFT
      | LESS | LEVEL | LIKE | LIMIT
      | LIST
      | LOCAL | LOWER
      | MATCH | MAX | MIN | MINUTE | MODIFY | MODULE
      | MONTH
      | MOVE | MULTISET
      | NAMES | NATIONAL | NATURAL | NCHAR | NEW
      | NEW_TABLE
      | NEXT | NO
      | NONE | NOT| NULL | NULLIF | NUMERIC
      | OCTET_LENGTH | OF | OFF
      | OID | OLD
      | OLD_TABLE
      | ON | ONLY | OPEN | OPERATION
      | OPERATOR
      | OPERATORS
      | OPTION | OR | ORDER
      | OUT | OUTER | OUTPUT | OVERLAPS
      | PAD | PARAMETERS | PARTIAL
      | PATH
      | PENDANT | POSITION | POSTFIX | PRECISION | PREFIX
      | PREORDER | PREPARE | PRESERVE | PRIMARY | PRIOR | PRIVATE
      | PRIVILEGES | PROCEDURE | PROTECTED | PUBLIC
      | READ | REAL | RECURSIVE
      | REFERENCES | REFERENCING | RELATIVE | REPRESENTATION
      | RESTRICT | REVOKE | RIGHT
      | ROLE | ROLLBACK
      | ROUTINE
      | ROW | ROWS
      | SAVEPOINT | SCHEMA | SCROLL | SEARCH | SECOND | SECTION
      | SELECT
      | SENSITIVE
      | SEQUENCE
      | SESSION | SESSION_USER | SET
      | SIMILAR | SIZE | SMALLINT | SOME | SPACE | SPECIFIC
      | SQL | SQLCODE
      | SQLERROR | SQLEXCEPTION | SQLSTATE | SQLWARNING
      | START | STATE
      | STRUCTURE
      | SUBSTRING | SUM
      | SYMBOL
      | SYSTEM_USER
      | TABLE | TEMPLATE | TEMPORARY
      | TERM
      | TEST | THAN
      | THEN | THERE | TIME | TIMESTAMP
      | TIMEZONE_HOUR
      | TIMEZONE_MINUTE | TO | TRAILING | TRANSACTION
      | TRANSLATE | TRANSLATION
      | TRIGGER | TRIM | TRUE | TYPE
      | UNDER | UNION | UNIQUE | UNKNOWN
      | UPDATE | UPPER | USAGE | USER | USING
      | VALUE | VALUES | VARCHAR | VARIABLE | VARIANT
      | VARYING | VIEW
      | VIRTUAL | VISIBLE
      | WAIT | WHEN | WHENEVER | WHERE
      | WITH | WITHOUT
      | WORK | WRITE
      | YEAR
      | ZONE

  <non-reserved word> ::=
        ADA
      | C | CATALOG_NAME
      | CHAIN
      | CHARACTER_SET_CATALOG | CHARACTER_SET_NAME
      | CHARACTER_SET_SCHEMA | CLASS_ORIGIN | COBOL | COLLATION_CATALOG
      | COLLATION_NAME
      | COLLATION_SCHEMA | COLUMN_NAME | COMMAND_FUNCTION
      | COMMITTED | CONDITION_NUMBER | CONNECTION_NAME | CONSTRAINT_CATALOG
      | CONSTRAINT_NAME | CONSTRAINT_SCHEMA | CURSOR_NAME
      | DATA | DATETIME_INTERVAL_CODE | DATETIME_INTERVAL_PRECISION
      | DYNAMIC_FUNCTION
      | FORTRAN
      | HOLD
      | KEY_MEMBER | KEY_TYPE
      | LENGTH
      | MESSAGE_LENGTH | MESSAGE_OCTET_LENGTH | MESSAGE_TEXT | MORE | MUMPS
      | NAME | NULLABLE | NUMBER
      | PASCAL | PLI
      | REPEATABLE | RETURNED_LENGTH | RETURNED_OCTET_LENGTH | RETURNED_SQLSTATE
      | ROUTINE_CATALOG | ROUTINE_NAME | ROUTINE_SCHEMA | ROW_COUNT
      | SCALE | SCHEMA_NAME | SERIALIZABLE | SERVER_NAME | SPECIFIC_NAME
      | SUBCLASS_ORIGIN
      | TABLE_NAME | TYPE
      | UNCOMMITTED | UNNAMED

  <unsigned numeric literal> ::=
        <exact numeric literal>
      | <approximate numeric literal>

  <exact numeric literal> ::=
        <unsigned integer> [ <period> [ <unsigned integer> ] ]
      | <period> <unsigned integer>

  <unsigned integer> ::= <digit>...

  <approximate numeric literal> ::= <mantissa> E <exponent>

  <mantissa> ::= <exact numeric literal>

  <exponent> ::= <signed integer>

  <signed integer> ::= [ <sign> ] <unsigned integer>

  <sign> ::= <plus sign> | <minus sign>

  <national character string literal> ::=
      N <quote> [ <character representation>... ] <quote>
        [ ( <separator> <quote> [ <character representation>... ] <quote> )... ]

  <character representation> ::=
        <nonquote character>
      | <quote symbol>

  <quote symbol> ::= <quote><quote>

  <bit string literal> ::=
      B <quote> [ <bit>... ] <quote>
        [ ( <separator> <quote> [ <bit>... ] <quote> )... ]

  <bit> ::= 0 | 1

  <hex string literal> ::=
      X <quote> [ <hexit>... ] <quote>
        [ ( <separator> <quote> [ <hexit>... ] <quote> )... ]

  <hexit> ::= <digit> | A | B | C | D | E | F | a | b | c | d | e | f

  <user-defined operator symbol> ::= !! <EMPHASIS>(See the Syntax Rules)

  <delimiter token> ::=
        <character string literal>
      | <date string>
      | <time string>
      | <timestamp string>
      | <interval string>
      | <delimited identifier>
      | <SQL special character>
      | <not equals operator>
      | <greater than or equals operator>
      | <less than or equals operator>
      | <concatenation operator>
      | <double period>
      | <double colon>
      | <assignment operator>
      | <left bracket>
      | <right bracket>

  <character string literal> ::=
      [ <introducer><character set specification> ]
      <quote> [ <character representation>... ] <quote>
        [ ( <separator> <quote> [ <character representation>... ] <quote> )... ]

  <introducer> ::= <underscore>

  <character set specification> ::=
        <standard character repertoire name>
      | <implementation-defined character repertoire name>
      | <user-defined character repertoire name>
      | <standard universal character form-of-use name>
      | <implementation-defined universal character form-of-use name>

  <standard character repertoire name> ::= <character set name>

  <character set name> ::= [ <schema name> <period> ]
        <SQL language identifier>

  <schema name> ::=
      [ <catalog name> <period> ] <unqualified schema name>

  <catalog name> ::= <identifier>

  <identifier> ::=
      [ <introducer><character set specification> ] <actual identifier>

  <actual identifier> ::=
        <regular identifier>
      | <delimited identifier>

  <delimited identifier> ::=
      <double quote> <delimited identifier body> <double quote>

  <delimited identifier body> ::= <delimited identifier part>...

  <delimited identifier part> ::=
        <nondoublequote character>
      | <doublequote symbol>

  <nondoublequote character> ::= !! <EMPHASIS>(See the Syntax Rules)

  <doublequote symbol> ::= <double quote><double quote>

  <unqualified schema name> ::= <identifier>

  <SQL language identifier> ::=
      <SQL language identifier start>
         [ ( <underscore> | <SQL language identifier part> )... ]

  <SQL language identifier start> ::= <simple Latin letter>

  <SQL language identifier part> ::=
        <simple Latin letter>
      | <digit>

  <implementation-defined character repertoire name> ::=
      <character set name>

  <user-defined character repertoire name> ::= <character set name>

  <standard universal character form-of-use name> ::=
      <character set name>

  <implementation-defined universal character form-of-use name> ::=
      <character set name>

  <date string> ::=
      <quote> <date value> <quote>

  <date value> ::=
      <years value> <minus sign> <months value>
          <minus sign> <days value>

  <years value> ::= <datetime value>

  <datetime value> ::= <unsigned integer>

  <months value> ::= <datetime value>

  <days value> ::= <datetime value>

  <time string> ::=
      <quote> <time value> [ <time zone interval> ] <quote>

  <time value> ::=
      <hours value> <colon> <minutes value> <colon> <seconds value>

  <hours value> ::= <datetime value>

  <minutes value> ::= <datetime value>

  <seconds value> ::=
        <seconds integer value> [ <period> [ <seconds fraction> ] ]

  <seconds integer value> ::= <unsigned integer>

  <seconds fraction> ::= <unsigned integer>

  <time zone interval> ::=
      <sign> <hours value> <colon> <minutes value>

  <timestamp string> ::=
      <quote> <date value> <space> <time value>
          [ <time zone interval> ] <quote>

  <interval string> ::=
      <quote> ( <year-month literal> | <day-time literal> ) <quote>

  <year-month literal> ::=
        <years value>
      | [ <years value> <minus sign> ] <months value>

  <day-time literal> ::=
        <day-time interval>
      | <time interval>

  <day-time interval> ::=
      <days value>
        [ <space> <hours value> [ <colon> <minutes value>
          [ <colon> <seconds value> ] ] ]

  <time interval> ::=
        <hours value> [ <colon> <minutes value> [ <colon> <seconds value> ] ]
      | <minutes value> [ <colon> <seconds value> ]
      | <seconds value>

  <not equals operator> ::= <>

  <greater than or equals operator> ::= >=

  <less than or equals operator> ::= <=

  <concatenation operator> ::= ||

  <double period> ::= ..

  <double colon> ::= ::

  <assignment operator> ::= :=

  <SQL-client module definition> ::= <module>

  <module> ::=
      <module name clause>
        <module remainder>
      [ END MODULE ]

  <module name clause> ::=
      MODULE [ <module name> ]

  <module name> ::=
        <SQL-server module name>
      | <SQL-client module name>

  <SQL-server module name> ::= <qualified identifier>

  <qualified identifier> ::= <identifier>

  <SQL-client module name> ::= <identifier>

  <module remainder> ::=
      [ <module character set specification> ]
      <language clause>
      <module authorization clause>
        [ <module path specification> ]
      <module contents>...

  <module character set specification> ::=
      NAMES ARE <character set specification>

  <language clause> ::=
      LANGUAGE <language name>

  <language name> ::=
      ADA | C | COBOL | FORTRAN | MUMPS | PASCAL | PLI | SQL

  <module authorization clause> ::=
        SCHEMA <schema name>
      | AUTHORIZATION <module authorization identifier>
      | SCHEMA <schema name> AUTHORIZATION <module authorization identifier>

  <module authorization identifier> ::=
      <authorization identifier>

  <authorization identifier> ::= <identifier>

  <module path specification> ::=
      PATH <schema name list>

  <schema name list> ::=
      <schema name> [ ( <comma> <schema name> )... ]

  <module contents> ::=
        <global declaration> [ <semicolon> ]
      | <routine>

  <global declaration> ::=
        <declare cursor>
      | <temporary abstract data type declaration>
      | <temporary table declaration>
      | <temporary view declaration>

  <declare cursor> ::=
      DECLARE <cursor name> [ <cursor sensitivity> ]
        [ SCROLL ] CURSOR
        [ WITH HOLD ]
        FOR <cursor specification>
  <cursor sensitivity> ::=
        SENSITIVE
      | INSENSITIVE

  <cursor name> ::= <local qualified name>

  <local qualified name> ::=
      [ <local qualifier> <period> ] <qualified identifier>

  <local qualifier> ::= MODULE
  <cursor specification> ::=
      <query expression> [ <order by clause> ]
        [ <updatability clause> ]

  <query expression> ::=
      <possibly updatable query expression> [ <trigger definition>... ]

  <possibly updatable query expression> ::=
        <non-join query expression>
      | <joined table>

  <non-join query expression> ::=
        <non-join query term>
      | <query expression> UNION  [ ALL ]
            [ <corresponding spec> ] <query term>
      | <query expression> EXCEPT [ ALL ]
            [ <corresponding spec> ] <query term>

  <non-join query term> ::=
        <non-join query primary>
      | <query term> INTERSECT [ ALL ]
            [ <corresponding spec> ] <query primary>
      | <recursive union>

  <non-join query primary> ::=
        <simple table>
      | <left paren> <non-join query expression> <right paren>

  <simple table> ::=
        <query specification>
      | <table value designator>
      | <explicit table>
      | <collection expression>

  <query specification> ::=
      SELECT [ <set quantifier> ] <select list>
        <table expression>

  <set quantifier> ::= DISTINCT | ALL

  <select list> ::=
        <asterisk>
      | <select sublist> [ ( <comma> <select sublist> )... ]

  <select sublist> ::=
        <derived column>
      | <qualifier> <period> <asterisk>

  <derived column> ::=
      <value expression> [ <as clause> ]

  <value expression> ::=
        <numeric value expression>
      | <string value expression>
      | <datetime value expression>
      | <interval value expression>
      | <enumerated value expression>
      | <boolean value expression>
      | <attributes function>
      | <abstract data type value expression>
      | <table value expression>
      | <collection value expression>

  <numeric value expression> ::=
        <term>
      | <numeric value expression> <plus sign> <term>
      | <numeric value expression> <minus sign> <term>

  <term> ::=
        <factor>
      | <term> <asterisk> <factor>
      | <term> <solidus> <factor>

  <factor> ::=
      [ <sign> ] <numeric primary>

  <numeric primary> ::=
        <value expression primary>
      | <numeric value function>

  <value expression primary> ::=
        <unsigned value specification>
      | <column reference>
      | <row reference>
      | <set function specification>
      | <table subquery>
      | <case expression>
      | <left paren> <value expression> <right paren>
      | <cast specification>

  <unsigned value specification> ::=
        <unsigned literal>
      | <general value specification>

  <unsigned literal> ::=
        <unsigned numeric literal>
      | <general literal>

  <general literal> ::=
        <character string literal>
      | <national character string literal>
      | <bit string literal>
      | <hex string literal>
      | <datetime literal>
      | <interval literal>
      | <enumeration literal>
      | <boolean literal>
      | <oid literal>

  <datetime literal> ::=
        <date literal>
      | <time literal>
      | <timestamp literal>

  <date literal> ::=
      DATE <date string>

  <time literal> ::=
      TIME <time string>

  <timestamp literal> ::=
      TIMESTAMP <timestamp string>

  <interval literal> ::=
      INTERVAL [ <sign> ] <interval string> <interval qualifier>

  <interval qualifier> ::=
        <start field> TO <end field>
      | <single datetime field>

  <start field> ::=
      <non-second datetime field>
          [ <left paren> <interval leading field precision> <right paren> ]

  <non-second datetime field> ::= YEAR | MONTH | DAY | HOUR | MINUTE

  <interval leading field precision> ::= <unsigned integer>

  <end field> ::=
        <non-second datetime field>
      | SECOND
          [ <left paren> <interval fractional seconds precision> <right paren> ]

  <interval fractional seconds precision> ::= <unsigned integer>

  <single datetime field> ::=
        <non-second datetime field>
            [ <left paren> <interval leading field precision> <right paren> ]
      | SECOND [ <left paren> <interval leading field precision>
            [ <comma> <interval fractional seconds precision> ] <right paren> ]

  <enumeration literal> ::=
      <domain name> <double colon> <enumeration name>

  <domain name> ::= <schema qualified name>

  <schema qualified name> ::=
      [ <schema name> <period> ] <qualified identifier>

  <enumeration name> ::= <identifier>

  <boolean literal> ::=
        TRUE
      | FALSE

  <oid literal> ::= OID <oid string>

  <oid string> ::= <quote> <oid value> <quote>

  <oid value> ::= <character representation>...

  <general value specification> ::=
        <item reference>
      | USER
      | CURRENT_USER
      | SESSION_USER
      | SYSTEM_USER
      | CURRENT_PATH
      | VALUE
      | <function invocation>
      | <attribute reference>
      | <template parameter name>

  <item reference> ::=
      <parameter name> [ <indicator parameter> ]

  <parameter name> ::= <colon> <identifier>

  <indicator parameter> ::= [ INDICATOR ] <parameter name>

  <function invocation> ::= <routine invocation>

  <routine invocation> ::=
      <routine name> <argument list>

  <routine name> ::= <local or schema qualified name>

  <local or schema qualified name> ::=
      [ <local or schema qualifier> <period> ] <qualified identifier>

  <local or schema qualifier> ::=
        <schema name>
      | MODULE

  <argument list> ::=
        <left paren> <positional arguments> <comma> <keyword arguments> <right paren>
      | <left paren> <positional arguments> <right paren>
      | <left paren> <keyword arguments> <right paren>
      | <left paren> <right paren>

  <positional arguments> ::=
      <argument> [ ( <comma> <argument> )... ]

  <argument> ::=
        <value expression>
      | <generalized expression>

  <generalized expression> ::=
      <value expression> AS <abstract data type name>

  <abstract data type name> ::= <local or schema qualified name>
  <attribute name> ::=
        <identifier>
      | OID

  <keyword arguments> ::=
      <keyword argument> [ ( <comma> <keyword argument> )... ]

  <keyword argument> ::=
      <parameter name> <keyword parameter tag> <argument>

  <keyword parameter tag> ::= =>

  <attribute reference> ::=
      <value specification> <period> <attribute name>

  <value specification> ::=
        <literal>
      | <general value specification>

  <literal> ::=
        <signed numeric literal>
      | <general literal>

  <signed numeric literal> ::=
      [ <sign> ] <unsigned numeric literal>

  <template parameter name> ::= <colon> <identifier>

  <column reference> ::= [ <qualifier> <period> ] <column name>

  <qualifier> ::=
        <table name>
      | <correlation name>

  <table name> ::=
        <local or schema qualified name>

  <correlation name> ::= <identifier>

  <column name> ::=
        <identifier>
      | OID

  <row reference> ::= ROW <qualifier>

  <set function specification> ::=
        COUNT <left paren> <asterisk> <right paren>
      | <general set function>

  <general set function> ::=
        <set function type>
            <left paren> [ <set quantifier> ] <value expression> <right paren> ]

  <set function type> ::=
      AVG | MAX | MIN | SUM | COUNT

  <table subquery> ::= <subquery>

  <subquery> ::= <left paren> <query expression> <right paren>

  <case expression> ::=
        <case abbreviation>
      | <case specification>

  <case abbreviation> ::=
        NULLIF <left paren> <value expression> <comma>
              <value expression> <right paren>
      | COALESCE <left paren> <value expression>
              ( <comma> <value expression> )... <right paren>

  <case specification> ::=
        <simple case>
      | <searched case>

  <simple case> ::=
      CASE <case operand>
        <simple when clause>...
        [ <else clause> ]
      END

  <case operand> ::= <value expression>

  <simple when clause> ::= WHEN <when operand> THEN <result>

  <when operand> ::= <value expression>

  <result> ::= <result expression> | NULL

  <result expression> ::= <value expression>

  <else clause> ::= ELSE <result>

  <searched case> ::=
      CASE
        <searched when clause>...
        [ <else clause> ]
      END

  <searched when clause> ::= WHEN <search condition> THEN <result>

  <search condition> ::=
      <boolean value expression>

  <boolean value expression> ::=
        <boolean term>
      | <boolean value expression> OR <boolean term>

  <boolean term> ::=
        <boolean factor>
      | <boolean term> AND <boolean factor>

  <boolean factor> ::=
      [ NOT ] <boolean primary>

  <boolean primary> ::=
        <predicate>
      | <value expression primary>

  <predicate> ::=
        <comparison predicate>
      | <between predicate>
      | <in predicate>
      | <like predicate>
      | <null predicate>
      | <quantified comparison predicate>
      | <exists predicate>
      | <unique predicate>
      | <match predicate>
      | <overlaps predicate>
      | <similar predicate>
      | <quantified predicate>
      | <there is predicate>
      | <distinct predicate>
      | <boolean predicate>

  <comparison predicate> ::=
      <row value designator> <comp op> <row value designator>

  <row value designator> ::=
         <row value designator element>
      | <left paren> <row value designator list> <right paren>
      | <row subquery>

  <row value designator element> ::=
        <value expression>
      | <null specification>
      | <default specification>

  <null specification> ::=
      NULL [ <left paren> <null state> <right paren> ]

  <null state> ::= <identifier>

  <default specification> ::=
      DEFAULT

  <row value designator list> ::=
      <row value designator element>
          [ ( <comma> <row value designator element> )... ]

  <row subquery> ::= <subquery>

  <comp op> ::=
        <equals operator>
      | <not equals operator>
      | <less than operator>
      | <greater than operator>
      | <less than or equals operator>
      | <greater than or equals operator>

  <between predicate> ::=
      <row value designator> [ NOT ] BETWEEN
        <row value designator> AND <row value designator>

  <in predicate> ::=
      <row value designator>
        [ NOT ] IN <in predicate value>

  <in predicate value> ::=
        <table subquery>
      | <left paren> <in value list> <right paren>

  <in value list> ::=
      <value expression> ( <comma> <value expression> )...

  <like predicate> ::=
      <match value> [ NOT ] LIKE <pattern>
        [ ESCAPE <escape character> ]

  <match value> ::= <character value expression>

  <character value expression> ::=
        <concatenation>
      | <character factor>

  <concatenation> ::=
      <character value expression> <concatenation operator>
          <character factor>

  <character factor> ::=
      <character primary> [ <collate clause> ]

  <character primary> ::=
        <value expression primary>
      | <string value function>

  <string value function> ::=
        <character value function>
      | <bit value function>

  <character value function> ::=
        <character substring function>
      | <regular expression substring function>
      | <fold>
      | <form-of-use conversion>
      | <character translation>
      | <trim function>

  <character substring function> ::=
      SUBSTRING <left paren> <character value expression> FROM <start position>
                  [ FOR <string length> ] <right paren>

  <start position> ::= <numeric value expression>

  <string length> ::= <numeric value expression>

  <regular expression substring function> ::=
      SUBSTRING <left paren> <character value expression> FROM
                  <character value expression> FOR
                        <escape character> <right paren>

  <escape character> ::= <character value expression>

  <fold> ::= ( UPPER | LOWER )
       <left paren> <character value expression> <right paren>

  <form-of-use conversion> ::=
      CONVERT <left paren> <character value expression>
          USING <form-of-use conversion name> <right paren>

  <form-of-use conversion name> ::= <schema qualified name>
  <character translation> ::=
      TRANSLATE <left paren> <character value expression>
          USING <translation name> <right paren>

  <translation name> ::= <schema qualified name>

  <trim function> ::=
      TRIM <left paren> <trim operands> <right paren>

  <trim operands> ::=
      [ [ <trim specification> ] [ <trim character> ] FROM ] <trim source>

  <trim specification> ::=
        LEADING
      | TRAILING
      | BOTH

  <trim character> ::= <character value expression>

  <trim source> ::= <character value expression>

  <bit value function> ::=
      <bit substring function>

  <bit substring function> ::=
      SUBSTRING <left paren> <bit value expression> FROM <start position>
          [ FOR <string length> ] <right paren>

  <bit value expression> ::=
        <bit concatenation>
      | <bit factor>

  <bit concatenation> ::=
      <bit value expression> <concatenation operator> <bit factor>

  <bit factor> ::= <bit primary>

  <bit primary> ::=
        <value expression primary>
      | <string value function>

  <collate clause> ::= COLLATE <collation name>

  <collation name> ::= <schema qualified name>

  <pattern> ::= <character value expression>

  <null predicate> ::= <row value designator>
      IS [ NOT ] NULL
          [ <left paren> <null values specification> <right paren> ]

  <null values specification> ::= <asterisk> | <null state>

  <quantified comparison predicate> ::=
      <row value designator> <comp op> <quantifier> <table subquery>

  <quantifier> ::= <all> | <some>

  <all> ::= ALL

  <some> ::= SOME | ANY

  <exists predicate> ::= EXISTS <table subquery>

  <unique predicate> ::= UNIQUE <table subquery>

  <match predicate> ::=
      <row value designator> MATCH [ UNIQUE ]
          [ PARTIAL | FULL ] <table subquery>

  <overlaps predicate> ::=
      <row value designator 1> OVERLAPS <row value designator 2>

  <row value designator 1> ::= <row value designator>

  <row value designator 2> ::= <row value designator>

  <row value designator 1> ::= <row value designator>

  <row value designator 2> ::= <row value designator>

  <similar predicate> ::=
      <match value> [ NOT ] SIMILAR TO
          <similar pattern>
        [ ESCAPE <escape character> ]

  <similar pattern> ::= <character value expression>

  <quantified predicate> ::=
        <existential clause> <left paren> <search condition> <right paren>
      | <universal clause> <left paren> <search condition> <right paren>
      | <quantified comparison predicate>

  <existential clause> ::=
      FOR SOME <table reference list>

  <table reference list> ::=
      <table reference> [ ( <comma> <table reference> )... ]

  <table reference> ::=
        <table name> [ [ AS ] <correlation name>
            [ <left paren> <derived column list> <right paren> ] ]
      | <derived table> [ AS ] <correlation name>
            [ <left paren> <derived column list> <right paren> ]
      | <joined table>

  <derived column list> ::= <column name list>

  <column name list> ::=
      <column name> [ ( <comma> <column name> )... ]

  <derived table> ::= <table subquery>

  <joined table> ::=
        <cross join>
      | <qualified join>
      | <left paren> <joined table> <right paren>

  <cross join> ::=
      <table reference> CROSS JOIN <table reference>

  <qualified join> ::=
      <table reference> [ NATURAL ] [ <join type> ] JOIN
        <table reference> [ <join specification> ]

  <join type> ::=
        INNER
      | <outer join type> [ OUTER ]
      | UNION

  <outer join type> ::=
        LEFT
      | RIGHT
      | FULL

  <join specification> ::=
        <join condition>
      | <named columns join>
      | <constraint join>

  <join condition> ::= ON <search condition>

  <named columns join> ::=
      USING <left paren> <join column list> <right paren>

  <join column list> ::= <column name list>

  <constraint join> ::=
      | USING PRIMARY KEY
      | USING FOREIGN KEY
      | USING CONSTRAINT <constraint name>

  <constraint name> ::= <schema qualified name>

  <universal clause> ::=
      FOR ALL <table reference list>

  <there is predicate> ::=
      <left paren> <there is clause> <where clause> <right paren>

  <there is clause> ::=
      THERE IS <table reference list>

  <where clause> ::= WHERE <search condition>

  <distinct predicate> ::=
      <row value designator 1> IS DISTINCT FROM
          <row value designator 2>

  <boolean predicate> ::=
      <boolean value expression> [ IS [ NOT ]
            <truth value> ]

  <truth value> ::=
        TRUE
      | FALSE
      | UNKNOWN

  <cast specification> ::=
      CAST <left paren> <cast operand> AS
          <cast target> <right paren>

  <cast operand> ::=
        <value expression>
      | NULL

  <cast target> ::=
        <domain name>
      | <data type>

  <data type> ::=
        <predefined type>
      | <abstract data type name>
      | <generated type reference>
      | <template parameter name>
      | <collection type>

  <predefined type> ::=
        <character string type>
             [ CHARACTER SET <character set specification> ]
      | <national character string type>
      | <bit string type>
      | <numeric type>
      | <enumerated type>
      | <boolean type>
      | <datetime type>
      | <interval type>

  <character string type> ::=
        CHARACTER [ <left paren> <length> <right paren> ]
      | CHAR [ <left paren> <length> <right paren> ]
      | CHARACTER VARYING <left paren> <length> <right paren>
      | CHAR VARYING <left paren> <length> <right paren>
      | VARCHAR <left paren> <length> <right paren>

  <length> ::= <unsigned integer>

  <national character string type> ::=
        NATIONAL CHARACTER [ <left paren> <length> <right paren> ]
      | NATIONAL CHAR [ <left paren> <length> <right paren> ]
      | NCHAR [ <left paren> <length> <right paren> ]
      | NATIONAL CHARACTER VARYING <left paren> <length> <right paren>
      | NATIONAL CHAR VARYING <left paren> <length> <right paren>
      | NCHAR VARYING <left paren> <length> <right paren>

  <bit string type> ::=
        BIT [ <left paren> <length> <right paren> ]
      | BIT VARYING <left paren> <length> <right paren>

  <numeric type> ::=
        <exact numeric type>
      | <approximate numeric type>

  <exact numeric type> ::=
        NUMERIC [ <left paren> <precision> [ <comma> <scale> ] <right paren> ]
      | DECIMAL [ <left paren> <precision> [ <comma> <scale> ] <right paren> ]
      | DEC [ <left paren> <precision> [ <comma> <scale> ] <right paren> ]
      | INTEGER
      | INT
      | SMALLINT

  <precision> ::= <unsigned integer>

  <scale> ::= <unsigned integer>

  <approximate numeric type> ::=
        FLOAT [ <left paren> <precision> <right paren> ]
      | REAL
      | DOUBLE PRECISION

  <enumerated type> ::=
      <left paren> <enumeration name list> <right paren>

  <enumeration name list> ::=
      <enumeration name> [ ( <comma> <enumeration name> )... ]

  <boolean type> ::= BOOLEAN

  <datetime type> ::=
        DATE
      | TIME [ <left paren> <time precision> <right paren> ]
            [ WITH TIME ZONE ]
      | TIMESTAMP [ <left paren> <timestamp precision> <right paren> ]
            [ WITH TIME ZONE ]
  <time precision> ::= <time fractional seconds precision>

  <time fractional seconds precision> ::= <unsigned integer>

  <timestamp precision> ::= <time fractional seconds precision>

  <interval type> ::= INTERVAL <interval qualifier>

  <generated type reference> ::=
      <type template name> <template parameter list>

  <type template name> ::= <schema qualified name>

  <template parameter list> ::=
      <left paren>
        <template parameter> [ ( <comma> <template parameter> )... ]
      <right paren>

  <template parameter> ::=
        <value specification>
      | <data type>

  <collection type> ::=
        <set type>
      | <multiset type>
      | <list type>

  <set type> ::= SET <left paren> <data type> <right paren>

  <multiset type> ::= MULTISET <left paren> <data type> <right paren>

  <list type> ::= LIST <left paren> <data type> <right paren>

  <numeric value function> ::=
        <position expression>
      | <extract expression>
      | <length expression>

  <position expression> ::=
      POSITION <left paren> <character value expression>
          IN <character value expression> <right paren>

  <extract expression> ::=
      EXTRACT <left paren> <extract field>
          FROM <extract source> <right paren>

  <extract field> ::=
        <datetime field>
      | <time zone field>

  <datetime field> ::=
        <non-second datetime field>
      | SECOND

  <time zone field> ::=
        TIMEZONE_HOUR
      | TIMEZONE_MINUTE

  <extract source> ::=
        <datetime value expression>
      | <interval value expression>

  <datetime value expression> ::=
        <datetime term>
      | <interval value expression> <plus sign> <datetime term>
      | <datetime value expression> <plus sign> <interval term>
      | <datetime value expression> <minus sign> <interval term>

  <interval term> ::=
        <interval factor>
      | <interval term 2> <asterisk> <factor>
      | <interval term 2> <solidus> <factor>
      | <term> <asterisk> <interval factor>

  <interval factor> ::=
      [ <sign> ] <interval primary>

  <interval primary> ::=
        <value expression primary> [ <interval qualifier> ]

  <interval term 2> ::= <interval term>

  <interval value expression> ::=
        <interval term>
      | <interval value expression 1> <plus sign> <interval term 1>
      | <interval value expression 1> <minus sign> <interval term 1>
      | <left paren> <datetime value expression> <minus sign>
            <datetime term> <right paren> <interval qualifier>

  <interval value expression 1> ::= <interval value expression>

  <interval term 1> ::= <interval term>

  <datetime term> ::=
        <datetime factor>

  <datetime factor> ::=
        <datetime primary> [ <time zone> ]

  <datetime primary> ::=
        <value expression primary>
      | <datetime value function>

  <datetime value function> ::=
        <current date value function>
      | <current time value function>
      | <current timestamp value function>

  <current date value function> ::= CURRENT_DATE

  <current time value function> ::=
        CURRENT_TIME [ <left paren> <time precision> <right paren> ]

  <current timestamp value function> ::=
        CURRENT_TIMESTAMP [ <left paren> <timestamp precision> <right paren> ]

  <time zone> ::=
      AT <time zone specifier>

  <time zone specifier> ::=
        LOCAL
      | TIME ZONE <interval primary>

  <length expression> ::=
        <char length expression>
      | <octet length expression>
      | <bit length expression>

  <char length expression> ::=
      ( CHAR_LENGTH | CHARACTER_LENGTH )
          <left paren> <string value expression> <right paren>

  <string value expression> ::=
        <character value expression>
      | <bit value expression>

  <octet length expression> ::=
      OCTET_LENGTH <left paren> <string value expression> <right paren>

  <bit length expression> ::=
      BIT_LENGTH <left paren> <string value expression> <right paren>

  <enumerated value expression> ::=
        <domain name> <left paren> <value expression> <right paren>
      | <enumerated primary>

  <enumerated primary> ::=
        <value expression primary>

  <attributes function> ::=
      ATTRIBUTES
        <left paren> <abstract data type value expression> <right paren>

  <abstract data type value expression> ::= <ADT expression>

  <ADT expression> ::=
      <ADT term>
      | <ADT expression> <term operator> <ADT term>

  <term operator> ::= <ADT operator>

  <ADT operator> ::= <user-defined operator symbol)

  <ADT term> ::=
      <ADT factor>
      | <ADT term> <factor operator> <ADT factor>

  <factor operator> ::= <ADT operator>

  <ADT factor> ::=
      <ADT primary>
      | <prefix operator> <ADT primary>
      | <ADT primary> <postfix operator>

  <ADT primary> ::=
      <value expression primary>

  <prefix operator> ::= <ADT operator>

  <postfix operator> ::= <ADT operator>

  <table value expression> ::=
      <table type>
        <left paren>
          [ <value expression> [ ( <comma> <value expression> )... ] ]
        <right paren>

  <table type> ::=
        TABLE
      | SET
      | LIST

  <collection value expression> ::=
        <set value designator>
      | <multiset value designator>
      | <list value designator>

  <set value designator> ::=
      SET <left paren> [ <collection list> ] <right paren>

  <collection list> ::=
      <collection element> [ ( <comma> <collection element> )... ]

  <collection element> ::= <value expression>

  <multiset value designator> ::=
      MULTISET <left paren> [ <collection list> ] <right paren>

  <list value designator> ::=
      LIST <left paren> [ <collection list> ] <right paren>

  <as clause> ::= [ AS ] <column name>

  <table expression> ::=
      <from clause>
      [ <where clause> ]
      [ <group by clause> ]
      [ <having clause> ]

  <from clause> ::= FROM <table reference>
      [ ( <comma> <table reference> )... ]

  <group by clause> ::=
      GROUP BY <grouping column reference list>

  <grouping column reference list> ::=
      <grouping column reference>
          [ ( <comma> <grouping column reference> )... ]

  <grouping column reference> ::=
      <column reference> [ <collate clause> ]

  <having clause> ::= HAVING <search condition>

  <table value designator> ::=
      VALUES <table value designator list>

  <table value designator list> ::=
      <row value designator> [ ( <comma> <row value designator> )... ]

  <explicit table> ::= <table type> <table name>

  <collection expression> ::=
      <value expression>

  <query term> ::=
        <non-join query term>
      | <joined table>

  <corresponding spec> ::=
      CORRESPONDING [ BY <left paren> <corresponding column list> <right paren> ]

  <corresponding column list> ::= <column name list>

  <query primary> ::=
        <non-join query primary>
      | <joined table>

  <recursive union> ::=
      <left paren> <initial expression>
        RECURSIVE UNION <correlation name list>
            [ <left paren> <recursive column list> <right paren> ]
        <iteration expression>
        [ <search clause> ]
        [ <cycle clause> ]
        [ <limit clause> ] <right paren>

  <initial expression> ::= <query expression>

  <correlation name list> ::=
      <correlation name> [ ( <comma> <correlation name> )... ]

  <recursive column list> ::= <column name list>

  <iteration expression> ::= <query expression>

  <search clause> ::=
      SEARCH <search order> SET <sequence column>

  <search order> ::=
        PREORDER
      | ( DEPTH | BREADTH ) FIRST BY <sort specification list>

  <sort specification list> ::=
      <sort specification> [ ( <comma> <sort specification> )... ]

  <sort specification> ::=
      <sort key> [ <collate clause> ] [ <ordering specification> ]

  <sort key> ::=
      <value expression>

  <ordering specification> ::= ASC | DESC

  <sequence column> ::= <column name>

  <cycle clause> ::=
      CYCLE [ <cycle column list> ]
        SET <cycle mark column>
            [ TO <cycle mark value> ]

  <cycle column list> ::=
      <cycle column> [ ( <comma> <cycle column> )... ]

  <cycle column> ::= <column name>

  <cycle mark column> ::= <column name>

  <cycle mark value> ::= <value expression>

  <limit clause> ::=
      [ RETURN | EXCEPTION ] LIMIT
          <left paren> <value specification> <right paren>

  <trigger definition> ::=
      [ CREATE ] TRIGGER [ <trigger name> ]
        <trigger action time> <trigger event>
          [ ON <table name> ]
          [ ORDER <order value> ]
          [ REFERENCING <old or new values alias list> ]
        <triggered action>

  <trigger name> ::= <schema qualified name>

  <trigger action time> ::=
        BEFORE
      | AFTER
      | INSTEAD OF

  <trigger event> ::=
        INSERT
      | DELETE
      | UPDATE [ OF <trigger column list> ]

  <trigger column list> ::= <column name list>

  <order value> ::= <unsigned integer>

  <old or new values alias list> ::=
      <old or new values alias>...

  <old or new values alias> ::=
        OLD [ AS ]
            <old values correlation name>
      | NEW [ AS ]
            <new values correlation name>
      | OLD_TABLE [ AS ]
            <old values table alias>
      | NEW_TABLE [ AS ]
            <new values table alias>

  <old values correlation name> ::= <correlation name>

  <new values correlation name> ::= <correlation name>

  <old values table alias> ::= <identifier>

  <new values table alias> ::= <identifier>

  <triggered action> ::=
      [ FOR EACH ( ROW | STATEMENT ) ]
        [ WHEN <left paren> <search condition> <right paren> ]
        <triggered SQL statement>

  <triggered SQL statement> ::=
      <SQL procedure statement> <semicolon>

  <SQL procedure statement> ::=
      [ ASYNC <left paren> <async statement identifier> <right paren> ]
            <SQL executable statement>

  <async statement identifier> ::= <numeric value expression>

  <SQL executable statement> ::=
        <SQL schema statement>
      | <SQL data statement>
      | <SQL transaction statement>
      | <SQL connection statement>
      | <SQL session statement>
      | <SQL diagnostics statement>

  <SQL schema statement> ::=
        <SQL schema definition statement>
      | <SQL schema manipulation statement>

  <SQL schema definition statement> ::=
        <schema definition>
      | <table definition>
      | <view definition>
      | <grant statement>
      | <role definition>
      | <grant role statement>
      | <domain definition>
      | <null class definition>
      | <character set definition>
      | <collation definition>
      | <translation definition>
      | <assertion definition>
      | <trigger definition>
      | <routine>
      | <abstract data type definition>
      | <type template definition>

  <schema definition> ::=
      CREATE SCHEMA <schema name clause>
        [ <schema character set specification> ]
        [ <schema path specification> ]
        [ <schema element>... ]

  <schema name clause> ::=
        <schema name>
      | AUTHORIZATION <schema authorization identifier>
      | <schema name> AUTHORIZATION <schema authorization identifier>

  <schema authorization identifier> ::=
      <authorization identifier>

  <schema character set specification> ::=
      DEFAULT CHARACTER SET <character set specification>

  <schema path specification> ::=
      PATH <schema name list>

  <schema element> ::=
        <table definition>
      | <view definition>
      | <domain definition>
      | <null class definition>
      | <character set definition>
      | <collation definition>
      | <translation definition>
      | <assertion definition>
      | <trigger definition>
      | <routine>
      | <abstract data type definition>
      | <type template definition>
      | <grant statement>
      | <role definition>
      | <grant role statement>

  <table definition> ::=
      CREATE [ <table scope> ] <table type> <table name>
        [ <constant or updatable> ]
        ( <table element list> | <subtable clause> )
        [ ON COMMIT <table commit action> ROWS ]

  <table scope> ::=
      <global or local> TEMPORARY

  <global or local> ::=
        GLOBAL
      | LOCAL

  <constant or updatable> ::=
        CONSTANT
      | UPDATABLE

  <table element list> ::=
      <left paren> <table element> [ ( <comma> <table element> )... ] <right paren>

  <table element> ::=
        <column definition>
      | <table constraint definition>
      | <like clause>

  <column definition> ::=
      <column name>
      ( <data type> | <domain name> )
      [ <default clause> ]
      [ <column constraint definition>... ]
      [ <collate clause> ]
      [ <null clause> ]

  <default clause> ::=
        ( DEFAULT | <assignment operator> ) <default option>

  <default option> ::=
        <literal>
      | <datetime value function>
      | USER
      | CURRENT_USER
      | SESSION_USER
      | SYSTEM_USER
      | NULL [ <left paren> <null state> <right paren> ]
      | <function invocation>

  <column constraint definition> ::=
      [ <constraint name definition> ]
      <column constraint> [ <constraint attributes> ]

  <constraint name definition> ::= CONSTRAINT <constraint name>

  <column constraint> ::=
        NOT NULL
      | <unique specification>
      | <references specification>
      | <check constraint definition>

  <unique specification> ::=
        UNIQUE
      | PRIMARY KEY

  <references specification> ::=
      REFERENCES [ PENDANT ] <referenced table and columns>
        [ MATCH <match type> ]
        [ <referential triggered action> ]

  <referenced table and columns> ::=
       <table name> [ <left paren> [ <reference column list> ] <right paren> ]

  <reference column list> ::= <column name list>

  <match type> ::=
        FULL
      | PARTIAL

  <referential triggered action> ::=
        <update rule> [ <delete rule> ]
      | <delete rule> [ <update rule> ]

  <update rule> ::= ON UPDATE <referential action>

  <referential action> ::=
        CASCADE
      | SET NULL [ <left paren> <null state> <right paren> ]
      | SET DEFAULT
      | RESTRICT
      | NO ACTION
  <delete rule> ::= ON DELETE <referential action>

  <check constraint definition> ::=
      CHECK <left paren> <search condition> <right paren>

  <constraint attributes> ::=
        <constraint check time> [ [ NOT ] DEFERRABLE ]
      | [ NOT ] DEFERRABLE [ <constraint check time> ]

  <constraint check time> ::=
        INITIALLY DEFERRED
      | INITIALLY IMMEDIATE

  <null clause> ::=
      NULL IS <null class name>

  <null class name> ::= <schema qualified name>

  <null clause> ::=
      NULL IS <null class name>

  <table constraint definition> ::=
      [ <constraint name definition> ]
      <table constraint> [ <constraint attributes> ]

  <table constraint> ::=
        <unique constraint definition>
      | <referential constraint definition>
      | <check constraint definition>

  <unique constraint definition> ::=
                                  even in SQL3)
        <unique specification> [ <left paren> <unique column list>
            <right paren> ]
      | UNIQUE ( VALUE )

  <unique column list> ::= <column name list>

  <referential constraint definition> ::=
      FOREIGN KEY [ <left paren> <referencing columns> <right paren> ]
        <references specification>

  <referencing columns> ::=
      <reference column list>

  <like clause> ::= LIKE <table name>

  <subtable clause> ::=
      UNDER <supertable clause>
          [ ( , <supertable clause> )... ]

  <supertable clause> ::=
      <supertable name>
        [ WITH ( <member renaming element>
            [ ( , <member renaming element> )... ] ) ]

  <supertable name> ::= <table name>

  <member renaming element> ::=
      <supertable member name> AS <subtable member name>

  <supertable member name> ::=
        <column name>
      | <routine name>

  <subtable member name> ::=
        <column name>
      | <routine name>

  <table commit action> ::=
        PRESERVE
      | DELETE

  <view definition> ::=
      CREATE VIEW <table name> [ <left paren> <view column list> <right paren> ]
        AS <query expression>
        [ WITH [ <levels clause> ] CHECK OPTION ]

  <view column list> ::= <column name list>

  <levels clause> ::=
        CASCADED
      | LOCAL

  <domain definition> ::=
      CREATE DOMAIN <domain name>
          [ AS ] <data type>
        [ <default clause> ]
        [ <domain constraint>... ]
        [ <collate clause> ]
        [ <null clause> ]

  <domain constraint> ::=
      [ <constraint name definition> ]
      <check constraint definition> [ <constraint attributes> ]

  <null class definition> ::=
      CREATE NULL CLASS <null class name> [ AS ]
          ( <null state list> )

  <null state list> ::=
      <null state> [ ( <comma> <null state> )... ]

  <character set definition> ::=
      CREATE CHARACTER SET <character set name>
          [ AS ]
        <character set source>
        <form-of-use specification>
        [ <collate clause> | <limited collation definition> ]

  <character set source> ::=
        GET <existing character set name>
            [ <plus sign> <character set source> ]
      | <left paren> <character list> <right paren>

  <character list> ::=
      <character specification> [ ( <comma> <character specification> )... ]

  <character specification> ::=
        <character string literal>
      | <ISO 10646 position>
      | <ISO 10646 character name>

  <ISO 10646 position> ::=
      <val> [ <sep> <val> [ <sep> <val> [ <sep> <val> ] ] ]

  <val> ::= <unsigned numeric literal>

  <sep> ::= <ampersand>

  <ISO 10646 character name> ::= !! <EMPHASIS>(See the Syntax Rules)

  <form-of-use specification> ::= <identifier>

  <limited collation definition> ::=
      COLLATION FROM <collation source>

  <collation source> ::=
        <collating sequence definition>
      | <translation collation>
      | <collation dictionary specification>
      | <collation routine specification>

  <collating sequence definition> ::=
        <external collation>
      | <schema collation name>
      | <internal collation source>
      | DESC <left paren> <collation name> <right paren>
      | DEFAULT

  <external collation> ::=
      EXTERNAL
          <left paren> <quote> <external collation name> <quote> <right paren>

  <external collation name> ::=
        <standard collation name>
      | <implementation-defined collation name>

  <standard collation name> ::= <collation name>

  <implementation-defined collation name> ::= <collation name>

  <schema collation name> ::= <collation name>

  <internal collation source> ::= <left paren> <collation options> <right paren>

  <collation options> ::=
      <collation option> [ ( <comma> <collation option> )... ]

  <collation option> ::=
        USING <left paren> <collating basis> <right paren>
      | SEQUENCE <left paren> <enumerated collating sequence> <right paren>
      | MODIFY <left paren> <collating modifiers> <right paren>
      | WHEN NOT FOUND
          ( IGNORE | MAX | MIN )

  <collating basis> ::=
      <collating foundation> [ ( <plus sign> <collating foundation> )... ]

  <collating foundation> ::=
      <collating sequence definition>
      <collating sequence definition> [ ( <asterisk> <translation name> )... ]

  <enumerated collating sequence> ::=
      <collating chars> [ ( <comma> <collating chars> )... ]

  <collating chars> ::=
        <character specification>
      | <character range>

  <character range> ::=
      <character specification> <minus sign> <character specification>

  <collating modifiers> ::=
        <collating modifier> [ ( <comma> <collating modifier> )... ]

  <collating modifier> ::=
      <collating chars>
        ( <less than operator> | <greater than operator> | <equals operator> )
      <collating chars>

  <translation collation> ::=
      TRANSLATION <translation name>
          [ THEN COLLATION <collation name> ]

  <collation dictionary specification> ::=
      DICTIONARY <dictionary name> [ <plus sign> <dictionary name> ]

  <dictionary name> ::=
      <quote> <implementation-defined dictionary name> <quote>

  <implementation-defined dictionary name> ::= !! <EMPHASIS>(See the Syntax Rules)

  <collation routine specification> ::=
        ROUTINE <left paren> <implementation-defined routine name>
            <left paren> <params> <right paren> <right paren>

  <implementation-defined routine name> ::= !! <EMPHASIS>(See the Syntax Rules)

  <params> ::= !! <EMPHASIS>(Not yet defined)

  <params> ::= !! <EMPHASIS>(Not yet defined)

  <existing character set name> ::=
        <standard character repertoire name>
      | <implementation-defined character repertoire name>
      | <schema character set name>

  <schema character set name> ::= <character set name>

  <collation definition> ::=
      CREATE COLLATION <collation name> FOR
          <character set specification>
        FROM <collation source>
          [ <pad attribute> ]

  <pad attribute> ::=
        NO PAD
      | PAD SPACE

  <translation definition> ::=
      CREATE TRANSLATION <translation name>
        FOR <source character set specification>
          TO <target character set specification>
        FROM <translation source>

  <source character set specification> ::= <character set specification>

  <target character set specification> ::= <character set specification>

  <translation source> ::=
        <translation specification>
      | <translation routine>

  <translation specification> ::=
        <external translation>
      | IDENTITY
      | <schema translation name>
      | <internal translation source>

  <external translation> ::=
      EXTERNAL
          <left paren> <quote> <external translation name> <quote> <right paren>

  <external translation name> ::=
        <standard translation name>
      | <implementation-defined translation name>

  <standard translation name> ::= <translation name>

  <implementation-defined translation name> ::= <translation name>

  <schema translation name> ::= <translation name>

  <internal translation source> ::=
      <left paren> <translation options> <right paren>

  <translation options> ::=
      <translation option> [ ( <comma> <translation option> )... ]

  <translation option> ::=
        USING <left paren> <translation basis> <right paren>
      | MODIFY <left paren> <translation modifiers> <right paren>

  <translation basis> ::=
      <translation definition> [ ( <asterisk> <translation definition> )... ]

  <translation modifiers> ::=
        <translation modifier> [ ( <comma> <translation modifier> )... ]

  <translation modifier> ::=
      <collating chars> <equals operator> <collating chars>

  <translation routine> ::=
        ROUTINE <left paren> <implementation-defined routine name>
            <left paren> <params> <right paren> <right paren>

  <assertion definition> ::=
      CREATE ASSERTION <constraint name>
        <assertion trigger>...
        <triggered assertion> [ <constraint attributes> ]

  <assertion trigger> ::=
        <immediate assertion trigger>
      | <deferred assertion trigger>

  <immediate assertion trigger> ::=
      AFTER ( <assertion trigger statement>
        [ ( <comma> <assertion trigger statement> )... ] ON
             <table name> )...

  <assertion trigger statement> ::=
        INSERT
      | DELETE
      | UPDATE [ OF <left paren> <assertion column list> <right paren> ]

  <assertion column list> ::= <column name list>

  <deferred assertion trigger> ::= BEFORE COMMIT

  <triggered assertion> ::=
      CHECK <left paren> <search condition> <right paren>
        [ FOR
            [ EACH [ ROW OF ] ] <table name> ]

  <routine> ::=
      [ CREATE | DECLARE ] <routine header> <routine name> <parameter list>
      [ <returns clause> ]
      [ <caller language clause> ]
      [ SPECIFIC <specific name> ] <semicolon>
      <routine body> <semicolon>

  <routine header> ::=
        PROCEDURE
      | [ <function type> ] FUNCTION

  <function type> ::=
        CONSTRUCTOR
      | DESTRUCTOR
      | DESIGNATOR
      | ACTOR

  <parameter list> ::=
      <left paren>
        [ <parameter declaration> [ (  <comma> <parameter declaration> )... ] ]
      <right paren>

  <parameter declaration> ::=
        [ <parameter mode> ] [ <parameter name> ] <data type>
            [ <default clause> ]
      | <status parameter>

  <parameter mode> ::=
        IN
      | OUT
      | INOUT

  <status parameter> ::=
        SQLSTATE
      | SQLCODE

  <returns clause> ::= RETURNS <returns data type> [ <result cast> ]

  <returns data type> ::= <data type>

  <result cast> ::= CAST FROM <data type>

  <caller language clause> ::= <language clause>

  <specific name> ::= <schema qualified name>

  <routine body> ::=
        <SQL routine body>
      | <external body reference>

  <SQL routine body> ::= <SQL procedure statement>

  <external body reference> ::=
      EXTERNAL [ NAME <external routine name> ]
      <external routine language clause>
      [ <variant attribute> ]

  <external routine name> ::= <identifier>

  <external routine language clause> ::= <language clause>

  <variant attribute> ::=
        VARIANT
      | NOT VARIANT

  <abstract data type definition> ::=
        <distinct type definition>
      | <explicit abstract data type definition>

  <distinct type definition> ::=
      CREATE DISTINCT TYPE <distinct type name>
        AS <data type>

  <distinct type name> ::= <abstract data type name>

  <explicit abstract data type definition> ::=
      CREATE TYPE <abstract data type name>
        <abstract data type body>

  <abstract data type body> ::=
      [ <oid options> ]
      [ <subtype clause> ]
      [ [ <constant or updatable> ] [ <member list> ] ]

  <oid options> ::=
        WITH OID [ [ NOT ] VISIBLE ]
      | WITHOUT OID

  <subtype clause> ::=
      UNDER <supertype clause>
          [ ( <comma> <supertype clause> )... ]

  <supertype clause> ::=
      <abstract data type name> [ <component renaming clause> ]

  <component renaming clause> ::=
      WITH <left paren> <component renaming element>
          [ ( , <component renaming element> )... ] <right paren>

  <component renaming element> ::=
      <supertype component name> AS <subtype component name>

  <supertype component name> ::= <component name>

  <component name> ::= <identifier>

  <subtype component name> ::= <component name>

  <member list> ::=
      <left paren> <member> [ ( <comma> <member> )... ] <right paren>

  <member> ::=
        <attribute definition>
      | <routine declaration>
      | <operator name list>
      | <equals clause>
      | <less-than clause>
      | <cast clause>
      | <table constraint definition>

  <attribute definition> ::=
        <stored attribute>
      | <virtual attribute>

  <stored attribute> ::=
      [ <encapsulation level> ]
      <attribute name> [ <constant or updatable> ]
      ( <data type> | <domain name> )
      [ <default clause> ]
      [ <column constraint definition>... ]
      [ <collate clause> ]
      [ <null clause> ]

  <encapsulation level> ::=
        PRIVATE
      | PROTECTED
      | PUBLIC
  <virtual attribute> ::=
      [ <encapsulation level> ]
        <attribute name> <derivation clause>
      [ <check constraint definition>... ]
      [ <collate clause> ]

  <derivation clause> ::=
      [ READ ONLY | CONSTANT | UPDATABLE ] <data type>
        VIRTUAL [ <derivation functions> ]

  <derivation functions> ::=
        <get function> [ <set function> ]
      | <set function> [ <get function> ]

  <get function> ::=
      GET WITH <routine name>

  <set function> ::=
      SET WITH <routine name>

  <routine declaration> ::=
      [ <encapsulation level> ] <routine>

  <operator name list> ::=
      OPERATORS <specific routine designator>...

  <specific routine designator> ::=
        SPECIFIC <specific name>
      | <member name>

  <member name> ::= <routine name> [ <data type list> ]

  <data type list> ::=
      <left paren> <data type> [ ( <comma> <data type> )... ] <right paren>

  <equals clause> ::=
      EQUALS <equals function specification> <semicolon>

  <equals function specification> ::=
        <routine name>
      | STATE
      | OID

  <less-than clause> ::=
      LESS THAN <less-than function specification> <semicolon>

  <less-than function specification> ::=
        <routine name>
      | NONE

  <cast clause> ::=
      CAST <left paren> <operand data type> AS
          <result data type>
           WITH <cast function> <right paren> <semicolon>

  <operand data type> ::= <data type>

  <result data type> ::= <data type>

  <cast function> ::=
      <routine name>

  <type template definition> ::=
      CREATE TYPE TEMPLATE <type template name>
        <template parameter declaration list>
        <abstract data type body>
  <template parameter declaration list> ::=
      <left paren>
        <template parameter declaration>
          [ ( <comma> <template parameter declaration>)... ]
      <right paren>

  <template parameter declaration> ::=
      <template parameter name> <template parameter type>

  <template parameter type> ::=
        <data type>
      | TYPE

  <grant statement> ::=
      GRANT <privileges>
        TO <grantee> [ ( <comma> <grantee> )... ]
          [ WITH GRANT OPTION ]

  <privileges> ::=
        ALL SCHEMA PRIVILEGES
      | <object privileges> ON <object name>

  <object privileges> ::=
        ALL PRIVILEGES
      | <action> [ ( <comma> <action> )... ]

  <action> ::=
        SELECT [ <left paren> <privilege column list> <right paren> ]
      | DELETE
      | INSERT [ <left paren> <privilege column list> <right paren> ]
      | UPDATE [ <left paren> <privilege column list> <right paren> ]
      | REFERENCES [ <left paren> <privilege column list> <right paren> ]
      | USAGE
      | TRIGGER
      | EXECUTE
      | UNDER

  <privilege column list> ::= <column name list>

  <object name> ::=
        [ <table type> ] <table name>
      | DOMAIN <domain name>
      | COLLATION <collation name>
      | CHARACTER SET <character set name>
      | TRANSLATION <translation name>
      | NULL CLASS <null class name>
      | DATA TYPE <abstract data type name>
      | MODULE <module name>
      | TYPE TEMPLATE <type template name>
      | EXTERNAL ROUTINE <specific routine designator>

  <grantee> ::=
        PUBLIC
      | <authorization identifier>
      | <role name>

  <role name> ::= <authorization identifier>

  <role definition> ::= CREATE ROLE <role name>

  <grant role statement> ::=
      GRANT <role granted> [ ( <comma> <role granted> )... ]
        TO <grantee> [ ( <comma> <grantee> )... ]
          [ WITH ADMIN OPTION ]

  <role granted> ::= <role name>
  <SQL schema manipulation statement> ::=
        <drop schema statement>
      | <alter table statement>
      | <drop table statement>
      | <drop view statement>
      | <revoke statement>
      | <revoke role statement>
      | <drop role statement>
      | <alter domain statement>
      | <drop domain statement>
      | <drop null class statement>
      | <drop character set statement>
      | <drop collation statement>
      | <drop translation statement>
      | <drop assertion statement>
      | <drop trigger statement>
      | <drop routine statement>
      | <drop data type statement>
      | <drop type template statement>

  <drop schema statement> ::=
      DROP SCHEMA <schema name> <drop behavior>

  <drop behavior> ::= CASCADE | RESTRICT

  <alter table statement> ::=
      ALTER <table type> <table name> <alter table action>

  <alter table action> ::=
        <add column definition>
      | <alter column definition>
      | <drop column definition>
      | <add supertable clause>
      | <drop supertable clause>
      | <add table constraint definition>
      | <drop table constraint definition>

  <add column definition> ::=
      ADD [ COLUMN ] <column definition>

  <alter column definition> ::=
      ALTER [ COLUMN ] <column name> <alter column action>

  <alter column action> ::=
        <set column default clause>
      | <drop column default clause>
      | <drop column domain clause>

  <set column default clause> ::=
      SET <default clause>

  <drop column default clause> ::=
      DROP DEFAULT

  <drop column domain clause> ::=
      DROP DOMAIN [ <constraint disposition> [ <constraint name list> ] ]

  <constraint disposition> ::=
        KEEP COLUMN CONSTRAINT
      | DROP COLUMN CONSTRAINT

  <constraint name list> ::=
        ALL
      | <constraint name> [ ( <comma> <constraint name> )... ]

  <drop column definition> ::=
      DROP [ COLUMN ] <column name> <drop behavior>

  <add supertable clause> ::=
      ADD <supertable clause>

  <drop supertable clause> ::=
      DROP <supertable clause> <drop behavior>

  <add table constraint definition> ::=
      ADD <table constraint definition>

  <drop table constraint definition> ::=
      DROP CONSTRAINT <constraint name> <drop behavior>

  <drop table statement> ::=
      DROP <table type> <table name> <drop behavior>

  <drop view statement> ::=
      DROP VIEW <table name> <drop behavior>

  <revoke statement> ::=
      REVOKE [ GRANT OPTION FOR ]
          <privileges>
        FROM <grantee> [ ( <comma> <grantee> )... ] <drop behavior>

  <revoke role statement> ::=
      REVOKE <role revoked> [ ( <comma> <role revoked> )... ]
        FROM <grantee> [ ( <comma> <grantee> )... ]

  <role revoked> ::= <role name>

  <drop role statement> ::= DROP ROLE <role name>

  <alter domain statement> ::=
      ALTER DOMAIN <domain name> <alter domain action>

  <alter domain action> ::=
        <set domain default clause>
      | <drop domain default clause>
      | <add domain constraint definition>
      | <drop domain constraint definition>

  <set domain default clause> ::= SET <default clause>

  <drop domain default clause> ::= DROP DEFAULT

  <add domain constraint definition> ::=
      ADD <domain constraint>

  <drop domain constraint definition> ::=
      DROP CONSTRAINT <constraint name>
        [ <constraint disposition> ]

  <drop domain statement> ::=
      DROP DOMAIN <domain name> <drop behavior>
        [ <constraint disposition> [ <constraint name list> ] ]

  <drop null class statement> ::=
       DROP NULL CLASS <null class name>

  <drop character set statement> ::=
      DROP CHARACTER SET <character set name>

  <drop collation statement> ::=
      DROP COLLATION <collation name>
        <drop behavior>
  <drop translation statement> ::=
      DROP TRANSLATION <translation name>

  <drop assertion statement> ::=
      DROP ASSERTION <constraint name>

  <drop trigger statement> ::= DROP TRIGGER <trigger name>

  <drop routine statement> ::=
      DROP ( PROCEDURE | FUNCTION ) <specific routine designator> <drop behavior>

  <drop data type statement> ::=
      DROP DATA TYPE
          <abstract data type name> <drop behavior>

  <drop type template statement> ::=
      DROP TYPE TEMPLATE <type template name>
        <drop behavior>

  <SQL data statement> ::=
        <open statement>
      | <fetch statement>
      | <close statement>
      | <select statement: single row>
      | <new statement>
      | <destroy statement>
      | <SQL data change statement>

  <open statement> ::=
      OPEN <cursor name>
        [ <open cascade option> ]

  <open cascade option> ::=
        CASCADE ON
      | CASCADE OFF

  <fetch statement> ::=
      FETCH [ [ <fetch orientation> ] FROM ]
        <cursor name> INTO <fetch target list>

  <fetch orientation> ::=
        NEXT
      | PRIOR
      | FIRST
      | LAST
      | ( ABSOLUTE | RELATIVE ) <simple value specification>

  <simple value specification> ::=
        <item reference>
      | <literal>

  <fetch target list> ::=
      <target specification> [ ( <comma> <target specification> )... ]

  <target specification> ::=
        <item reference>
      | <template parameter name>

  <close statement> ::=
      CLOSE <cursor name>

  <select statement: single row> ::=
      SELECT [ <set quantifier> ] <select list>
        INTO <select target list>
          <table expression>

  <select target list> ::=
      <target specification> [ ( <comma> <target specification> )... ]

  <new statement> ::=
      NEW <item reference>

  <destroy statement> ::=
      DESTROY <object parameter name>

  <object parameter name> ::= <parameter name>

  <SQL data change statement> ::=
        <delete statement: positioned>
      | <delete statement: searched>
      | <insert statement>
      | <update statement: positioned>
      | <update statement: searched>

  <delete statement: positioned> ::=
      DELETE [ FROM <table name> ]
        WHERE CURRENT OF <cursor name>

  <delete statement: searched> ::=
      DELETE FROM <table reference>
        [ WHERE <search condition> ]

  <insert statement> ::=
      INSERT INTO ( <table reference> | CURSOR <cursor name> )
        <insert columns and source>
        [ <insert point> ]

  <insert columns and source> ::=
        [ <left paren> <insert column list> <right paren> ]
              <query expression>
      | DEFAULT VALUES

  <insert column list> ::= <column name list>

  <insert point> ::=
      <relative insert point> ELEMENT <where clause>

  <relative insert point> ::=
        BEFORE
      | AFTER

  <update statement: positioned> ::=
      UPDATE [ <table reference> ]
        SET [ <update type> ] <set clause list>
          WHERE CURRENT OF <cursor name>

  <update type> ::= ALL | SOME | NONE

  <set clause list> ::=
      <set clause> [ ( <comma> <set clause> )... ]

  <set clause> ::=
      <update target> <equals operator> <row value designator>

  <update target> ::=
        <object column>
      | <left paren> <object column list> <right paren>

  <object column> ::= <column name>

  <object column list> ::=
      <object column> [ ( <comma> <object column> )... ]
  <update statement: searched> ::=
      UPDATE <table reference>
        <update mechanism>
        [ WHERE <search condition> ]

  <update mechanism> ::=
        <update by setting>
      | <update by moving>

  <update by setting> ::=
      SET [ <update type> ] <set clause list>

  <update by moving> ::=
      MOVE <insert point>

  <SQL transaction statement> ::=
        <start transaction statement>
      | <set transaction statement>
      | <set constraints mode statement>
      | <test completion statement>
      | <savepoint statement>
      | <release savepoint statement>
      | <commit statement>
      | <rollback statement>

  <start transaction statement> ::=
      START TRANSACTION <transaction mode>
          [ ( <comma> <transaction mode> )...]

  <transaction mode> ::=
        <isolation level>
      | <transaction access mode>
      | <diagnostics size>

  <isolation level> ::=
      ISOLATION LEVEL <level of isolation>

  <level of isolation> ::=
        READ UNCOMMITTED
      | READ COMMITTED
      | REPEATABLE READ
      | SERIALIZABLE

  <transaction access mode> ::=
        READ ONLY
      | READ WRITE

  <diagnostics size> ::=
      DIAGNOSTICS SIZE <number of conditions>

  <number of conditions> ::= <simple value specification>

  <set transaction statement> ::=
      SET [ LOCAL ] TRANSACTION <transaction mode>
          [ ( <comma> <transaction mode> )... ]

  <set constraints mode statement> ::=
      SET CONSTRAINTS <constraint name list>
          ( DEFERRED | IMMEDIATE )

  <test completion statement> ::=
      ( TEST | WAIT )
         ( ALL | ANY | <async statement identifier list> )
      COMPLETION

  <async statement identifier list> ::=
      <left paren> <async statement identifier>
          [ ( <comma> <async statement identifier> )... ] <right paren>

  <savepoint statement> ::= SAVEPOINT <savepoint specifier>

  <savepoint specifier> ::=
        <savepoint name>
      | <simple target specification>

  <savepoint name> ::= <identifier>

  <simple target specification> ::=
      <item reference>

  <release savepoint statement> ::=
      RELEASE SAVEPOINT <savepoint specifier>

  <commit statement> ::=
      COMMIT [ WORK ] [ AND [ NO ] CHAIN ]

  <rollback statement> ::=
      ROLLBACK [ WORK ] [ AND[ NO ]  CHAIN ]
        [ <savepoint clause> ]

  <savepoint clause> ::=
      TO SAVEPOINT <savepoint specifier>

  <SQL connection statement> ::=
        <connect statement>
      | <set connection statement>
      | <disconnect statement>

  <connect statement> ::=
      CONNECT TO <connection target>

  <connection target> ::=
        <SQL-server name>
          [ AS <connection name> ]
            correspondence with Tony Gordon)
          [ USER <user name> ]
      | DEFAULT

  <SQL-server name> ::= <simple value specification>

  <connection name> ::= <simple value specification>

  <user name> ::= <simple value specification>

  <set connection statement> ::=
      SET CONNECTION <connection object>

  <connection object> ::=
        DEFAULT
      | <connection name>

  <disconnect statement> ::=
      DISCONNECT <disconnect object>

  <disconnect object> ::=
        <connection object>
      | ALL
      | CURRENT

  <SQL session statement> ::=
        <set session authorization identifier statement>
      | <set role statement>
      | <set local time zone statement>

  <set session authorization identifier statement> ::=
      SET SESSION AUTHORIZATION <value specification>

  <set role statement> ::=
      SET ROLE ( <role name> | NONE )

  <set local time zone statement> ::=
      SET TIME ZONE
          <set time zone value>

  <set time zone value> ::=
        <interval value expression>
      | LOCAL

  <SQL diagnostics statement> ::=
      <get diagnostics statement>

  <get diagnostics statement> ::=
      GET DIAGNOSTICS <sql diagnostics information>

  <sql diagnostics information> ::=
        <statement information>
      | <condition information>

  <statement information> ::=
      <statement information item> [ ( <comma> <statement information item> )... ]

  <statement information item> ::=
      <simple target specification>
          <equals operator> <statement information item name>

  <statement information item name> ::=
        NUMBER
      | MORE
      | COMMAND_FUNCTION
      | ROW_COUNT
      | TRANSACTIONS_COMMITTED
      | TRANSACTIONS_ROLLED_BACK
      | TRANSACTION_ACTIVE

  <condition information> ::=
      EXCEPTION <condition number>
        <condition information item>
            [ ( <comma> <condition information item> )... ]

  <condition number> ::= <simple value specification>

  <condition information item> ::=
      <simple target specification>
          <equals operator> <condition information item name>

  <condition information item name> ::=
        CONDITION_NUMBER
      | RETURNED_SQLSTATE
      | CLASS_ORIGIN
      | SUBCLASS_ORIGIN
      | SERVER_NAME
      | CONNECTION_NAME
      | CONSTRAINT_CATALOG
      | CONSTRAINT_SCHEMA
      | CONSTRAINT_NAME
      | TRIGGER_CATALOG
      | TRIGGER_SCHEMA
      | TRIGGER_NAME
      | CATALOG_NAME
      | SCHEMA_NAME
      | TABLE_NAME
      | COLUMN_NAME
      | CURSOR_NAME
      | ROUTINE_CATALOG
      | ROUTINE_SCHEMA
      | ROUTINE_NAME
      | SPECIFIC_NAME
      | MESSAGE_TEXT
      | MESSAGE_LENGTH
      | MESSAGE_OCTET_LENGTH

  <order by clause> ::=
      ORDER BY <sort specification list>

  <updatability clause> ::=
      FOR
          ( READ ONLY |
            UPDATE [ OF <column name list> ] )

  <temporary abstract data type declaration> ::=
      DECLARE TEMPORARY TYPE <abstract data type name>
          <abstract data type body>

  <temporary table declaration> ::=
      DECLARE LOCAL TEMPORARY <table type> <table name>
        <table element list>
        [ ON COMMIT <table commit action> ROWS ]

  <temporary view declaration> ::=
      DECLARE TEMPORARY VIEW <table name>
          [ <left paren> <view column list> <right paren> ]
          AS <query expression>

  <scalar subquery> ::= <subquery>

  <regular expression> ::=
        <regular term>
      | <regular expression> <vertical bar> <regular term>

  <regular term> ::=
        <regular factor>
      | <regular term> <regular factor>

  <regular factor> ::=
        <regular primary>
      | <regular primary> <asterisk>
      | <regular primary> <plus sign>

  <regular primary> ::=
        <character specifier>
      | <percent>
      | <regular character set>
      | <left paren> <regular expression> <right paren>

  <character specifier> ::=
        <non-escaped character>
      | <escaped character>

  <non-escaped character> ::= !! <EMPHASIS>(See the Syntax Rules)

  <escaped character> ::= !! <EMPHASIS>(See the Syntax Rules)

  <regular character set> ::=
        <underscore>
      | <left bracket> <character enumeration>... <right bracket>
      | <left bracket> <circumflex> <character enumeration>... <right bracket>
      | <left bracket> <colon> <regular character set identifier> <colon> <right bracket>

  <character enumeration> ::=
        <character specifier>
      | <character specifier> <minus sign> <character specifier>

  <regular character set identifier> ::= <identifier>

  <SQL object identifier> ::=
      <SQL provenance> <SQL variant>

  <SQL provenance> ::= <arc1> <arc2> <arc3>

  <arc1> ::= iso | 1 | iso <left paren> 1 <right paren>

  <arc2> ::= standard | 0 | standard <left paren> 0 <right paren>

  <arc3> ::= 9075

  <SQL variant> ::= <SQL edition> <SQL conformance>

  <SQL edition> ::= <1987> | <1989> | <1992>

  <1987> ::= 0 | edition1987 <left paren> 0 <right paren>

  <1989> ::= <1989 base> <1989 package>

  <1989 base> ::= 1 | edition1989 <left paren> 1 <right paren>

  <1989 package> ::= <integrity no> | <integrity yes>

  <integrity no> ::= 0 | IntegrityNo <left paren> 0 <right paren>

  <integrity yes> ::= 1 | IntegrityYes <left paren> 1 <right paren>

  <1992> ::= 2 | edition1992 <left paren> 2 <right paren>

  <SQL conformance> ::= <low> | <intermediate> | <high>

  <low> ::= 0 | Low <left paren> 0 <right paren>

  <intermediate> ::= 1 | Intermediate <left paren> 1 <right paren>

  <high> ::= 2 | High <left paren> 2 <right paren>

  44.  Appendix C - SQL Tutorial for beginners

       SQL tutorial is also distributed with PostgreSQL. The SQL tutorial
       scripts is in the directory src/tutorial

  The SQL tutorial for beginners can be found at
  <http://w3.one.net/~jhoffman/sqltut.htm>

  Comments or suggestions? Mail to jhoffman@one.net

  Or you may wish to look at <http://w3.one.net/~jhoffman/index.html>

  The following are the sites suggested by John Hoffman:

  <http://www.contrib.andrew.cmu.edu/~shadow/sql.html>SQL Reference

  <http://www.inquiry.com/techtips/thesqlpro/>Ask the SQL Pro

  <http://www.inquiry.com/techtips/thesqlpro/usefulsites.html>SQL Pro's
  Relational DB Useful Sites

  <http://infoweb.magi.com/~steve/develop.html>Programmer's Source

  DBMS Sites <http://info.itu.ch/special/wwwfiles> Go here and see file
  comp_db.html

  <http://www.compapp.dcu.ie/databases/f017.html>DB Ingredients

  <http://www.stars.com/Tutorial/CGI/>Web Authoring

  <http://wfn-shop.princeton.edu/cgi-bin/foldoc>Computing Dictionary

  <http://www-ccs.cs.umass.edu/db.html>DBMS Lab/Links

  SQL FAQ <http://epoch.CS.Berkeley.EDU:8000/sequoia/dba/montage/FAQ> Go
  here and see file SQL_TOC.html

  <http://chaos.mur.csu.edu.au/itc125/cgi/sqldb.html>SQL Databases

  <http://www.it.rit.edu/~wjs/IT/199602/icsa720/icsa720postings.html>RIT
  Database Design Page

  <http://www.pcslink.com/~ej/dbweb.html>Database Jump Site

  <http://www.eng.uc.edu/~jtilley/tutorial.html>Programming Tutorials on
  the Web

  <http://www.ndev.com/ndc2/support/resources.htp>Development Resources

  <http://ashok.pair.com/sql.htm>Query List

  <http://jazz.external.hp.com/training/sqltables/main.html>IMAGE SQL
  Miscellaneous

  <http://www.eit.com/web/netservices.html>Internet Resource List

  Below is the extract from the home page of SQL tutorial.

  Introduction to Structured Query Language

  Version 3.31

  This page is a tutorial of the Structured Query Language (also known as SQL)
  and is a pioneering effort on the World Wide Web, as this is the first
  comprehensive SQL tutorial available on the Internet. SQL allows users to
  access data in relational database management systems, such as Oracle,
  Sybase, Informix, Microsoft SQL Server, Access, and others, by allowing
  users to describe the data the user wishes to see. SQL also allows users to
  define the data in a database, and manipulate that data. This page will
  describe how to use SQL, and give examples. The SQL used in this document is
  "ANSI", or standard SQL, and no SQL features of specific database management
  systems will be discussed until the "Nonstandard SQL" section. It is
  recommended that you print this page, so that you can easily refer back to
  previous examples.
  ----------------------------------------------------------------------------
  Table of Contents

       Basics of the SELECT Statement
       Conditional Selection
       Relational Operators
       Compound Conditions
       IN & BETWEEN
       Using LIKE

       Joins
       Keys
       Performing a Join
       Eliminating Duplicates
       Aliases & In/Subqueries

       Aggregate Functions
       Views
       Creating New Tables
       Altering Tables
       Adding Data
       Deleting Data
       Updating Data

       Indexes
       GROUP BY & HAVING
       More Subqueries
       EXISTS & ALL
       UNION & Outer Joins
       Embedded SQL
       Common SQL Questions
       Nonstandard SQL
       Syntax Summary
       Important Links

  ----------------------------------------------------------------------------
  Basics of the SELECT Statement

  In a relational database, data is stored in tables. An example table would
  relate Social Security Number, Name, and Address:

                          EmployeeAddressTable

   SSN      FirstName LastName  Address         City        State
   512687458Joe       Smith     83 First Street Howard      Ohio
   758420012Mary      Scott     842 Vine Ave.   LosantivilleOhio
   102254896Sam       Jones     33 Elm St.      Paris       New York
   876512563Sarah     Ackerman  440 U.S. 110    Upton       Michigan

  Now, let's say you want to see the address of each employee. Use the SELECT
  statement, like so:

  SELECT FirstName, LastName, Address, City, State
  FROM EmployeeAddressTable;

  The following is the results of your query of the database:

   First NameLast Name  Address          City         State
   Joe       Smith      83 First Street  Howard       Ohio
   Mary      Scott      842 Vine Ave.    Losantiville Ohio
   Sam       Jones      33 Elm St.       Paris        New York
   Sarah     Ackerman   440 U.S. 110     Upton        Michigan

  To explain what you just did, you asked for the all of data in the
  EmployeeAddressTable, and specifically, you asked for the columns called
  FirstName, LastName, Address, City, and State. Note that column names and
  table names do not have spaces...they must be typed as one word; and that
  the statement ends with a semicolon (;). The general form for a SELECT
  statement, retrieving all of the rows in the table is:

  SELECT ColumnName, ColumnName, ...
  FROM TableName;

  To get all columns of a table without typing all column names, use:

  SELECT * FROM TableName;

  Each database management system (DBMS) and database software has different
  methods for logging in to the database and entering SQL commands; see the
  local computer "guru" to help you get onto the system, so that you can use
  SQL.
  ----------------------------------------------------------------------------
  Conditional Selection

  To further discuss the SELECT statement, let's look at a new example table
  (for hypothetical purposes only):

                        EmployeeStatisticsTable

   EmployeeIDNo      Salary           Benefits         Position
   010               75000            15000            Manager
   105               65000            15000            Manager
   152               60000            15000            Manager
   215               60000            12500            Manager
   244               50000            12000            Staff
   300               45000            10000            Staff
   335               40000            10000            Staff
   400               32000            7500             Entry-Level
   441               28000            7500             Entry-Level

  ----------------------------------------------------------------------------
  Relational Operators

  There are six Relational Operators in SQL, and after introducing them, we'll
  see how they're used:

   =            Equal
   <> or !=
   (see manual) Not Equal
   <            Less Than
   >            Greater Than
   <=           Less Than or Equal To

   >=           Greater Than or Equal
                To

  The WHERE clause is used to specify that only certain rows of the table are
  displayed, based on the criteria described in that WHERE clause. It is most
  easily understood by looking at a couple of examples.

  If you wanted to see the EMPLOYEEIDNO's of those making at or over 50,000,
  use the following:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE SALARY >= 50000;

  Notice that the >= (greater than or equal to) sign is used, as we wanted to
  see those who made greater than 50,000, or equal to 50,000, listed
  together. This displays:

  EMPLOYEEIDNO
  ------------
  010
  105
  152
  215
  244

  The WHERE description, SALARY >= 50000, is known as a condition. The same
  can be done for text columns:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE POSITION = 'Manager';

  This displays the ID Numbers of all Managers. Generally, with text columns,
  stick to equal to or not equal to, and make sure that any text that appears
  in the statement is surrounded by single quotes (').

  ----------------------------------------------------------------------------
  More Complex Conditions: Compound Conditions

  The AND operator joins two or more conditions, and displays a row only if
  that row's data satisfies ALL conditions listed (i.e. all conditions hold
  true). For example, to display all staff making over 40,000, use:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE SALARY > 40000 AND POSITION = 'Staff';

  The OR operator joins two or more conditions, but returns a row if ANY of
  the conditions listed hold true. To see all those who make less than 40,000
  or have less than 10,000 in benefits, listed together, use the following
  query:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE SALARY < 40000 OR BENEFITS < 10000;

  AND & OR can be combined, for example:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE POSITION = 'Manager' AND SALARY > 60000 OR BENEFITS > 12000;

  First, SQL finds the rows where the salary is greater than 60,000 and the
  position column is equal to Manager, then taking this new list of rows, SQL
  then sees if any of these rows satisfies the previous AND condition or the
  condition that the Benefits column is greater then 12,000. Subsequently,
  SQL only displays this second new list of rows, keeping in mind that anyone
  with Benefits over 12,000 will be included as the OR operator includes a
  row if either resulting condition is True. Also note that the AND operation
  is done first.

  To generalize this process, SQL performs the AND operation(s) to determine
  the rows where the AND operation(s) hold true (remember: all of the
  conditions are true), then these results are used to compare with the
  OR conditions, and only display those remaining rows where the conditions
  joined by the OR operator hold true.

  To perform OR's before AND's, like if you wanted to see a list of employees
  making a large salary (>50,000) or have a large benefit package (>10,000),
  and that happen to be a manager, use parentheses:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE POSITION = 'Manager' AND (SALARY > 50000 OR BENEFIT > 10000);

  ----------------------------------------------------------------------------
  IN & BETWEEN

  An easier method of using compound conditions uses IN or BETWEEN. For
  example, if you wanted to list all managers and staff:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE POSITION IN ('Manager', 'Staff');

  or to list those making greater than or equal to 30,000, but less than or
  equal to 50,000, use:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE SALARY BETWEEN 30000 AND 50000;

  To list everyone not in this range, try:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEESTATISTICSTABLE
  WHERE SALARY NOT BETWEEN 30000 AND 50000;

  Similarly, NOT IN lists all rows excluded from the IN list.

  ----------------------------------------------------------------------------
  Using LIKE

  Look at the EmployeeStatisticsTable, and say you wanted to see all people
  whose last names started with "L"; try:

  SELECT EMPLOYEEIDNO
  FROM EMPLOYEEADDRESSTABLE
  WHERE LASTNAME LIKE 'L%';

  The percent sign (%) is used to represent any possible character (number,
  letter, or punctuation) or set of characters that might appear after the
  "L". To find those people with LastName's ending in "L", use '%L', or if you
  wanted the "L" in the middle of the word, try '%L%'. The '%' can be used for
  any characters, in that relative position to the given characters. NOT LIKE
  displays rows not fitting the given description. Other possiblities of using
  LIKE, or any of these discussed conditionals, are available, though it
  depends on what DBMS you are using; as usual, consult a manual or your
  system manager or administrator for the available features on your system,
  or just to make sure that what you are trying to do is available and
  allowed. This disclaimer holds for the features of SQL that will be
  discussed below. This section is just to give you an idea of the
  possibilities of queries that can be written in SQL.
  ----------------------------------------------------------------------------
  Joins

  In this section, we will only discuss inner joins, and equijoins, as in
  general, they are the most useful. For more information, try the SQL links
  at the bottom of the page.

  Good database design suggests that each table lists data only about a single
  entity, and detailed information can be obtained in a relational database,
  by using additional tables, and by using a join.

  First, take a look at these example tables:

              AntiqueOwners

   OwnerIDOwnerLastName OwnerFirstName
   01     Jones         Bill
   02     Smith         Bob
   15     Lawson        Patricia
   21     Akins         Jane
   50     Fowler        Sam

  ---------------------------------------------------------

         Orders

   OwnerIDItemDesired
   02     Table
   02     Desk
   21     Chair
   15     Mirror

  --------------------------------------

             Antiques

   SellerIDBuyerID Item
   01      50      Bed
   02      15      Table
   15      02      Chair
   21      50      Mirror
   50      01      Desk
   01      21      Cabinet
   02      21      Coffee Table
   15      50      Chair
   01      15      Jewelry Box
   02      21      Pottery
   21      02      Bookcase
   50      01      Plant Stand

  ----------------------------------------------------------------------------
  Keys

  First, let's discuss the concept of keys. A primary key is a column or set
  of columns that uniquely identifies the rest of the data in any given row.
  For example, in the AntiqueOwners table, the OwnerID column uniquely
  identifies that row. This means two things: no two rows can have the same
  OwnerID, and, even if two owners have the same first and last names, the
  OwnerID column ensures that the two owners will not be confused with each
  other, because the unique OwnerID column will be used throughout the
  database to track the owners, rather than the names.

  A foreign key is a column in a table where that column is a primary key of
  another table, which means that any data in a foreign key column must have
  corresponding data in the other table where that column is the primary key.
  In DBMS-speak, this correspondence is known as referential integrity. For
  example, in the Antiques table, both the BuyerID and SellerID are foreign
  keys to the primary key of the AntiqueOwners table (OwnerID; for purposes of
  argument, one has to be an Antique Owner before one can buy or sell any
  items), as, in both tables, the ID rows are used to identify the owners or
  buyers and sellers, and that the OwnerID is the primary key of the
  AntiqueOwners table. In other words, all of this "ID" data is used to refer
  to the owners, buyers, or sellers of antiques, themselves, without having to
  use the actual names.

  ----------------------------------------------------------------------------
  Performing a Join

  The purpose of these keys is so that data can be related across tables,
  without having to repeat data in every table--this is the power of
  relational databases. For example, you can find the names of those who
  bought a chair without having to list the full name of the buyer in the
  Antiques table...you can get the name by relating those who bought a chair
  with the names in the AntiqueOwners table through the use of the OwnerID,
  which relates the data in the two tables. To find the names of those who
  bought a chair, use the following query:

  SELECT OWNERLASTNAME, OWNERFIRSTNAME
  FROM ANTIQUEOWNERS, ANTIQUES
  WHERE BUYERID = OWNERID AND ITEM = 'Chair';

  Note the following about this query...notice that both tables involved in
  the relation are listed in the FROM clause of the statement. In the WHERE
  clause, first notice that the ITEM = 'Chair' part restricts the listing to
  those who have bought (and in this example, thereby owns) a chair. Secondly,
  notice how the ID columns are related from one table to the next by use of
  the BUYERID = OWNERID clause. Only where ID's match across tables and the
  item purchased is a chair (because of the AND), will the names from the
  AntiqueOwners table be listed. Because the joining condition used an equal
  sign, this join is called an equijoin. The result of this query is two
  names: Smith, Bob & Fowler, Sam.

  Dot notation refers to prefixing the table names to column names, to avoid
  ambiguity, as such:

  SELECT ANTIQUEOWNERS.OWNERLASTNAME, ANTIQUEOWNERS.OWNERFIRSTNAME
  FROM ANTIQUEOWNERS, ANTIQUES
  WHERE ANTIQUES.BUYERID = ANTIQUEOWNERS.OWNERID AND ANTIQUES.ITEM = 'Chair';

  As the column names are different in each table, however, this wasn't
  necessary.

  ----------------------------------------------------------------------------
  DISTINCT and Eliminating Duplicates

  Let's say that you want to list the ID and names of only those people who
  have sold an antique. Obviously, you want a list where each seller is only
  listed once--you don't want to know how many antiques a person sold, just
  the fact that this person sold one (for counts, see the Aggregate Function
  section below). This means that you will need to tell SQL to eliminate
  duplicate sales rows, and just list each person only once. To do this, use
  the DISTINCT keyword.

  First, we will need an equijoin to the AntiqueOwners table to get the detail
  data of the person's LastName and FirstName. However, keep in mind that
  since the SellerID column in the Antiques table is a foreign key to the
  AntiqueOwners table, a seller will only be listed if there is a row in the
  AntiqueOwners table listing the ID and names. We also want to eliminate
  multiple occurences of the SellerID in our listing, so we use DISTINCT on
  the column where the repeats may occur.

  To throw in one more twist, we will also want the list alphabetized by
  LastName, then by FirstName (on a LastName tie), then by OwnerID (on a
  LastName and FirstName tie). Thus, we will use the ORDER BY clause:

  SELECT DISTINCT SELLERID, OWNERLASTNAME, OWNERFIRSTNAME
  FROM ANTIQUES, ANTIQUEOWNERS
  WHERE SELLERID = OWNERID
  ORDER BY OWNERLASTNAME, OWNERFIRSTNAME, OWNERID;

  In this example, since everyone has sold an item, we will get a listing of
  all of the owners, in alphabetical order by last name. For future reference
  (and in case anyone asks), this type of join is considered to be in the
  category of inner joins.

  ----------------------------------------------------------------------------
  Aliases & In/Subqueries

  In this section, we will talk about Aliases, In and the use of subqueries,
  and how these can be used in a 3-table example. First, look at this query
  which prints the last name of those owners who have placed an order and what
  the order is, only listing those orders which can be filled (that is, there
  is a buyer who owns that ordered item):

  SELECT OWN.OWNERLASTNAME Last Name, ORD.ITEMDESIRED Item Ordered
  FROM ORDERS ORD, ANTIQUEOWNERS OWN
  WHERE ORD.OWNERID = OWN.OWNERID
  AND ORD.ITEMDESIRED IN

       (SELECT ITEM
       FROM ANTIQUES);

  This gives:

  Last Name Item Ordered
  --------- ------------
  Smith     Table
  Smith     Desk
  Akins     Chair
  Lawson    Mirror

  There are several things to note about this query:

    1. First, the "Last Name" and "Item Ordered" in the Select lines gives the
       headers on the report.
    2. The OWN & ORD are aliases; these are new names for the two tables
       listed in the FROM clause that are used as prefixes for all dot
       notations of column names in the query (see above). This eliminates
       ambiguity, especially in the equijoin WHERE clause where both tables
       have the column named OwnerID, and the dot notation tells SQL that we
       are talking about two different OwnerID's from the two different
       tables.
    3. Note that the Orders table is listed first in the FROM clause; this
       makes sure listing is done off of that table, and the AntiqueOwners
       table is only used for the detail information (Last Name).
    4. Most importantly, the AND in the WHERE clause forces the In Subquery to
       be invoked ("= ANY" or "= SOME" are two equivalent uses of IN). What
       this does is, the subquery is performed, returning all of the Items
       owned from the Antiques table, as there is no WHERE clause. Then, for a
       row from the Orders table to be listed, the ItemDesired must be in that
       returned list of Items owned from the Antiques table, thus listing an
       item only if the order can be filled from another owner. You can think
       of it this way: the subquery returns a set of Items from which each
       ItemDesired in the Orders table is compared; the In condition is true
       only if the ItemDesired is in that returned set from the Antiques
       table.
    5. Also notice, that in this case, that there happened to be an antique
       available for each one desired...obviously, that won't always be the
       case. In addition, notice that when the IN, "= ANY", or "= SOME" is
       used, that these keywords refer to any possible row matches, not column
       matches...that is, you cannot put multiple columns in the subquery
       Select clause, in an attempt to match the column in the outer Where
       clause to one of multiple possible column values in the subquery; only
       one column can be listed in the subquery, and the possible match comes
       from multiple row values in that one column, not vice-versa.

  Whew! That's enough on the topic of complex SELECT queries for now. Now on
  to other SQL statements.
  ----------------------------------------------------------------------------
  Miscellaneous SQL Statements

  Aggregate Functions

  I will discuss five important aggregate functions: SUM, AVG, MAX, MIN, and
  COUNT. They are called aggregate functions because they summarize the
  results of a query, rather than listing all of the rows.

     * SUM () gives the total of all the rows, satisfying any conditions, of
       the given column, where the given column is numeric.
     * AVG () gives the average of the given column.
     * MAX () gives the largest figure in the given column.
     * MIN () gives the smallest figure in the given column.
     * COUNT(*) gives the number of rows satisfying the conditions.

  Looking at the tables at the top of the document, let's look at three
  examples:

  SELECT SUM(SALARY), AVG(SALARY)
  FROM EMPLOYEESTATISTICSTABLE;

  This query shows the total of all salaries in the table, and the average
  salary of all of the entries in the table.

  SELECT MIN(BENEFITS)
  FROM EMPLOYEESTATISTICSTABLE
  WHERE POSITION = 'Manager';

  This query gives the smallest figure of the Benefits column, of the
  employees who are Managers, which is 12500.

  SELECT COUNT(*)
  FROM EMPLOYEESTATISTICSTABLE
  WHERE POSITION = 'Staff';

  This query tells you how many employees have Staff status (3).

  ----------------------------------------------------------------------------
  Views

  In SQL, you might (check your DBA) have access to create views for yourself.
  What a view does is to allow you to assign the results of a query to a new,
  personal table, that you can use in other queries, where this new table is
  given the view name in your FROM clause. When you access a view, the query
  that is defined in your view creation statement is performed (generally),
  and the results of that query look just like another table in the query that
  you wrote invoking the view. For example, to create a view:

  CREATE VIEW ANTVIEW AS SELECT ITEMDESIRED FROM ORDERS;

  Now, write a query using this view as a table, where the table is just a
  listing of all Items Desired from the Orders table:

  SELECT SELLERID
  FROM ANTIQUES, ANTVIEW
  WHERE ITEMDESIRED = ITEM;
  This query shows all SellerID's from the Antiques table where the Item in
  that table happens to appear in the Antview view, which is just all of the
  Items Desired in the Orders table. The listing is generated by going through
  the Antique Items one-by-one until there's a match with the Antview view.
  Views can be used to restrict database access, as well as, in this case,
  simplify a complex query.

  ----------------------------------------------------------------------------
  Creating New Tables

  All tables within a database must be created at some point in time...let's
  see how we would create the Orders table:

  CREATE TABLE ORDERS
  (OWNERID INTEGER NOT NULL,
  ITEMDESIRED CHAR(40) NOT NULL);

  This statement gives the table name and tells the DBMS about each column in
  the table. Please note that this statement uses generic data types, and that
  the data types might be different, depending on what DBMS you are using. As
  usual, check local listings. Some common generic data types are:

     * Char(x) - A column of characters, where x is a number designating the
       maximum number of characters allowed (maximum length) in the column.
     * Integer - A column of whole numbers, positive or negative.
     * Decimal(x, y) - A column of decimal numbers, where x is the maximum
       length in digits of the decimal numbers in this column, and y is the
       maximum number of digits allowed after the decimal point. The maximum
       (4,2) number would be 99.99.
     * Date - A date column in a DBMS-specific format.
     * Logical - A column that can hold only two values: TRUE or FALSE.

  One other note, the NOT NULL means that the column must have a value in each
  row. If NULL was used, that column may be left empty in a given row.

  ----------------------------------------------------------------------------
  Altering Tables

  Let's add a column to the Antiques table to allow the entry of the price of
  a given Item:

  ALTER TABLE ANTIQUES ADD (PRICE DECIMAL(8,2) NULL);

  The data for this new column can be updated or inserted as shown later.

  ----------------------------------------------------------------------------
  Adding Data

  To insert rows into a table, do the following:

  INSERT INTO ANTIQUES VALUES (21, 01, 'Ottoman', 200.00);

  This inserts the data into the table, as a new row, column-by-column, in the
  pre-defined order. Instead, let's change the order and leave Price blank:

  INSERT INTO ANTIQUES (BUYERID, SELLERID, ITEM)
  VALUES (01, 21, 'Ottoman');

  ----------------------------------------------------------------------------
  Deleting Data

  Let's delete this new row back out of the database:

  DELETE FROM ANTIQUES
  WHERE ITEM = 'Ottoman';

  But if there is another row that contains 'Ottoman', that row will be
  deleted also. Let's delete all rows (one, in this case) that contain the
  specific data we added before:

  DELETE FROM ANTIQUES
  WHERE ITEM = 'Ottoman' AND BUYERID = 01 AND SELLERID = 21;

  ----------------------------------------------------------------------------
  Updating Data

  Let's update a Price into a row that doesn't have a price listed yet:

  UPDATE ANTIQUES SET PRICE = 500.00 WHERE ITEM = 'Chair';

  This sets all Chair's Prices to 500.00. As shown above, more WHERE
  conditionals, using AND, must be used to limit the updating to more specific
  rows. Also, additional columns may be set by separating equal statements
  with commas.

  ----------------------------------------------------------------------------
  Miscellaneous Topics

  Indexes

  Indexes allow a DBMS to access data quicker (please note: this feature is
  nonstandard/not available on all systems). The system creates this internal
  data structure (the index) which causes selection of rows, when the
  selection is based on indexed columns, to occur faster. This index tells the
  DBMS where a certain row is in the table given an indexed-column value, much
  like a book index tells you what page a given word appears. Let's create an
  index for the OwnerID in the AntiqueOwners column:

  CREATE INDEX OID_IDX ON ANTIQUEOWNERS (OWNERID);

  Now on the names:

  CREATE INDEX NAME_IDX ON ANTIQUEOWNERS (OWNERLASTNAME, OWNERFIRSTNAME);

  To get rid of an index, drop it:

  DROP INDEX OID_IDX;

  By the way, you can also "drop" a table, as well (careful!--that means that
  your table is deleted). In the second example, the index is kept on the two
  columns, aggregated together--strange behavior might occur in this
  situation...check the manual before performing such an operation.

  Some DBMS's do not enforce primary keys; in other words, the uniqueness of a
  column is not enforced automatically. What that means is, if, for example, I
  tried to insert another row into the AntiqueOwners table with an OwnerID of
  02, some systems will allow me to do that, even though, we do not, as that
  column is supposed to be unique to that table (every row value is supposed
  to be different). One way to get around that is to create a unique index on
  the column that we want to be a primary key, to force the system to enforce
  prohibition of duplicates:

  CREATE UNIQUE INDEX OID_IDX ON ANTIQUEOWNERS (OWNERID);

  ----------------------------------------------------------------------------
  GROUP BY & HAVING

  One special use of GROUP BY is to associate an aggregate function
  (especially COUNT; counting the number of rows in each group) with groups of
  rows. First, assume that the Antiques table has the Price column, and each
  row has a value for that column. We want to see the price of the most
  expensive item bought by each owner. We have to tell SQL to group each
  owner's purchases, and tell us the maximum purchase price:

  SELECT BUYERID, MAX(PRICE)
  FROM ANTIQUES
  GROUP BY BUYERID;

  Now, say we only want to see the maximum purchase price if the purchase is
  over 1000, so we use the HAVING clause:

  SELECT BUYERID, MAX(PRICE)
  FROM ANTIQUES
  GROUP BY BUYERID
  HAVING PRICE > 1000;

  ----------------------------------------------------------------------------
  More Subqueries

  Another common usage of subqueries involves the use of operators to allow a
  Where condition to include the Select output of a subquery. First, list the
  buyers who purchased an expensive item (the Price of the item is 100
  greater than the average price of all items purchased):

  SELECT OWNERID
  FROM ANTIQUES
  WHERE PRICE >

       (SELECT AVG(PRICE) + 100
       FROM ANTIQUES);

  The subquery calculates the average Price, plus 100, and using that figure,
  an OwnerID is printed for every item costing over that figure. One could use
  DISTINCT OWNERID, to eliminate duplicates.

  List the Last Names of those in the AntiqueOwners table, ONLY if they have
  bought an item:

  SELECT OWNERLASTNAME
  FROM ANTIQUEOWNERS
  WHERE OWNERID =

       (SELECT DISTINCT BUYERID
       FROM ANTIQUES);

  The subquery returns a list of buyers, and the Last Name is printed for an
  Antique Owner if and only if the Owner's ID appears in the subquery list
  (sometimes called a candidate list).

  For an Update example, we know that the gentleman who bought the bookcase
  has the wrong First Name in the database...it should be John:

  UPDATE ANTIQUEOWNERS
  SET OWNERFIRSTNAME = 'John'
  WHERE OWNERID =

       (SELECT BUYERID
       FROM ANTIQUES
       WHERE ITEM = 'Bookcase');

  First, the subquery finds the BuyerID for the person(s) who bought the
  Bookcase, then the outer query updates his First Name.

  Remember this rule about subqueries: when you have a subquery as part of a
  WHERE condition, the Select clause in the subquery must have columns that
  match in number and type to those in the Where clause of the outer query. In
  other words, if you have "WHERE ColumnName = (SELECT...);", the Select must
  have only one column in it, to match the ColumnName in the outer Where
  clause, and they must match in type (both being integers, both being
  character strings, etc.).

  ----------------------------------------------------------------------------
  EXISTS & ALL

  EXISTS uses a subquery as a condition, where the condition is True if the
  subquery returns any rows, and False if the subquery does not return any
  rows; this is a nonintuitive feature with few unique uses. However, if a
  prospective customer wanted to see the list of Owners only if the shop dealt
  in Chairs, try:

  SELECT OWNERFIRSTNAME, OWNERLASTNAME
  FROM ANTIQUEOWNERS
  WHERE EXISTS

       (SELECT *
       FROM ANTIQUES
       WHERE ITEM = 'Chair');

  If there are any Chairs in the Antiques column, the subquery would return a
  row or rows, making the EXISTS clause true, causing SQL to list the Antique
  Owners. If there had been no Chairs, no rows would have been returned by the
  outside query.

  ALL is another unusual feature, as ALL queries can usually be done with
  different, and possibly simpler methods; let's take a look at an example
  query:

  SELECT BUYERID, ITEM
  FROM ANTIQUES
  WHERE PRICE >= ALL

       (SELECT PRICE
       FROM ANTIQUES);

  This will return the largest priced item (or more than one item if there is
  a tie), and its buyer. The subquery returns a list of all Prices in the
  Antiques table, and the outer query goes through each row of the Antiques
  table, and if its Price is greater than or equal to every (or ALL) Prices in
  the list, it is listed, giving the highest priced Item. The reason ">=" must
  be used is that the highest priced item will be equal to the highest price
  on the list, because this Item is in the Price list.

  ----------------------------------------------------------------------------
  UNION & Outer Joins

  There are occasions where you might want to see the results of multiple
  queries together, combining their output; use UNION. To merge the output of
  the following two queries, displaying the ID's of all Buyers, plus all those
  who have an Order placed:

  SELECT BUYERID
  FROM ANTIQUEOWNERS
  UNION
  SELECT OWNERID
  FROM ORDERS;

  Notice that SQL requires that the Select list (of columns) must match,
  column-by-column, in data type. In this case BuyerID and OwnerID are of the
  same data type (integer). Also notice that SQL does automatic duplicate
  elimination when using UNION (as if they were two "sets"); in single
  queries, you have to use DISTINCT.

  The outer join is used when a join query is "united" with the rows not
  included in the join, and are especially useful if constant text "flags" are
  included. First, look at the query:

  SELECT OWNERID, 'is in both Orders & Antiques'
  FROM ORDERS, ANTIQUES
  WHERE OWNERID = BUYERID
  UNION
  SELECT BUYERID, 'is in Antiques only'
  FROM ANTIQUES
  WHERE BUYERID NOT IN

       (SELECT OWNERID
       FROM ORDERS);

  The first query does a join to list any owners who are in both tables, and
  putting a tag line after the ID repeating the quote. The UNION merges this
  list with the next list. The second list is generated by first listing those
  ID's not in the Orders table, thus generating a list of ID's excluded from
  the join query. Then, each row in the Antiques table is scanned, and if the
  BuyerID is not in this exclusion list, it is listed with its quoted tag.
  There might be an easier way to make this list, but it's difficult to
  generate the informational quoted strings of text.

  This concept is useful in situations where a primary key is related to a
  foreign key, but the foreign key value for some primary keys is NULL. For
  example, in one table, the primary key is a salesperson, and in another
  table is customers, with their salesperson listed in the same row. However,
  if a salesperson has no customers, that person's name won't appear in the
  customer table. The outer join is used if the listing of all sales person is
  to be printed, listed with their customers, whether the salesperson has a
  customer or not--that is, no customer is printed (a logical NULL value) if
  the salesperson has no customers, but is in the sales person table.
  Otherwise, the salesperson will be listed with each customer.

  ENOUGH QUERIES!!! you say?...now on to something completely different...

  ----------------------------------------------------------------------------
  Embedded SQL--an ugly example (do not write a program like this...for
  purposes of argument ONLY)

  /* -To get right to it, here is an example program that uses Embedded
      SQL. Embedded SQL allows programmers to connect to a database and
      include SQL code right in the program, so that their programs can
      use, manipulate, and process data from a database.
     -This example C Program (using Embedded SQL) will print a report.
     -This program will have to be precompiled for the SQL statements,
      before regular compilation.
     -The EXEC SQL parts are the same (standard), but the surrounding C
      code will need to be changed, including the host variable
      declarations, if you are using a different language.
     -Embedded SQL changes from system to system, so, once again, check
      local documentation, especially variable declarations and logging
      in procedures, in which network, DBMS, and operating system
      considerations are crucial. */

  /************************************************/
  /* THIS PROGRAM IS NOT COMPILABLE OR EXECUTABLE */
  /* IT IS FOR EXAMPLE PURPOSES ONLY              */
  /************************************************/

  #include <stdio.h>

  /* This section declares the host variables; these will be the
     variables your program uses, but also the variable SQL will put
     values in or take values out. */
  EXEC SQL BEGIN DECLARE SECTION;
    int BuyerID;
    char FirstName[100], LastName[100], Item[100];
  EXEC SQL END DECLARE SECTION;

  /* This includes the SQLCA variable, so that some error checking can be
  done. */
  EXEC SQL INCLUDE SQLCA;

  main() (

  /* This is a possible way to log into the database */
  EXEC SQL CONNECT UserID/Password;

  /* This code either says that you are connected or checks if an error
     code was generated, meaning log in was incorrect or not possible. */
    if(sqlca.sqlcode) (
      printf(Printer, "Error connecting to database server.\n");
      exit();
    )
    printf("Connected to database server.\n");

  /* This declares a "Cursor". This is used when a query returns more
     than one row, and an operation is to be performed on each row
     resulting from the query. With each row established by this query,
     I'm going to use it in the report. Later, "Fetch" will be used to
     pick off each row, one at a time, but for the query to actually
     be executed, the "Open" statement is used. The "Declare" just
     establishes the query. */
  EXEC SQL DECLARE ItemCursor CURSOR FOR
    SELECT ITEM, BUYERID
    FROM ANTIQUES
    ORDER BY ITEM;
  EXEC SQL OPEN ItemCursor;

  /* +-- You may wish to put a similar error checking block here --+ */

  /* Fetch puts the values of the "next" row of the query in the host
     variables, respectively. However, a "priming fetch" (programming
     technique) must first be done. When the cursor is out of data, a
     sqlcode will be generated allowing us to leave the loop. Notice
     that, for simplicity's sake, the loop will leave on any sqlcode,
     even if it is an error code. Otherwise, specific code checking must
     be performed. */
  EXEC SQL FETCH ItemCursor INTO :Item, :BuyerID;
    while(!sqlca.sqlcode) (

  /* With each row, we will also do a couple of things. First, bump the
     price up by 5 (dealer's fee) and get the buyer's name to put in
     the report. To do this, I'll use an Update and a Select, before
     printing the line on the screen. The update assumes however, that
     a given buyer has only bought one of any given item, or else the
     price will be increased too many times. Otherwise, a "RowID" logic
     would have to be used (see documentation). Also notice the colon
     before host variable names when used inside of SQL statements. */

  EXEC SQL UPDATE ANTIQUES
    SET PRICE = PRICE + 5
    WHERE ITEM = :Item AND BUYERID = :BuyerID;

  EXEC SQL SELECT OWNERFIRSTNAME, OWNERLASTNAME
    INTO :FirstName, :LastName
    FROM ANTIQUEOWNERS
    WHERE BUYERID = :BuyerID;

      printf("%25s %25s %25s", FirstName, LastName, Item);

  /* Ugly report--for example purposes only! Get the next row. */
  EXEC SQL FETCH ItemCursor INTO :Item, :BuyerID;
    )

  /* Close the cursor, commit the changes (see below), and exit the
     program. */
  EXEC SQL CLOSE DataCursor;
  EXEC SQL COMMIT RELEASE;
    exit();
  )

  ----------------------------------------------------------------------------
  Common SQL Questions--Advanced Topics (see FAQ link for several more)

    1. Why can't I just ask for the first three rows in a table? --Because in
       relational databases, rows are inserted in no particular order, that
       is, the system inserts them in an arbitrary order; so, you can only
       request rows using valid SQL features, like ORDER BY, etc.
    2. What is this DDL and DML I hear about? --DDL (Data Definition Language)
       refers to (in SQL) the Create Table statement...DML (Data Manipulation
       Language) refers to the Select, Update, Insert, and Delete statements.
    3. Aren't database tables just files? --Well, DBMS's store data in files
       declared by system managers before new tables are created (on large
       systems), but the system stores the data in a special format, and may
       spread data from one table over several files. In the database world, a
       set of files created for a database is called a tablespace. In general,
       on small systems, everything about a database (definitions and all
       table data) is kept in one file.
    4. (Related question) Aren't database tables just like spreadsheets? --No,
       for two reasons. First, spreadsheets can have data in a cell, but a
       cell is more than just a row-column-intersection. Depending on your
       spreadsheet software, a cell might also contain formulas and
       formatting, which database tables cannot have (currently). Secondly,
       spreadsheet cells are often dependent on the data in other cells. In
       databases, "cells" are independent, except that columns are logically
       related (hopefully; together a row of columns describe an entity), and,
       other than primary key and foreign key constraints, each row in a table
       in independent from one another.
    5. How do I import a text file of data into a database? --Well, you can't
       do it directly...you must use a utility, such as Oracle's SQL*Loader,
       or write a program to load the data into the database. A program to do
       this would simply go through each record of a text file, break it up
       into columns, and do an Insert into the database.
    6. What is a schema? --A schema is a logical set of tables, such as the
       Antiques database above...usually, it is thought of as simply "the
       database", but a database can hold more than one schema. For example, a
       star schema is a set of tables where one large, central table holds all
       of the important information, and is linked, via foreign keys, to
       dimension tables which hold detail information, and can be used in a
       join to create detailed reports.
    7. What are some general tips you would give to make my SQL queries and
       databases better and faster (optimized)?
          o You should try, if you can, to avoid expressions in Selects, such
            as SELECT ColumnA + ColumnB, etc. The query optimizer of the
            database, the portion of the DBMS that determines the best way to
            get the required data out of the database itself, handles
            expressions in such a way that would normally require more time to
            retrieve the data than if columns were normally selected, and the
            expression itself handled programmatically.
          o Minimize the number of columns included in a Group By clause.
          o If you are using a join, try to have the columns joined on (from
            both tables) indexed.
          o When in doubt, index.
          o Unless doing multiple counts or a complex query, use COUNT(*) (the
            number of rows generated by the query) rather than
            COUNT(Column_Name).
    8. What is normalization? --Normalization is a technique of database
       design that suggests that certain criteria be used when constructing a
       table layout (deciding what columns each table will have, and creating
       the key structure), where the idea is to eliminate redundancy of
       non-key data across tables. Normalization is usually referred to in
       terms of forms, and I will introduce only the first three, even though
       it is somewhat common to use other, more advanced forms (fourth, fifth,
       Boyce-Codd; see documentation).

       First Normal Form refers to moving data into separate tables where the
       data in each table is of a similar type, and by giving each table a
       primary key.

       Putting data in Second Normal Form involves taking out data off to
       other tables that is only dependent of a part of the key. For example,
       if I had left the names of the Antique Owners in the items table, that
       would not be in second normal form because that data would be
       redundant; the name would be repeated for each item owned, so the names
       were placed in their own table. The names themselves don't have
       anything to do with the items, only the identities of the buyers and
       sellers.

       Third Normal Form involves getting rid of anything in the tables that
       doesn't depend solely on the primary key. Only include information that
       is dependent on the key, and move off data to other tables that are
       independent of the primary key, and create a primary keys for the new
       tables.

       There is some redundancy to each form, and if data is in 3NF (shorthand
       for 3rd normal form), it is already in 1NF and 2NF. In terms of data
       design then, arrange data so that any non-primary key columns are
       dependent only on the whole primary key. If you take a look at the
       sample database, you will see that the way then to navigate through the
       database is through joins using common key columns.

       Two other important points in database design are using good,
       consistent, logical, full-word names for the tables and columns, and
       the use of full words in the database itself. On the last point, my
       database is lacking, as I use numeric codes for identification. It is
       usually best, if possible, to come up with keys that are, by
       themselves, self-explanatory; for example, a better key would be the
       first four letters of the last name and first initial of the owner,
       like JONEB for Bill Jones (or for tiebreaking purposes, add numbers to
       the end to differentiate two or more people with similar names, so you
       could try JONEB1, JONEB2, etc.).
    9. What is the difference between a single-row query and a multiple-row
       query and why is it important to know the difference? --First, to cover
       the obvious, a single-row query is a query that returns one row as its
       result, and a multiple-row query is a query that returns more than one
       row as its result. Whether a query returns one row or more than one row
       is entirely dependent on the design (or schema) of the tables of the
       database. As query-writer, you must be aware of the schema, be sure to
       include enough conditions, and structure your SQL statement properly,
       so that you will get the desired result (either one row or multiple
       rows). For example, if you wanted to be sure that a query of the
       AntiqueOwners table returned only one row, consider an equal condition
       of the primary key-column, OwnerID.

       Three reasons immediately come to mind as to why this is important.
       First, getting multiple rows when you were expecting only one, or
       vice-versa, may mean that the query is erroneous, that the database is
       incomplete, or simply, you learned something new about your data.
       Second, if you are using an update or delete statement, you had better
       be sure that the statement that you write performs the operation on the
       desired row (or rows)...or else, you might be deleting or updating more
       rows than you intend. Third, any queries written in Embedded SQL must
       be carefully thought out as to the number of rows returned. If you
       write a single-row query, only one SQL statement may need to be
       performed to complete the programming logic required. If your query, on
       the other hand, returns multiple rows, you will have to use the Fetch
       statement, and quite probably, some sort of looping structure in your
       program will be required to iterate processing on each returned row of
       the query.
   10. What are relationships? --Another design question...the term
       "relationships" (often termed "relation") usually refers to the
       relationships among primary and foreign keys between tables. This
       concept is important because when the tables of a relational database
       are designed, these relationships must be defined because they
       determine which columns are or are not primary or foreign keys. You may
       have heard of an Entity-Relationship Diagram, which is a graphical view
       of tables in a database schema, with lines connecting related columns
       across tables. See the sample diagram at the end of this section or
       some of the sites below in regard to this topic, as there are many
       different ways of drawing E-R diagrams. But first, let's look at each
       kind of relationship...

       A One-to-one relationship means that you have a primary key column that
       is related to a foreign key column, and that for every primary key
       value, there is one foreign key value. For example, in the first
       example, the EmployeeAddressTable, we add an EmployeeIDNo column. Then,
       the EmployeeAddressTable is related to the EmployeeStatisticsTable
       (second example table) by means of that EmployeeIDNo. Specifically,
       each employee in the EmployeeAddressTable has statistics (one row of
       data) in the EmployeeStatisticsTable. Even though this is a contrived
       example, this is a "1-1" relationship. Also notice the "has" in
       bold...when expressing a relationship, it is important to describe the
       relationship with a verb.

       The other two kinds of relationships may or may not use logical primary
       key and foreign key constraints...it is strictly a call of the
       designer. The first of these is the one-to-many relationship ("1-M").
       This means that for every column value in one table, there is one or
       more related values in another table. Key constraints may be added to
       the design, or possibly just the use of some sort of identifier column
       may be used to establish the relationship. An example would be that for
       every OwnerID in the AntiqueOwners table, there are one or more (zero
       is permissible too) Items bought in the Antiques table (verb: buy).

       Finally, the many-to-many relationship ("M-M") does not involve keys
       generally, and usually involves idenifying columns. The unusual
       occurence of a "M-M" means that one column in one table is related to
       another column in another table, and for every value of one of these
       two columns, there are one or more related values in the corresponding
       column in the other table (and vice-versa), or more a common
       possibility, two tables have a 1-M relationship to each other (two
       relationships, one 1-M going each way). A [bad] example of the more
       common situation would be if you had a job assignment database, where
       one table held one row for each employee and a job assignment, and
       another table held one row for each job with one of the assigned
       employees. Here, you would have multiple rows for each employee in the
       first table, one for each job assignment, and multiple rows for each
       job in the second table, one for each employee assigned to the project.
       These tables have a M-M: each employee in the first table has many job
       assignments from the second table, and each job has many employees
       assigned to it from the first table. This is the tip of the iceberg on
       this topic...see the links below for more information and see the
       diagram below for a simplified example of an E-R diagram.
       [Sample Simplified Entity-Relationship Diagram]

   11. What are some important nonstandard SQL features (extremely common
       question)? --Well, see the next section...

  ----------------------------------------------------------------------------
  Nonstandard SQL..."check local listings"

     * INTERSECT and MINUS are like the UNION statement, except that INTERSECT
       produces rows that appear in both queries, and MINUS produces rows that
       result from the first query, but not the second.
     * Report Generation Features: the COMPUTE clause is placed at the end of
       a query to place the result of an aggregate function at the end of a
       listing, like COMPUTE SUM (PRICE); Another option is to use break
       logic: define a break to divide the query results into groups based on
       a column, like BREAK ON BUYERID. Then, to produce a result after the
       listing of a group, use COMPUTE SUM OF PRICE ON BUYERID. If, for
       example, you used all three of these clauses (BREAK first, COMPUTE on
       break second, COMPUTE overall sum third), you would get a report that
       grouped items by their BuyerID, listing the sum of Prices after each
       group of a BuyerID's items, then, after all groups are listed, the sum
       of all Prices is listed, all with SQL-generated headers and lines.
     * In addition to the above listed aggregate functions, some DBMS's allow
       more functions to be used in Select lists, except that these functions
       (some character functions allow multiple-row results) are to be used
       with an individual value (not groups), on single-row queries. The
       functions are to be used only on appropriate data types, also. Here are
       some Mathematical Functions:

        ABS(X)       Absolute value-converts negative numbers to positive, or
                     leaves positive numbers alone
        CEIL(X)      X is a decimal value that will be rounded up.
        FLOOR(X)     X is a decimal value that will be rounded down.
        GREATEST(X,Y)Returns the largest of the two values.
        LEAST(X,Y)   Returns the smallest of the two values.
        MOD(X,Y)     Returns the remainder of X / Y.
        POWER(X,Y)   Returns X to the power of Y.

        ROUND(X,Y)   Rounds X to Y decimal places. If Y is omitted, X is
                     rounded to the nearest integer.
        SIGN(X)      Returns a minus if X < 0, else a plus.
        SQRT(X)      Returns the square root of X.
                                 Character Functions

        LEFT(<string>,X)
                             Returns the leftmost X characters of the string.

        RIGHT(<string>,X)
                             Returns the rightmost X characters of the
                             string.
        UPPER(<string>)
                             Converts the string to all uppercase letters.
        LOWER(<string>)
                             Converts the string to all lowercase letters.
        INITCAP(<string>)
                             Converts the string to initial caps.
        LENGTH(<string>)
                             Returns the number of characters in the string.

        <string>||<string>
                             Combines the two strings of text into one,
                             concatenated string, where the first string is
                             immediately followed by the second.

        LPAD(<string>,X,'*')
                             Pads the string on the left with the * (or
                             whatever character is inside the quotes), to
                             make the string X characters long.

        RPAD(<string>,X,'*')
                             Pads the string on the right with the * (or
                             whatever character is inside the quotes), to
                             make the string X characters long.

        SUBSTR(<string>,X,Y)
                             Extracts Y letters from the string beginning at
                             position X.

        NVL(<column>,<value>)
                             The Null value function will substitute <value>
                             for any NULLs for in the <column>. If the
                             current value of <column> is not NULL, NVL has
                             no effect.

  ----------------------------------------------------------------------------
  Syntax Summary--For Advanced Users Only

  Here are the general forms of the statements discussed in this tutorial,
  plus some extra important ones (explanations given). REMEMBER that all of
  these statements may or may not be available on your system, so check
  documentation regarding availability:

  ALTER TABLE <TABLE NAME> ADD|DROP|MODIFY (COLUMN SPECIFICATION[S]...see
  Create Table); --allows you to add or delete a column or columns from a
  table, or change the specification (data type, etc.) on an existing column;
  this statement is also used to change the physical specifications of a table
  (how a table is stored, etc.), but these definitions are DBMS-specific, so
  read the documentation. Also, these physical specifications are used with
  the Create Table statement, when a table is first created. In addition, only
  one option can be performed per Alter Table statement--either add, drop, OR
  modify in a single statement.

  COMMIT; --makes changes made to some database systems permanent (since the
  last COMMIT; known as a transaction)

  CREATE [UNIQUE] INDEX <INDEX NAME>
  ON <TABLE NAME> (<COLUMN LIST>); --UNIQUE is optional; within brackets.

  CREATE TABLE <TABLE NAME>
  (<COLUMN NAME> <DATA TYPE> [(<SIZE>)] <COLUMN CONSTRAINT>,
  --where SIZE is only used on certain data types (see above), and constraints
  include the following possibilities (automatically enforced by the DBMS;
  failure causes an error to be generated):

    1. NULL or NOT NULL (see above)
    2. UNIQUE enforces that no two rows will have the same value for this
       column
    3. PRIMARY KEY tells the database that this column is the primary key
       column (only used if the key is a one column key, otherwise a
       PRIMARY KEY (column, column, ...) statement appears after the last
       column definition.
    4. CHECK allows a condition to be checked for when data in that column is
       updated or inserted; for example, CHECK (PRICE > 0) causes the system
       to check that the Price column is greater than zero before accepting
       the value...sometimes implemented as the CONSTRAINT statement.
    5. DEFAULT inserts the default value into the database if a row is
       inserted without that column's data being inserted; for example,
       BENEFITS INTEGER DEFAULT = 10000
    6. FOREIGN KEY works the same as Primary Key, but is followed by:
       REFERENCES <TABLE NAME> (<COLUMN NAME>), which refers to the
       referential primary key.

  CREATE VIEW <TABLE NAME> AS <QUERY>;

  DELETE FROM <TABLE NAME> WHERE <CONDITION>;

  INSERT INTO <TABLE NAME> [(<COLUMN LIST>)]
  VALUES (<VALUE LIST>);
  ROLLBACK; --Takes back any changes to the database that you have made, back
  to the last time you gave a Commit command...beware! Some software uses
  automatic committing on systems that use the transaction features, so the
  Rollback command may not work.

  SELECT [DISTINCT|ALL] <LIST OF COLUMNS, FUNCTIONS, CONSTANTS, ETC.>
  FROM <LIST OF TABLES OR VIEWS>
  [WHERE <CONDITION(S)>]
  [GROUP BY <GROUPING COLUMN(S)>]
  [HAVING <CONDITION>]
  [ORDER BY <ORDERING COLUMN(S)> [ASC|DESC]]; --where ASC|DESC allows the
  ordering to be done in ASCending or DESCending order

  UPDATE <TABLE NAME>
  SET <COLUMN NAME> = <VALUE>
  [WHERE <CONDITION>]; --if the Where clause is left out, all rows will be
  updated according to the Set statement

  ----------------------------------------------------------------------------

